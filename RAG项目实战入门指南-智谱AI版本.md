# ğŸš€ RAGé¡¹ç›®å®æˆ˜å…¥é—¨æŒ‡å—ï¼ˆæ™ºè°±AIç‰ˆæœ¬ï¼‰

## ğŸ¯ å­¦ä¹ ç›®æ ‡

é€šè¿‡æœ¬æŒ‡å—ï¼Œæ‚¨å°†ï¼š
1. âœ… äº†è§£RAGé¡¹ç›®çš„å‰ç½®çŸ¥è¯†
2. âœ… æ­å»ºå®Œæ•´çš„å¼€å‘ç¯å¢ƒï¼ˆä½¿ç”¨æ™ºè°±AIï¼‰
3. âœ… å®ç°ç¬¬ä¸€ä¸ªèƒ½è¿è¡Œçš„RAGç³»ç»Ÿ
4. âœ… ç†è§£RAGçš„æ ¸å¿ƒç»„ä»¶
5. âœ… æŒæ¡é€æ­¥æ‰©å±•çš„æ–¹æ³•

---

## ğŸ“‹ å‰ç½®çŸ¥è¯†è‡ªæŸ¥è¡¨

### âœ… å¿…é¡»æŒæ¡ï¼ˆæ‚¨å·²ç»å…·å¤‡ï¼‰

- [x] **PythonåŸºç¡€**ï¼šå˜é‡ã€å‡½æ•°ã€ç±»
- [x] **åŸºæœ¬æ•°æ®ç»“æ„**ï¼šåˆ—è¡¨ã€å­—å…¸
- [x] **æ–‡ä»¶æ“ä½œ**ï¼šè¯»å†™æ–‡ä»¶

### ğŸŸ¡ éœ€è¦äº†è§£ï¼ˆå¯ä»¥è¾¹åšè¾¹å­¦ï¼‰

- [ ] **å‘é‡æ•°æ®åº“æ¦‚å¿µ**ï¼šå·²å­¦ä¹ ç†è®ºï¼Œå®è·µä¸­ä¼šç”¨åˆ°
- [ ] **APIè°ƒç”¨**ï¼šä¼šç”¨requestsæˆ–SDKè°ƒç”¨æ¥å£
- [ ] **å¼‚å¸¸å¤„ç†**ï¼štry-exceptåŸºæœ¬ç”¨æ³•

### ğŸ”µ å¯é€‰ï¼ˆæœ‰æ›´å¥½ï¼Œæ²¡æœ‰ä¹Ÿè¡Œï¼‰

- [ ] **Docker**ï¼šæ–¹ä¾¿éƒ¨ç½²å‘é‡æ•°æ®åº“
- [ ] **å¼‚æ­¥ç¼–ç¨‹**ï¼šasync/awaitï¼ˆå¯ä»¥æå‡æ€§èƒ½ï¼‰
- [ ] **Webæ¡†æ¶**ï¼šFlask/FastAPIï¼ˆå¦‚æœè¦åšAPIæœåŠ¡ï¼‰

---

## ğŸ“ å­¦ä¹ è·¯å¾„ï¼šä¸‰ä¸ªé˜¶æ®µ

### é˜¶æ®µ1ï¼šæœ€ç®€RAGï¼ˆ1-2å¤©ï¼‰â­ ä»è¿™é‡Œå¼€å§‹

**ç›®æ ‡ï¼š**è·‘é€šä¸€ä¸ªæœ€ç®€å•çš„RAGç³»ç»Ÿ

**æ ¸å¿ƒåŠŸèƒ½ï¼š**
- è¯»å–æœ¬åœ°æ–‡æ¡£ï¼ˆtxt/mdï¼‰
- ä½¿ç”¨æ™ºè°±AI Embeddingï¼ˆembedding-2æ¨¡å‹ï¼‰
- å­˜å‚¨åˆ°æœ¬åœ°ï¼ˆä¸ç”¨å‘é‡åº“ï¼‰
- ç®€å•æ£€ç´¢+é—®ç­”

**æŠ€æœ¯æ ˆï¼š**
```python
- Python 3.8+
- zhipuaiåº“ï¼ˆæ™ºè°±AI SDKï¼‰
- numpyï¼ˆå‘é‡è®¡ç®—ï¼‰
```

**éš¾åº¦ï¼š** â­ é€‚åˆå…¥é—¨

---

### é˜¶æ®µ2ï¼šæ ‡å‡†RAGï¼ˆ3-5å¤©ï¼‰

**æ–°å¢åŠŸèƒ½ï¼š**
- æ¥å…¥å‘é‡æ•°æ®åº“ï¼ˆMilvus/ChromaDBï¼‰
- æ”¯æŒæ›´å¤šæ–‡æ¡£ç±»å‹ï¼ˆPDFã€Wordï¼‰
- ä¼˜åŒ–æ£€ç´¢æ•ˆæœ

**æŠ€æœ¯æ ˆï¼š**
```python
- é˜¶æ®µ1 +
- pymilvus / chromadbï¼ˆå‘é‡åº“ï¼‰
- langchainï¼ˆRAGæ¡†æ¶ï¼‰
- pypdf / docxï¼ˆæ–‡æ¡£è§£æï¼‰
```

**éš¾åº¦ï¼š** â­â­ 

---

### é˜¶æ®µ3ï¼šç”Ÿäº§çº§RAGï¼ˆ1-2å‘¨ï¼‰

**æ–°å¢åŠŸèƒ½ï¼š**
- APIæœåŠ¡åŒ–ï¼ˆFastAPIï¼‰
- æµå¼è¾“å‡º
- å¤šè½®å¯¹è¯
- ç›‘æ§å’Œæ—¥å¿—

**æŠ€æœ¯æ ˆï¼š**
```python
- é˜¶æ®µ2 +
- fastapiï¼ˆWebæ¡†æ¶ï¼‰
- redisï¼ˆç¼“å­˜ï¼‰
- dockerï¼ˆéƒ¨ç½²ï¼‰
```

**éš¾åº¦ï¼š** â­â­â­

---

## ğŸ’¡ å»ºè®®ï¼šä»é˜¶æ®µ1å¼€å§‹ï¼

å…ˆæŠŠæœ€ç®€å•çš„ç‰ˆæœ¬è·‘é€šï¼Œç†è§£æ ¸å¿ƒåŸç†ï¼Œå†é€æ­¥æ‰©å±•ã€‚

---

## ğŸ› ï¸ é˜¶æ®µ1ï¼šæœ€ç®€RAGå®æˆ˜

### é¡¹ç›®ç»“æ„

```
simple-rag/
â”œâ”€â”€ documents/          # å­˜æ”¾æ–‡æ¡£
â”‚   â”œâ”€â”€ doc1.txt
â”‚   â””â”€â”€ doc2.txt
â”œâ”€â”€ simple_rag.py      # ä¸»ç¨‹åº
â”œâ”€â”€ requirements.txt   # ä¾èµ–
â”œâ”€â”€ .env               # APIå¯†é’¥é…ç½®
â””â”€â”€ README.md
```

### æ ¸å¿ƒæµç¨‹

```
1. æ–‡æ¡£åŠ è½½ â†’ åˆ†å—
2. ç”ŸæˆEmbedding â†’ å­˜å‚¨
3. ç”¨æˆ·æé—® â†’ ç”Ÿæˆé—®é¢˜Embedding
4. ç›¸ä¼¼åº¦æœç´¢ â†’ æ‰¾åˆ°ç›¸å…³æ–‡æ¡£
5. æ–‡æ¡£+é—®é¢˜ â†’ å‘ç»™LLM â†’ ç”Ÿæˆç­”æ¡ˆ
```

è®©æˆ‘ä»¬ä¸€æ­¥æ­¥å®ç°ï¼

---

## ğŸ“¦ æ­¥éª¤1ï¼šç¯å¢ƒé…ç½®

### 1.1 åˆ›å»ºé¡¹ç›®ç›®å½•

```bash
mkdir simple-rag
cd simple-rag
mkdir documents
```

### 1.2 åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Mac/Linux
python3 -m venv venv
source venv/bin/activate
```

### 1.3 å®‰è£…ä¾èµ–

åˆ›å»º `requirements.txt`ï¼š

```txt
zhipuai>=2.0.0
numpy>=1.24.0
python-dotenv>=1.0.0
```

å®‰è£…ï¼š

```bash
pip install -r requirements.txt
```

### 1.4 é…ç½®APIå¯†é’¥

**å¦‚ä½•è·å–æ™ºè°±AI APIå¯†é’¥ï¼š**
1. è®¿é—® https://open.bigmodel.cn/
2. æ³¨å†Œ/ç™»å½•è´¦å·
3. åœ¨æ§åˆ¶å°åˆ›å»ºAPIå¯†é’¥
4. å¤åˆ¶å¯†é’¥

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```bash
ZHIPUAI_API_KEY=your_api_key_here
```

**æ™ºè°±AIçš„ä¼˜åŠ¿ï¼š**
- âœ… å›½å†…è®¿é—®é€Ÿåº¦å¿«
- âœ… ä»·æ ¼ç›¸å¯¹ä¾¿å®œ
- âœ… æ”¯æŒä¸­æ–‡æ•ˆæœå¥½
- âœ… æœ‰å…è´¹é¢åº¦å¯ç”¨

---

## ğŸ’» æ­¥éª¤2ï¼šå®Œæ•´ä»£ç å®ç°

ä¸‹é¢æ˜¯ä¸€ä¸ªå®Œæ•´çš„ã€å¯è¿è¡Œçš„æœ€ç®€RAGç³»ç»Ÿï¼ˆæ™ºè°±AIç‰ˆæœ¬ï¼‰ï¼š

### 2.1 åˆ›å»º `simple_rag.py`

```python
"""
æœ€ç®€RAGç³»ç»Ÿ - å®Œæ•´å®ç°ï¼ˆæ™ºè°±AIç‰ˆæœ¬ï¼‰
simple_rag.py
"""

import os
import numpy as np
from zhipuai import ZhipuAI
from typing import List, Tuple
import json

# ============================================
# ç¬¬1éƒ¨åˆ†ï¼šæ–‡æ¡£å¤„ç†
# ============================================

class DocumentLoader:
    """æ–‡æ¡£åŠ è½½å™¨"""
    
    def load_documents(self, folder_path: str) -> List[str]:
        """ä»æ–‡ä»¶å¤¹åŠ è½½æ‰€æœ‰txtæ–‡æ¡£"""
        documents = []
        
        for filename in os.listdir(folder_path):
            if filename.endswith('.txt'):
                filepath = os.path.join(folder_path, filename)
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()
                    documents.append(content)
                print(f"âœ… åŠ è½½æ–‡æ¡£: {filename}")
        
        return documents
    
    def split_text(self, text: str, chunk_size: int = 500) -> List[str]:
        """å°†æ–‡æœ¬åˆ†å—
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            chunk_size: æ¯å—çš„å­—ç¬¦æ•°
        """
        chunks = []
        
        # ç®€å•æŒ‰å­—ç¬¦æ•°åˆ†å—
        for i in range(0, len(text), chunk_size):
            chunk = text[i:i + chunk_size]
            chunks.append(chunk)
        
        return chunks


# ============================================
# ç¬¬2éƒ¨åˆ†ï¼šå‘é‡å­˜å‚¨ï¼ˆç®€å•ç‰ˆï¼Œä¸ç”¨å‘é‡åº“ï¼‰
# ============================================

class SimpleVectorStore:
    """ç®€å•çš„å‘é‡å­˜å‚¨ï¼ˆå†…å­˜å­˜å‚¨ï¼‰"""
    
    def __init__(self):
        self.texts = []      # å­˜å‚¨åŸå§‹æ–‡æœ¬
        self.embeddings = [] # å­˜å‚¨å¯¹åº”çš„å‘é‡
        
    def add(self, text: str, embedding: List[float]):
        """æ·»åŠ æ–‡æœ¬å’Œå‘é‡"""
        self.texts.append(text)
        self.embeddings.append(embedding)
    
    def search(self, query_embedding: List[float], top_k: int = 3) -> List[Tuple[str, float]]:
        """æœç´¢æœ€ç›¸ä¼¼çš„æ–‡æ¡£
        
        Args:
            query_embedding: æŸ¥è¯¢å‘é‡
            top_k: è¿”å›å‰kä¸ªç»“æœ
            
        Returns:
            [(æ–‡æœ¬, ç›¸ä¼¼åº¦åˆ†æ•°), ...]
        """
        if not self.embeddings:
            return []
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        query_vec = np.array(query_embedding)
        
        similarities = []
        for i, emb in enumerate(self.embeddings):
            emb_vec = np.array(emb)
            
            # ä½™å¼¦ç›¸ä¼¼åº¦å…¬å¼
            similarity = np.dot(query_vec, emb_vec) / (
                np.linalg.norm(query_vec) * np.linalg.norm(emb_vec)
            )
            
            similarities.append((self.texts[i], float(similarity)))
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åºï¼Œè¿”å›top_k
        similarities.sort(key=lambda x: x[1], reverse=True)
        return similarities[:top_k]
    
    def save(self, filepath: str):
        """ä¿å­˜åˆ°æ–‡ä»¶"""
        data = {
            'texts': self.texts,
            'embeddings': self.embeddings
        }
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False)
        print(f"âœ… å‘é‡åº“å·²ä¿å­˜åˆ°: {filepath}")
    
    def load(self, filepath: str):
        """ä»æ–‡ä»¶åŠ è½½"""
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        self.texts = data['texts']
        self.embeddings = data['embeddings']
        print(f"âœ… å‘é‡åº“å·²åŠ è½½ï¼Œå…± {len(self.texts)} æ¡è®°å½•")


# ============================================
# ç¬¬3éƒ¨åˆ†ï¼šRAGæ ¸å¿ƒç±»
# ============================================

class SimpleRAG:
    """ç®€å•çš„RAGç³»ç»Ÿï¼ˆæ™ºè°±AIç‰ˆæœ¬ï¼‰"""
    
    def __init__(self, api_key: str):
        """åˆå§‹åŒ–
        
        Args:
            api_key: æ™ºè°±AI APIå¯†é’¥
        """
        self.client = ZhipuAI(api_key=api_key)
        
        self.doc_loader = DocumentLoader()
        self.vector_store = SimpleVectorStore()
        
        print("âœ… SimpleRAG åˆå§‹åŒ–å®Œæˆï¼ˆä½¿ç”¨æ™ºè°±AIï¼‰")
    
    def get_embedding(self, text: str) -> List[float]:
        """è·å–æ–‡æœ¬çš„Embeddingå‘é‡"""
        try:
            response = self.client.embeddings.create(
                model="embedding-2",  # æ™ºè°±AIçš„embeddingæ¨¡å‹
                input=text
            )
            # æ™ºè°±AIè¿”å›æ ¼å¼ï¼šresponse.data[0].embedding
            return response.data[0].embedding
        except Exception as e:
            print(f"âŒ è·å–Embeddingå¤±è´¥: {e}")
            raise
    
    def index_documents(self, folder_path: str):
        """ç´¢å¼•æ–‡æ¡£ï¼ˆæ„å»ºå‘é‡åº“ï¼‰"""
        print(f"\nğŸ“š å¼€å§‹ç´¢å¼•æ–‡æ¡£...")
        
        # 1. åŠ è½½æ–‡æ¡£
        documents = self.doc_loader.load_documents(folder_path)
        print(f"âœ… å…±åŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£")
        
        # 2. åˆ†å—
        all_chunks = []
        for doc in documents:
            chunks = self.doc_loader.split_text(doc, chunk_size=500)
            all_chunks.extend(chunks)
        print(f"âœ… å…±åˆ†æˆ {len(all_chunks)} ä¸ªæ–‡æœ¬å—")
        
        # 3. ç”ŸæˆEmbeddingå¹¶å­˜å‚¨
        print("ğŸ”„ æ­£åœ¨ç”Ÿæˆå‘é‡...")
        for i, chunk in enumerate(all_chunks):
            embedding = self.get_embedding(chunk)
            self.vector_store.add(chunk, embedding)
            
            if (i + 1) % 10 == 0:
                print(f"   è¿›åº¦: {i + 1}/{len(all_chunks)}")
        
        print("âœ… å‘é‡ç”Ÿæˆå®Œæˆï¼")
    
    def query(self, question: str, top_k: int = 3) -> str:
        """æŸ¥è¯¢é—®é¢˜
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            top_k: æ£€ç´¢å¤šå°‘ä¸ªç›¸å…³æ–‡æ¡£
            
        Returns:
            LLMç”Ÿæˆçš„ç­”æ¡ˆ
        """
        print(f"\nâ“ é—®é¢˜: {question}")
        
        # 1. å°†é—®é¢˜è½¬æˆå‘é‡
        print("ğŸ”„ æ­£åœ¨æ£€ç´¢ç›¸å…³æ–‡æ¡£...")
        question_embedding = self.get_embedding(question)
        
        # 2. æ£€ç´¢ç›¸ä¼¼æ–‡æ¡£
        results = self.vector_store.search(question_embedding, top_k=top_k)
        
        if not results:
            return "âŒ æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ–‡æ¡£"
        
        # 3. æ‰“å°æ£€ç´¢ç»“æœ
        print(f"âœ… æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£:")
        for i, (text, score) in enumerate(results):
            print(f"   {i+1}. ç›¸ä¼¼åº¦: {score:.3f} - {text[:50]}...")
        
        # 4. æ„å»ºprompt
        context = "\n\n".join([text for text, score in results])
        
        prompt = f"""è¯·åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ã€‚å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯´"æ–‡æ¡£ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯"ã€‚

æ–‡æ¡£å†…å®¹ï¼š
{context}

é—®é¢˜ï¼š{question}

å›ç­”ï¼š"""
        
        # 5. è°ƒç”¨LLMç”Ÿæˆç­”æ¡ˆ
        print("ğŸ”„ æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ...")
        try:
            response = self.client.chat.completions.create(
                model="glm-4",  # æ™ºè°±AIçš„å¯¹è¯æ¨¡å‹ï¼Œä¹Ÿå¯ä»¥ç”¨ "glm-3-turbo"
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7
            )
            
            answer = response.choices[0].message.content
            return answer
        except Exception as e:
            print(f"âŒ ç”Ÿæˆç­”æ¡ˆå¤±è´¥: {e}")
            return f"ç”Ÿæˆç­”æ¡ˆæ—¶å‡ºé”™: {str(e)}"
```

---

## ğŸ® æ­¥éª¤3ï¼šä½¿ç”¨ç¤ºä¾‹

### 3.1 å‡†å¤‡æµ‹è¯•æ–‡æ¡£

åˆ›å»º `documents/ai_intro.txt`ï¼š

```
äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligence, AIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ã€‚
å®ƒä¼å›¾äº†è§£æ™ºèƒ½çš„å®è´¨ï¼Œå¹¶ç”Ÿäº§å‡ºä¸€ç§æ–°çš„èƒ½ä»¥äººç±»æ™ºèƒ½ç›¸ä¼¼çš„æ–¹å¼åšå‡ºååº”çš„æ™ºèƒ½æœºå™¨ã€‚
è¯¥é¢†åŸŸçš„ç ”ç©¶åŒ…æ‹¬æœºå™¨äººã€è¯­è¨€è¯†åˆ«ã€å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œä¸“å®¶ç³»ç»Ÿç­‰ã€‚

æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒï¼Œæ˜¯ä½¿è®¡ç®—æœºå…·æœ‰æ™ºèƒ½çš„æ ¹æœ¬é€”å¾„ã€‚
æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒä½¿ç”¨ç¥ç»ç½‘ç»œæ¥å­¦ä¹ æ•°æ®çš„è¡¨ç¤ºã€‚
```

åˆ›å»º `documents/rag_intro.txt`ï¼š

```
RAGï¼ˆRetrieval Augmented Generationï¼‰æ˜¯ä¸€ç§ç»“åˆæ£€ç´¢å’Œç”Ÿæˆçš„AIæŠ€æœ¯ã€‚
å®ƒé€šè¿‡æ£€ç´¢ç›¸å…³æ–‡æ¡£æ¥å¢å¼ºå¤§è¯­è¨€æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ã€‚

RAGçš„æ ¸å¿ƒä¼˜åŠ¿åŒ…æ‹¬ï¼š
1. å¯ä»¥ä½¿ç”¨æœ€æ–°çš„ã€ç§æœ‰çš„æ•°æ®
2. å‡å°‘å¤§æ¨¡å‹çš„å¹»è§‰é—®é¢˜
3. ç­”æ¡ˆå¯ä»¥è¿½æº¯æ¥æº
4. ä¸éœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹

RAGç³»ç»Ÿé€šå¸¸åŒ…å«ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šæ–‡æ¡£æ£€ç´¢å™¨ã€å‘é‡æ•°æ®åº“å’Œå¤§è¯­è¨€æ¨¡å‹ã€‚
```

### 3.2 åˆ›å»ºä¸»ç¨‹åº `main.py`

```python
from simple_rag import SimpleRAG
import os
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ä»ç¯å¢ƒå˜é‡è¯»å–APIå¯†é’¥
api_key = os.getenv('ZHIPUAI_API_KEY')

if not api_key:
    print("âŒ è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® ZHIPUAI_API_KEY")
    exit(1)

# åˆå§‹åŒ–RAG
rag = SimpleRAG(api_key=api_key)

# ç´¢å¼•æ–‡æ¡£
rag.index_documents('documents')

# ä¿å­˜å‘é‡åº“ï¼ˆå¯é€‰ï¼‰
rag.vector_store.save('vector_store.json')

# å¼€å§‹é—®ç­”
while True:
    question = input("\nè¯·è¾“å…¥é—®é¢˜ï¼ˆè¾“å…¥'quit'é€€å‡ºï¼‰: ")
    
    if question.lower() == 'quit':
        break
    
    answer = rag.query(question)
    print(f"\nğŸ’¡ ç­”æ¡ˆ:\n{answer}\n")
    print("-" * 50)
```

### 3.3 è¿è¡Œ

```bash
python main.py
```

---

## ğŸ” ä»£ç è¯¦è§£

### æ ¸å¿ƒæµç¨‹å›¾

```
ç”¨æˆ·é—®é¢˜: "ä»€ä¹ˆæ˜¯RAG?"
    â†“
1. è½¬æˆå‘é‡ (get_embedding)
    ä½¿ç”¨æ™ºè°±AI embedding-2æ¨¡å‹
    [0.23, -0.45, 0.67, ...]
    â†“
2. å‘é‡æ£€ç´¢ (vector_store.search)
    æ‰¾åˆ°æœ€ç›¸ä¼¼çš„3ä¸ªæ–‡æ¡£å—
    â†“
3. æ„å»ºPrompt
    "åŸºäºä»¥ä¸‹æ–‡æ¡£: [æ–‡æ¡£1][æ–‡æ¡£2][æ–‡æ¡£3]
     é—®é¢˜: ä»€ä¹ˆæ˜¯RAG?"
    â†“
4. å‘ç»™LLM (client.chat.completions.create)
    ä½¿ç”¨æ™ºè°±AI glm-4æ¨¡å‹
    â†“
5. è¿”å›ç­”æ¡ˆ
    "RAGæ˜¯ä¸€ç§ç»“åˆæ£€ç´¢å’Œç”Ÿæˆçš„AIæŠ€æœ¯..."
```

### å…³é”®ä»£ç è§£æ

#### 1. æ™ºè°±AIå®¢æˆ·ç«¯åˆå§‹åŒ–

```python
from zhipuai import ZhipuAI

self.client = ZhipuAI(api_key=api_key)
```

**è¯´æ˜ï¼š**
- ä½¿ç”¨ `zhipuai` åº“ï¼Œè€Œä¸æ˜¯ `openai`
- åªéœ€è¦ä¼ å…¥ `api_key`ï¼Œä¸éœ€è¦ `base_url`

#### 2. è·å–Embeddingå‘é‡

```python
response = self.client.embeddings.create(
    model="embedding-2",  # æ™ºè°±AIçš„embeddingæ¨¡å‹
    input=text
)
return response.data[0].embedding
```

**è¯´æ˜ï¼š**
- æ¨¡å‹åç§°ï¼š`embedding-2`ï¼ˆæ™ºè°±AIçš„embeddingæ¨¡å‹ï¼‰
- è¿”å›æ ¼å¼ä¸OpenAIç›¸åŒï¼š`response.data[0].embedding`

#### 3. è°ƒç”¨å¯¹è¯æ¨¡å‹

```python
response = self.client.chat.completions.create(
    model="glm-4",  # æ™ºè°±AIçš„å¯¹è¯æ¨¡å‹
    messages=[
        {"role": "user", "content": prompt}
    ],
    temperature=0.7
)
```

**è¯´æ˜ï¼š**
- æ¨¡å‹åç§°ï¼š`glm-4`ï¼ˆæ™ºè°±AIæœ€æ–°æ¨¡å‹ï¼‰æˆ– `glm-3-turbo`ï¼ˆæ›´å¿«æ›´ä¾¿å®œï¼‰
- APIè°ƒç”¨æ–¹å¼ä¸OpenAIå®Œå…¨å…¼å®¹

#### 4. ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—

```python
similarity = np.dot(query_vec, emb_vec) / (
    np.linalg.norm(query_vec) * np.linalg.norm(emb_vec)
)
```

**å«ä¹‰ï¼š**
- `np.dot()`: å‘é‡ç‚¹ç§¯
- `np.linalg.norm()`: å‘é‡é•¿åº¦
- ä½™å¼¦ç›¸ä¼¼åº¦ = ç‚¹ç§¯ / (é•¿åº¦1 Ã— é•¿åº¦2)
- èŒƒå›´ï¼š-1åˆ°1ï¼Œè¶Šæ¥è¿‘1è¶Šç›¸ä¼¼

---

## ğŸš¨ å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

### Q1: æ™ºè°±AI APIè°ƒç”¨å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

**æ–¹æ¡ˆAï¼šæ£€æŸ¥APIå¯†é’¥**

```python
# ç¡®ä¿APIå¯†é’¥æ­£ç¡®
import os
from dotenv import load_dotenv
load_dotenv()

api_key = os.getenv('ZHIPUAI_API_KEY')
print(f"APIå¯†é’¥å‰5ä½: {api_key[:5]}...")  # æ£€æŸ¥æ˜¯å¦æ­£ç¡®åŠ è½½
```

**æ–¹æ¡ˆBï¼šæ£€æŸ¥ç½‘ç»œè¿æ¥**

```python
# æ™ºè°±AIæœåŠ¡å™¨åœ¨å›½å†…ï¼Œå¦‚æœè®¿é—®å¤±è´¥å¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜
# å¯ä»¥å°è¯•ä½¿ç”¨ä»£ç†æˆ–æ£€æŸ¥é˜²ç«å¢™è®¾ç½®
```

**æ–¹æ¡ˆCï¼šæŸ¥çœ‹é”™è¯¯ä¿¡æ¯**

```python
try:
    response = self.client.embeddings.create(...)
except Exception as e:
    print(f"é”™è¯¯è¯¦æƒ…: {e}")
    # å¸¸è§é”™è¯¯ï¼š
    # - APIå¯†é’¥æ— æ•ˆ
    # - ä½™é¢ä¸è¶³
    # - è¯·æ±‚é¢‘ç‡è¿‡é«˜
```

---

### Q2: APIè°ƒç”¨å¤ªæ…¢æ€ä¹ˆåŠï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼šæ‰¹é‡å¤„ç†**

```python
def get_embeddings_batch(self, texts: List[str]) -> List[List[float]]:
    """æ‰¹é‡è·å–embeddingï¼ˆæ™ºè°±AIç‰ˆæœ¬ï¼‰"""
    try:
        response = self.client.embeddings.create(
            model="embedding-2",
            input=texts  # ä¸€æ¬¡å‘é€å¤šä¸ªæ–‡æœ¬ï¼ˆæ™ºè°±AIæ”¯æŒæ‰¹é‡ï¼‰
        )
        return [data.embedding for data in response.data]
    except Exception as e:
        print(f"âŒ æ‰¹é‡è·å–Embeddingå¤±è´¥: {e}")
        # é™çº§ä¸ºå•ä¸ªå¤„ç†
        return [self.get_embedding(text) for text in texts]
```

**ä¼˜åŒ–ç´¢å¼•æ–‡æ¡£æ–¹æ³•ï¼š**

```python
def index_documents(self, folder_path: str):
    # ... å‰é¢çš„ä»£ç  ...
    
    # æ‰¹é‡ç”ŸæˆEmbeddingï¼ˆæ›´å¿«ï¼‰
    print("ğŸ”„ æ­£åœ¨æ‰¹é‡ç”Ÿæˆå‘é‡...")
    batch_size = 20  # æ¯æ‰¹å¤„ç†20ä¸ª
    for i in range(0, len(all_chunks), batch_size):
        batch = all_chunks[i:i + batch_size]
        embeddings = self.get_embeddings_batch(batch)
        
        for chunk, embedding in zip(batch, embeddings):
            self.vector_store.add(chunk, embedding)
        
        print(f"   è¿›åº¦: {min(i + batch_size, len(all_chunks))}/{len(all_chunks)}")
```

---

### Q3: æ–‡æ¡£å¤ªå¤§æ€ä¹ˆåŠï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼šæ™ºèƒ½åˆ†å—**

```python
def split_text_smart(self, text: str, chunk_size: int = 500):
    """æŒ‰æ®µè½æ™ºèƒ½åˆ†å—"""
    paragraphs = text.split('\n\n')
    
    chunks = []
    current_chunk = ""
    
    for para in paragraphs:
        if len(current_chunk) + len(para) < chunk_size:
            current_chunk += para + "\n\n"
        else:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = para + "\n\n"
    
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    return chunks
```

---

### Q4: æ£€ç´¢ç»“æœä¸å‡†ç¡®ï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼šè°ƒæ•´å‚æ•°**

```python
# 1. å¢åŠ æ£€ç´¢æ•°é‡
results = self.vector_store.search(question_embedding, top_k=5)  # ä»3æ”¹åˆ°5

# 2. æ·»åŠ ç›¸ä¼¼åº¦é˜ˆå€¼
filtered_results = [
    (text, score) for text, score in results 
    if score > 0.7  # åªè¦ç›¸ä¼¼åº¦>0.7çš„
]

# 3. è°ƒæ•´chunk_size
# å¦‚æœchunkå¤ªå°ï¼Œå¯èƒ½ä¸¢å¤±ä¸Šä¸‹æ–‡
# å¦‚æœchunkå¤ªå¤§ï¼Œå¯èƒ½åŒ…å«æ— å…³ä¿¡æ¯
chunks = self.doc_loader.split_text(doc, chunk_size=800)  # ä»500æ”¹åˆ°800
```

---

### Q5: æ™ºè°±AIæ¨¡å‹é€‰æ‹©

**Embeddingæ¨¡å‹ï¼š**
- `embedding-2`ï¼šæ¨èä½¿ç”¨ï¼Œæ•ˆæœå¥½
- `embedding-1`ï¼šæ—§ç‰ˆæœ¬ï¼Œä¸æ¨è

**å¯¹è¯æ¨¡å‹ï¼š**
- `glm-4`ï¼šæœ€æ–°æœ€å¼ºæ¨¡å‹ï¼Œæ•ˆæœå¥½ä½†ç¨æ…¢
- `glm-3-turbo`ï¼šé€Ÿåº¦å¿«ï¼Œä»·æ ¼ä¾¿å®œï¼Œé€‚åˆç®€å•ä»»åŠ¡
- `glm-4-flash`ï¼šå¹³è¡¡ç‰ˆæœ¬ï¼Œé€Ÿåº¦å¿«ä¸”æ•ˆæœå¥½

**é€‰æ‹©å»ºè®®ï¼š**
- å¼€å‘æµ‹è¯•ï¼šç”¨ `glm-3-turbo`ï¼ˆä¾¿å®œï¼‰
- ç”Ÿäº§ç¯å¢ƒï¼šç”¨ `glm-4`ï¼ˆæ•ˆæœå¥½ï¼‰

---

## ğŸ¯ ç»ƒä¹ ä»»åŠ¡

### ä»»åŠ¡1ï¼šåŸºç¡€ç‰ˆï¼ˆå¿…åšï¼‰â­

**ç›®æ ‡ï¼š**è·‘é€šä¸Šé¢çš„ä»£ç 

**æ­¥éª¤ï¼š**
1. âœ… å®‰è£…ä¾èµ–
2. âœ… æ³¨å†Œæ™ºè°±AIè´¦å·å¹¶è·å–APIå¯†é’¥
3. âœ… åˆ›å»ºæµ‹è¯•æ–‡æ¡£ï¼ˆè‡³å°‘2ä¸ªtxtæ–‡ä»¶ï¼‰
4. âœ… è¿è¡Œä»£ç ï¼ŒæˆåŠŸé—®ç­”
5. âœ… æµ‹è¯•ä¸åŒçš„é—®é¢˜

**éªŒæ”¶æ ‡å‡†ï¼š**
- èƒ½æˆåŠŸç´¢å¼•æ–‡æ¡£
- èƒ½æ­£ç¡®å›ç­”åŸºäºæ–‡æ¡£çš„é—®é¢˜
- ç†è§£æ•´ä¸ªæµç¨‹

---

### ä»»åŠ¡2ï¼šæ”¹è¿›ç‰ˆï¼ˆæ¨èï¼‰â­â­

**ç›®æ ‡ï¼š**æ·»åŠ æ–°åŠŸèƒ½

**å¯é€‰æ”¹è¿›ï¼š**
1. âœ… æ·»åŠ æ–‡æ¡£å…ƒæ•°æ®ï¼ˆæ–‡ä»¶åã€åˆ›å»ºæ—¶é—´ï¼‰
2. âœ… åœ¨ç­”æ¡ˆä¸­æ˜¾ç¤ºå¼•ç”¨æ¥æº
3. âœ… æ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼ï¼ˆmdã€pdfï¼‰
4. âœ… æ·»åŠ ç®€å•çš„Webç•Œé¢ï¼ˆStreamlitï¼‰

**æç¤ºï¼šå¼•ç”¨æ¥æºå®ç°**

```python
def query_with_source(self, question: str) -> Tuple[str, List[str]]:
    """æŸ¥è¯¢å¹¶è¿”å›æ¥æº"""
    # ... æ£€ç´¢ä»£ç  ...
    
    # è®°å½•æ¥æº
    sources = [f"æ–‡æ¡£ç‰‡æ®µ{i+1}: {text[:100]}..." 
               for i, (text, score) in enumerate(results)]
    
    # åœ¨promptä¸­è¦æ±‚æ ‡æ³¨æ¥æº
    prompt = f"""åŸºäºä»¥ä¸‹æ–‡æ¡£å›ç­”ï¼Œå¹¶æ ‡æ³¨å¼•ç”¨äº†å“ªäº›æ–‡æ¡£ã€‚

æ–‡æ¡£1: {results[0][0]}
æ–‡æ¡£2: {results[1][0]}
...

é—®é¢˜: {question}"""
    
    answer = # ... LLMè°ƒç”¨ ...
    
    return answer, sources
```

---

### ä»»åŠ¡3ï¼šå‘é‡åº“ç‰ˆï¼ˆè¿›é˜¶ï¼‰â­â­â­

**ç›®æ ‡ï¼š**æ¥å…¥çœŸå®å‘é‡æ•°æ®åº“

**æ­¥éª¤ï¼š**
1. âœ… å®‰è£…ChromaDBï¼ˆæœ€ç®€å•çš„å‘é‡åº“ï¼‰
   ```bash
   pip install chromadb
   ```

2. âœ… æ›¿æ¢SimpleVectorStoreä¸ºChromaDB

```python
import chromadb

class ChromaVectorStore:
    def __init__(self):
        self.client = chromadb.Client()
        self.collection = self.client.create_collection("documents")
    
    def add(self, text: str, embedding: List[float]):
        self.collection.add(
            embeddings=[embedding],
            documents=[text],
            ids=[f"doc_{len(self.collection.get()['ids'])}"]
        )
    
    def search(self, query_embedding: List[float], top_k: int = 3):
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k
        )
        return list(zip(results['documents'][0], results['distances'][0]))
```

---

## ğŸ“š æ¨èå­¦ä¹ èµ„æº

### å®˜æ–¹æ–‡æ¡£

1. **æ™ºè°±AI APIæ–‡æ¡£**
   - https://open.bigmodel.cn/dev/api
   - å­¦ä¹ Embeddingå’ŒChat APIçš„ç”¨æ³•
   - æŸ¥çœ‹æ¨¡å‹åˆ—è¡¨å’Œä»·æ ¼
   - æŸ¥çœ‹ç¤ºä¾‹ä»£ç 

2. **ChromaDBæ–‡æ¡£**
   - https://docs.trychroma.com/
   - æœ€ç®€å•çš„å‘é‡æ•°æ®åº“

3. **LangChainæ–‡æ¡£**
   - https://python.langchain.com/
   - RAGæ¡†æ¶ï¼Œé˜¶æ®µ2ä¼šç”¨åˆ°
   - æ”¯æŒæ™ºè°±AIé›†æˆ

### è§†é¢‘æ•™ç¨‹

1. **Bç«™æœç´¢ï¼š**
   - "RAGæ•™ç¨‹"
   - "å¤§æ¨¡å‹åº”ç”¨å¼€å‘"
   - "æ™ºè°±AIä½¿ç”¨æ•™ç¨‹"

2. **YouTubeæœç´¢ï¼š**
   - "RAG tutorial"
   - "Build RAG from scratch"
   - "LangChain RAG"

### å¼€æºé¡¹ç›®å‚è€ƒ

1. **Awesome-RAG**
   - https://github.com/Awesome-LLM-RAG/Awesome-RAG
   - RAGç›¸å…³èµ„æºåˆé›†

2. **LangChain RAGç¤ºä¾‹**
   ```bash
   git clone https://github.com/langchain-ai/langchain
   cd langchain/templates/rag-*
   ```

---

## ğŸ—ºï¸ åç»­å­¦ä¹ è·¯çº¿

### å®Œæˆé˜¶æ®µ1åï¼Œæ¥ä¸‹æ¥å­¦ä»€ä¹ˆï¼Ÿ

```
é˜¶æ®µ1ï¼ˆå½“å‰ï¼‰
  â†“
äº†è§£æ ¸å¿ƒæ¦‚å¿µ âœ…
  â†“
é˜¶æ®µ2ï¼šæ ‡å‡†RAG
  - å­¦ä¹ LangChainæ¡†æ¶
  - æ¥å…¥Milvus/ChromaDB
  - æ–‡æ¡£è§£æï¼ˆPDFã€Wordï¼‰
  - ä¼˜åŒ–æ£€ç´¢æ•ˆæœ
  â†“
é˜¶æ®µ3ï¼šé«˜çº§ç‰¹æ€§
  - å¤šè½®å¯¹è¯
  - æµå¼è¾“å‡º
  - Agentèƒ½åŠ›
  â†“
é˜¶æ®µ4ï¼šç”Ÿäº§éƒ¨ç½²
  - APIæœåŠ¡åŒ–
  - æ€§èƒ½ä¼˜åŒ–
  - ç›‘æ§å’Œæ—¥å¿—
```

### æ¨èçš„å­¦ä¹ é¡ºåº

1. **ç¬¬1å‘¨ï¼šé˜¶æ®µ1**
   - è·‘é€šæœ¬æ–‡æ¡£çš„ä»£ç 
   - å®Œæˆä»»åŠ¡1å’Œä»»åŠ¡2
   - ç†è§£RAGçš„æ ¸å¿ƒåŸç†

2. **ç¬¬2å‘¨ï¼šé˜¶æ®µ2**
   - å­¦ä¹ LangChainåŸºç¡€
   - æ¥å…¥å‘é‡æ•°æ®åº“
   - å¤„ç†æ›´å¤æ‚çš„æ–‡æ¡£

3. **ç¬¬3-4å‘¨ï¼šå®æˆ˜é¡¹ç›®**
   - é€‰æ‹©ä¸€ä¸ªçœŸå®åœºæ™¯ï¼ˆå¦‚ä¸ªäººçŸ¥è¯†åº“ï¼‰
   - å®Œæ•´å®ç°ä¸€ä¸ªRAGåº”ç”¨
   - éƒ¨ç½²å¹¶å®é™…ä½¿ç”¨

---

## ğŸ’¡ å…³é”®è¦ç‚¹æ€»ç»“

### âœ… RAGçš„æ ¸å¿ƒåªæœ‰5æ­¥

1. **æ–‡æ¡£åŠ è½½** â†’ è¯»å–æ–‡æ¡£
2. **æ–‡æ¡£åˆ†å—** â†’ åˆ‡æˆå°æ®µ
3. **ç”Ÿæˆå‘é‡** â†’ Embeddingï¼ˆä½¿ç”¨æ™ºè°±AI embedding-2ï¼‰
4. **å‘é‡æ£€ç´¢** â†’ æ‰¾ç›¸ä¼¼æ–‡æ¡£
5. **LLMç”Ÿæˆ** â†’ åŸºäºæ–‡æ¡£å›ç­”ï¼ˆä½¿ç”¨æ™ºè°±AI glm-4ï¼‰

### âœ… æœ€å°å¯è¿è¡Œç³»ç»Ÿéœ€è¦

- âœ… PythonåŸºç¡€
- âœ… æ™ºè°±AI APIå¯†é’¥ï¼ˆæ³¨å†Œå³é€å…è´¹é¢åº¦ï¼‰
- âœ… 200è¡Œä»£ç 
- âœ… åŠå¤©æ—¶é—´

### âœ… ä¸éœ€è¦ï¼ˆåˆæœŸï¼‰

- âŒ å¤æ‚çš„å‘é‡æ•°æ®åº“
- âŒ LangChainæ¡†æ¶
- âŒ ç”Ÿäº§çº§éƒ¨ç½²
- âŒ åˆ†å¸ƒå¼æ¶æ„

### âœ… å­¦ä¹ å»ºè®®

1. **å…ˆè·‘é€šï¼Œå†ä¼˜åŒ–**
   - ä¸è¦ä¸€å¼€å§‹å°±è¿½æ±‚å®Œç¾
   - å…ˆå®ç°æœ€ç®€ç‰ˆæœ¬
   - ç†è§£åŸç†åå†æ”¹è¿›

2. **åŠ¨æ‰‹æœ€é‡è¦**
   - çœ‹100éä¸å¦‚å†™1é
   - é‡åˆ°é—®é¢˜ç°æŸ¥æ–‡æ¡£
   - è¾¹åšè¾¹å­¦æ•ˆç‡æœ€é«˜

3. **ä»ç®€å•æ–‡æ¡£å¼€å§‹**
   - å…ˆç”¨txtæ–‡ä»¶æµ‹è¯•
   - ä¸è¦ä¸€å¼€å§‹å°±å¤„ç†PDFã€Word
   - æ–‡æ¡£å†…å®¹è¦å°‘ï¼ˆå‡ åƒå­—å³å¯ï¼‰

---

## ğŸ¯ ä¸‹ä¸€æ­¥è¡ŒåŠ¨æ¸…å•

### ä»Šå¤©å°±å¯ä»¥åšçš„ï¼ˆ1-2å°æ—¶ï¼‰

- [ ] åˆ›å»ºé¡¹ç›®ç›®å½•
- [ ] å®‰è£…ä¾èµ–ï¼ˆpip install zhipuai numpy python-dotenvï¼‰
- [ ] æ³¨å†Œæ™ºè°±AIè´¦å·å¹¶è·å–APIå¯†é’¥
- [ ] åˆ›å»º2-3ä¸ªæµ‹è¯•æ–‡æ¡£
- [ ] å¤åˆ¶æœ¬æ–‡æ¡£çš„ä»£ç åˆ° `simple_rag.py`

### æœ¬å‘¨å®Œæˆï¼ˆ2-3å¤©ï¼‰

- [ ] è·‘é€šå®Œæ•´æµç¨‹
- [ ] æµ‹è¯•10ä¸ªä¸åŒé—®é¢˜
- [ ] ç†è§£æ¯è¡Œä»£ç çš„å«ä¹‰
- [ ] å®Œæˆä»»åŠ¡1ï¼ˆåŸºç¡€ç‰ˆï¼‰
- [ ] å°è¯•ä»»åŠ¡2ï¼ˆæ”¹è¿›ç‰ˆï¼‰

### ä¸‹å‘¨ç›®æ ‡ï¼ˆ1å‘¨ï¼‰

- [ ] å­¦ä¹ LangChainåŸºç¡€
- [ ] æ¥å…¥ChromaDB
- [ ] æ”¯æŒPDFæ–‡æ¡£
- [ ] åšä¸€ä¸ªç®€å•çš„Webç•Œé¢

---

## âœ… å‡†å¤‡å¥½å¼€å§‹äº†å—ï¼Ÿ

**ç°åœ¨å°±åŠ¨æ‰‹å§ï¼** ğŸš€

è®°ä½ï¼š
- é‡åˆ°é—®é¢˜å¾ˆæ­£å¸¸ï¼Œå¤šæŸ¥æ–‡æ¡£
- ä»æœ€ç®€å•çš„å¼€å§‹
- æ¯å¤©è¿›æ­¥ä¸€ç‚¹ç‚¹

**ç¥æ‚¨å­¦ä¹ é¡ºåˆ©ï¼** ğŸ’ª

---

## ğŸ“ å®Œæ•´ä»£ç æ–‡ä»¶æ¸…å•

### `simple_rag.py` - å®Œæ•´ä»£ç 

```python
"""
æœ€ç®€RAGç³»ç»Ÿ - å®Œæ•´å®ç°ï¼ˆæ™ºè°±AIç‰ˆæœ¬ï¼‰
simple_rag.py
"""

import os
import numpy as np
from zhipuai import ZhipuAI
from typing import List, Tuple
import json


class DocumentLoader:
    """æ–‡æ¡£åŠ è½½å™¨"""
    
    def load_documents(self, folder_path: str) -> List[str]:
        """ä»æ–‡ä»¶å¤¹åŠ è½½æ‰€æœ‰txtæ–‡æ¡£"""
        documents = []
        
        for filename in os.listdir(folder_path):
            if filename.endswith('.txt'):
                filepath = os.path.join(folder_path, filename)
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()
                    documents.append(content)
                print(f"âœ… åŠ è½½æ–‡æ¡£: {filename}")
        
        return documents
    
    def split_text(self, text: str, chunk_size: int = 500) -> List[str]:
        """å°†æ–‡æœ¬åˆ†å—"""
        chunks = []
        for i in range(0, len(text), chunk_size):
            chunk = text[i:i + chunk_size]
            chunks.append(chunk)
        return chunks


class SimpleVectorStore:
    """ç®€å•çš„å‘é‡å­˜å‚¨ï¼ˆå†…å­˜å­˜å‚¨ï¼‰"""
    
    def __init__(self):
        self.texts = []
        self.embeddings = []
        
    def add(self, text: str, embedding: List[float]):
        """æ·»åŠ æ–‡æœ¬å’Œå‘é‡"""
        self.texts.append(text)
        self.embeddings.append(embedding)
    
    def search(self, query_embedding: List[float], top_k: int = 3) -> List[Tuple[str, float]]:
        """æœç´¢æœ€ç›¸ä¼¼çš„æ–‡æ¡£"""
        if not self.embeddings:
            return []
        
        query_vec = np.array(query_embedding)
        similarities = []
        
        for i, emb in enumerate(self.embeddings):
            emb_vec = np.array(emb)
            similarity = np.dot(query_vec, emb_vec) / (
                np.linalg.norm(query_vec) * np.linalg.norm(emb_vec)
            )
            similarities.append((self.texts[i], float(similarity)))
        
        similarities.sort(key=lambda x: x[1], reverse=True)
        return similarities[:top_k]
    
    def save(self, filepath: str):
        """ä¿å­˜åˆ°æ–‡ä»¶"""
        data = {'texts': self.texts, 'embeddings': self.embeddings}
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False)
        print(f"âœ… å‘é‡åº“å·²ä¿å­˜åˆ°: {filepath}")
    
    def load(self, filepath: str):
        """ä»æ–‡ä»¶åŠ è½½"""
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        self.texts = data['texts']
        self.embeddings = data['embeddings']
        print(f"âœ… å‘é‡åº“å·²åŠ è½½ï¼Œå…± {len(self.texts)} æ¡è®°å½•")


class SimpleRAG:
    """ç®€å•çš„RAGç³»ç»Ÿï¼ˆæ™ºè°±AIç‰ˆæœ¬ï¼‰"""
    
    def __init__(self, api_key: str):
        """åˆå§‹åŒ–"""
        self.client = ZhipuAI(api_key=api_key)
        self.doc_loader = DocumentLoader()
        self.vector_store = SimpleVectorStore()
        print("âœ… SimpleRAG åˆå§‹åŒ–å®Œæˆï¼ˆä½¿ç”¨æ™ºè°±AIï¼‰")
    
    def get_embedding(self, text: str) -> List[float]:
        """è·å–æ–‡æœ¬çš„Embeddingå‘é‡"""
        try:
            response = self.client.embeddings.create(
                model="embedding-2",
                input=text
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"âŒ è·å–Embeddingå¤±è´¥: {e}")
            raise
    
    def index_documents(self, folder_path: str):
        """ç´¢å¼•æ–‡æ¡£ï¼ˆæ„å»ºå‘é‡åº“ï¼‰"""
        print(f"\nğŸ“š å¼€å§‹ç´¢å¼•æ–‡æ¡£...")
        
        documents = self.doc_loader.load_documents(folder_path)
        print(f"âœ… å…±åŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£")
        
        all_chunks = []
        for doc in documents:
            chunks = self.doc_loader.split_text(doc, chunk_size=500)
            all_chunks.extend(chunks)
        print(f"âœ… å…±åˆ†æˆ {len(all_chunks)} ä¸ªæ–‡æœ¬å—")
        
        print("ğŸ”„ æ­£åœ¨ç”Ÿæˆå‘é‡...")
        for i, chunk in enumerate(all_chunks):
            embedding = self.get_embedding(chunk)
            self.vector_store.add(chunk, embedding)
            if (i + 1) % 10 == 0:
                print(f"   è¿›åº¦: {i + 1}/{len(all_chunks)}")
        
        print("âœ… å‘é‡ç”Ÿæˆå®Œæˆï¼")
    
    def query(self, question: str, top_k: int = 3) -> str:
        """æŸ¥è¯¢é—®é¢˜"""
        print(f"\nâ“ é—®é¢˜: {question}")
        
        print("ğŸ”„ æ­£åœ¨æ£€ç´¢ç›¸å…³æ–‡æ¡£...")
        question_embedding = self.get_embedding(question)
        
        results = self.vector_store.search(question_embedding, top_k=top_k)
        
        if not results:
            return "âŒ æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ–‡æ¡£"
        
        print(f"âœ… æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£:")
        for i, (text, score) in enumerate(results):
            print(f"   {i+1}. ç›¸ä¼¼åº¦: {score:.3f} - {text[:50]}...")
        
        context = "\n\n".join([text for text, score in results])
        
        prompt = f"""è¯·åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ã€‚å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯´"æ–‡æ¡£ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯"ã€‚

æ–‡æ¡£å†…å®¹ï¼š
{context}

é—®é¢˜ï¼š{question}

å›ç­”ï¼š"""
        
        print("ğŸ”„ æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ...")
        try:
            response = self.client.chat.completions.create(
                model="glm-4",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7
            )
            answer = response.choices[0].message.content
            return answer
        except Exception as e:
            print(f"âŒ ç”Ÿæˆç­”æ¡ˆå¤±è´¥: {e}")
            return f"ç”Ÿæˆç­”æ¡ˆæ—¶å‡ºé”™: {str(e)}"
```

### `main.py` - ä¸»ç¨‹åº

```python
from simple_rag import SimpleRAG
import os
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ä»ç¯å¢ƒå˜é‡è¯»å–APIå¯†é’¥
api_key = os.getenv('ZHIPUAI_API_KEY')

if not api_key:
    print("âŒ è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® ZHIPUAI_API_KEY")
    exit(1)

# åˆå§‹åŒ–RAG
rag = SimpleRAG(api_key=api_key)

# ç´¢å¼•æ–‡æ¡£
rag.index_documents('documents')

# ä¿å­˜å‘é‡åº“ï¼ˆå¯é€‰ï¼‰
rag.vector_store.save('vector_store.json')

# å¼€å§‹é—®ç­”
while True:
    question = input("\nè¯·è¾“å…¥é—®é¢˜ï¼ˆè¾“å…¥'quit'é€€å‡ºï¼‰: ")
    
    if question.lower() == 'quit':
        break
    
    answer = rag.query(question)
    print(f"\nğŸ’¡ ç­”æ¡ˆ:\n{answer}\n")
    print("-" * 50)
```

### `requirements.txt` - ä¾èµ–

```txt
zhipuai>=2.0.0
numpy>=1.24.0
python-dotenv>=1.0.0
```

### `.env` - é…ç½®æ–‡ä»¶

```bash
ZHIPUAI_API_KEY=your_api_key_here
```

---

**æ–‡æ¡£åˆ›å»ºæ—¶é—´ï¼š** 2025-11-19  
**ä½œè€…ï¼š** AI Assistant  
**ç‰ˆæœ¬ï¼š** 1.0ï¼ˆæ™ºè°±AIä¸“ç”¨ç‰ˆï¼‰

