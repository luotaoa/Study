{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸš€ Transformer vs LangChain vs LangGraph vs RAGFlow\n",
        "\n",
        "## å®Œæ•´å¯¹æ¯”ä¸å®æˆ˜ä»£ç \n",
        "\n",
        "æœ¬æ•™ç¨‹å°†é€šè¿‡å®é™…ä»£ç ï¼Œå±•ç¤ºè¿™å››ä¸ªæŠ€æœ¯çš„ï¼š\n",
        "- âœ… å®šä½å’Œä½œç”¨\n",
        "- âœ… å®é™…ä½¿ç”¨æ–¹æ³•\n",
        "- âœ… é€‚ç”¨åœºæ™¯\n",
        "- âœ… ç›¸äº’å…³ç³»\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“Š æŠ€æœ¯æ ˆå±‚æ¬¡\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  äº§å“å±‚ï¼šRAGFlow (å¼€ç®±å³ç”¨)          â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "              â†‘\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  åº”ç”¨æ¡†æ¶å±‚ï¼šLangChain + LangGraph   â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "              â†‘\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  æ¨¡å‹å±‚ï¼šGPT-4, GLM-4, ...          â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "              â†‘\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  æ¶æ„å±‚ï¼šTransformer                â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1ï¸âƒ£ Transformer - åº•å±‚æ¶æ„\n",
        "\n",
        "### ğŸ¯ å®šä½\n",
        "- **ç±»å‹**ï¼šæ·±åº¦å­¦ä¹ æ¨¡å‹æ¶æ„\n",
        "- **å±‚æ¬¡**ï¼šæœ€åº•å±‚ï¼ˆæŠ€æœ¯åŸç†ï¼‰\n",
        "- **ä½œç”¨**ï¼šç”¨äºæ„å»ºå¤§è¯­è¨€æ¨¡å‹\n",
        "- **æ—¶é—´**ï¼š2017å¹´ï¼ˆGoogle è®ºæ–‡ï¼‰\n",
        "\n",
        "### ğŸ“š æ ¸å¿ƒæ¦‚å¿µ\n",
        "\n",
        "Transformer æ˜¯ä¸€ç§ç¥ç»ç½‘ç»œæ¶æ„ï¼Œä¸»è¦ç‰¹ç‚¹ï¼š\n",
        "1. **è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆSelf-Attentionï¼‰**ï¼šè®©æ¨¡å‹å…³æ³¨è¾“å…¥çš„ä¸åŒéƒ¨åˆ†\n",
        "2. **ä½ç½®ç¼–ç ï¼ˆPositional Encodingï¼‰**ï¼šè®°ä½è¯çš„é¡ºåº\n",
        "3. **ç¼–ç å™¨-è§£ç å™¨ç»“æ„**ï¼šé€‚åˆåºåˆ—åˆ°åºåˆ—çš„ä»»åŠ¡\n",
        "\n",
        "**ç±»æ¯”**ï¼š\n",
        "- Transformer = æ±½è½¦å‘åŠ¨æœºçš„è®¾è®¡å›¾çº¸\n",
        "- GPT-4/GLM-4 = ç”¨è¿™ä¸ªè®¾è®¡é€ å‡ºæ¥çš„å„ç§æ±½è½¦\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ’¡ æ³¨æ„\n",
        "- âŒ **Transformer ä¸æ˜¯ä¸€ä¸ªå¯ä»¥ç›´æ¥è°ƒç”¨çš„å·¥å…·**\n",
        "- âœ… **å®ƒæ˜¯ä¸€ç§æŠ€æœ¯åŸç†/æ¶æ„**\n",
        "- âœ… **æ‰€æœ‰ç°ä»£ LLM éƒ½åŸºäºå®ƒ**\n",
        "- ğŸ“– **å­¦ä¹ å®ƒæ˜¯ä¸ºäº†ç†è§£åº•å±‚åŸç†**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Transformer æ ¸å¿ƒç»„ä»¶ç¤ºä¾‹ï¼ˆç®€åŒ–ç‰ˆï¼‰\n",
        "\n",
        "æ³¨æ„ï¼šè¿™æ˜¯æ•™å­¦ä»£ç ï¼Œå±•ç¤º Transformer çš„æ ¸å¿ƒæ€æƒ³\n",
        "å®é™…çš„ GPT-4/GLM-4 è¦å¤æ‚å¾—å¤š\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# ========== 1. è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆSelf-Attentionï¼‰==========\n",
        "\n",
        "def softmax(x):\n",
        "    \"\"\"Softmax å‡½æ•°\"\"\"\n",
        "    exp_x = np.exp(x - np.max(x))\n",
        "    return exp_x / exp_x.sum(axis=-1, keepdims=True)\n",
        "\n",
        "class SimpleSelfAttention:\n",
        "    \"\"\"ç®€åŒ–çš„è‡ªæ³¨æ„åŠ›æœºåˆ¶\"\"\"\n",
        "    \n",
        "    def __init__(self, embed_dim):\n",
        "        self.embed_dim = embed_dim\n",
        "        # åˆå§‹åŒ–æƒé‡çŸ©é˜µ\n",
        "        self.W_q = np.random.randn(embed_dim, embed_dim) * 0.01  # Query\n",
        "        self.W_k = np.random.randn(embed_dim, embed_dim) * 0.01  # Key\n",
        "        self.W_v = np.random.randn(embed_dim, embed_dim) * 0.01  # Value\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x: (seq_len, embed_dim) - è¾“å…¥åºåˆ—\n",
        "        \n",
        "        è¿”å›: (seq_len, embed_dim) - åŠ æƒåçš„è¾“å‡º\n",
        "        \"\"\"\n",
        "        # è®¡ç®— Query, Key, Value\n",
        "        Q = x @ self.W_q  # (seq_len, embed_dim)\n",
        "        K = x @ self.W_k  # (seq_len, embed_dim)\n",
        "        V = x @ self.W_v  # (seq_len, embed_dim)\n",
        "        \n",
        "        # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°\n",
        "        # Q @ K.T è¡¨ç¤ºæ¯ä¸ªè¯å¯¹å…¶ä»–è¯çš„å…³æ³¨ç¨‹åº¦\n",
        "        scores = Q @ K.T / np.sqrt(self.embed_dim)  # (seq_len, seq_len)\n",
        "        \n",
        "        # Softmax å½’ä¸€åŒ–\n",
        "        attention_weights = softmax(scores)  # (seq_len, seq_len)\n",
        "        \n",
        "        # åŠ æƒæ±‚å’Œ\n",
        "        output = attention_weights @ V  # (seq_len, embed_dim)\n",
        "        \n",
        "        return output, attention_weights\n",
        "\n",
        "\n",
        "# ========== 2. å®é™…æ¼”ç¤º ==========\n",
        "\n",
        "# å‡è®¾æˆ‘ä»¬æœ‰3ä¸ªè¯ï¼Œæ¯ä¸ªè¯ç”¨4ç»´å‘é‡è¡¨ç¤º\n",
        "seq_len = 3\n",
        "embed_dim = 4\n",
        "\n",
        "# è¾“å…¥ï¼š3ä¸ªè¯çš„embedding\n",
        "# æ¯”å¦‚ [\"æˆ‘\", \"çˆ±\", \"AI\"] çš„å‘é‡è¡¨ç¤º\n",
        "x = np.random.randn(seq_len, embed_dim)\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"ğŸ“ è¾“å…¥åºåˆ—ï¼ˆ3ä¸ªè¯çš„å‘é‡è¡¨ç¤ºï¼‰ï¼š\")\n",
        "print(x)\n",
        "print(f\"å½¢çŠ¶: {x.shape}\")\n",
        "\n",
        "# åˆ›å»ºæ³¨æ„åŠ›å±‚\n",
        "attention = SimpleSelfAttention(embed_dim)\n",
        "\n",
        "# å‰å‘ä¼ æ’­\n",
        "output, weights = attention.forward(x)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"ğŸ¯ æ³¨æ„åŠ›æƒé‡çŸ©é˜µï¼ˆæ¯ä¸ªè¯å¯¹å…¶ä»–è¯çš„å…³æ³¨ç¨‹åº¦ï¼‰ï¼š\")\n",
        "print(weights)\n",
        "print(f\"å½¢çŠ¶: {weights.shape}\")\n",
        "\n",
        "print(\"\\nè§£è¯»ï¼š\")\n",
        "print(f\"  - weights[0] = {weights[0]} \")\n",
        "print(f\"    è¡¨ç¤ºç¬¬1ä¸ªè¯å¯¹æ‰€æœ‰è¯çš„å…³æ³¨åˆ†å¸ƒ\")\n",
        "print(f\"  - weights[0][1] = {weights[0][1]:.4f}\")\n",
        "print(f\"    è¡¨ç¤ºç¬¬1ä¸ªè¯å¯¹ç¬¬2ä¸ªè¯çš„å…³æ³¨ç¨‹åº¦\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"âœ¨ è¾“å‡ºåºåˆ—ï¼ˆç»è¿‡æ³¨æ„åŠ›åŠ æƒåçš„å‘é‡ï¼‰ï¼š\")\n",
        "print(output)\n",
        "print(f\"å½¢çŠ¶: {output.shape}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"ğŸ” å…³é”®ç†è§£ï¼š\")\n",
        "print(\"1. è¾“å…¥ x: æ¯ä¸ªè¯çš„åŸå§‹å‘é‡\")\n",
        "print(\"2. æ³¨æ„åŠ›æƒé‡: æ¯ä¸ªè¯åº”è¯¥å…³æ³¨å“ªäº›è¯\")\n",
        "print(\"3. è¾“å‡º: èåˆäº†ä¸Šä¸‹æ–‡ä¿¡æ¯çš„æ–°å‘é‡\")\n",
        "print(\"\\nè¿™å°±æ˜¯ Transformer çš„æ ¸å¿ƒé­”æ³•ï¼âœ¨\")\n",
        "print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ“Š Transformer çš„å®é™…åº”ç”¨\n",
        "\n",
        "Transformer æ¶æ„è®­ç»ƒå‡ºçš„è‘—åæ¨¡å‹ï¼š\n",
        "\n",
        "| æ¨¡å‹ | å…¬å¸ | ç‰¹ç‚¹ | å‚æ•°é‡ |\n",
        "|------|------|------|--------|\n",
        "| **GPT-4** | OpenAI | ç”Ÿæˆå¼ã€é€šç”¨èƒ½åŠ›å¼º | ~1.7ä¸‡äº¿ |\n",
        "| **GLM-4** | æ™ºè°±AI | ä¸­æ–‡ä¼˜åŒ–ã€å¯¹è¯èƒ½åŠ›å¼º | æœªå…¬å¼€ |\n",
        "| **BERT** | Google | åŒå‘ç¼–ç ã€ç†è§£èƒ½åŠ›å¼º | 3.4äº¿ |\n",
        "| **LLaMA** | Meta | å¼€æºã€å¯æœ¬åœ°è¿è¡Œ | 70äº¿-650äº¿ |\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ¯ æ€»ç»“\n",
        "\n",
        "**Transformer çš„å®šä½ï¼š**\n",
        "- âœ… æŠ€æœ¯æ¶æ„/è®¾è®¡å›¾\n",
        "- âœ… å­¦ä¹ å®ƒæ˜¯ä¸ºäº†ç†è§£åŸç†\n",
        "- âŒ ä¸æ˜¯ç›´æ¥ä½¿ç”¨çš„å·¥å…·\n",
        "\n",
        "**ä½•æ—¶éœ€è¦äº†è§£ Transformerï¼š**\n",
        "1. ğŸ”¬ æƒ³ç†è§£ LLM çš„å·¥ä½œåŸç†\n",
        "2. ğŸ“ åš AI ç›¸å…³ç ”ç©¶\n",
        "3. ğŸ”§ å¾®è°ƒæˆ–è®­ç»ƒè‡ªå·±çš„æ¨¡å‹\n",
        "4. ğŸ“š é¢è¯• AI ç®—æ³•å²—ä½\n",
        "\n",
        "**å¯¹äºåº”ç”¨å¼€å‘è€…ï¼š**\n",
        "- ğŸ“– äº†è§£åŸºæœ¬æ¦‚å¿µå³å¯\n",
        "- ğŸš€ é‡ç‚¹æ”¾åœ¨å¦‚ä½•ä½¿ç”¨ LLMï¼ˆä¸‹é¢çš„ LangChainï¼‰\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2ï¸âƒ£ LangChain - åº”ç”¨å¼€å‘æ¡†æ¶\n",
        "\n",
        "### ğŸ¯ å®šä½\n",
        "- **ç±»å‹**ï¼šPython/JavaScript å¼€å‘æ¡†æ¶\n",
        "- **å±‚æ¬¡**ï¼šåº”ç”¨å±‚ï¼ˆè°ƒç”¨ LLM çš„å·¥å…·ï¼‰\n",
        "- **ä½œç”¨**ï¼šç®€åŒ– LLM åº”ç”¨å¼€å‘\n",
        "- **æ—¶é—´**ï¼š2022å¹´\n",
        "\n",
        "### ğŸ“š æ ¸å¿ƒåŠŸèƒ½\n",
        "\n",
        "LangChain æä¾›çš„ä¸»è¦ç»„ä»¶ï¼š\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  LangChain å·¥å…·ç®±                   â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚  ğŸ“„ Document Loaders                â”‚  åŠ è½½å„ç§æ ¼å¼çš„æ–‡æ¡£\n",
        "â”‚  âœ‚ï¸  Text Splitters                 â”‚  æ™ºèƒ½æ–‡æœ¬åˆ†å‰²\n",
        "â”‚  ğŸ—ƒï¸  Vector Stores                  â”‚  å‘é‡å­˜å‚¨é›†æˆ\n",
        "â”‚  ğŸ”— Chains                          â”‚  ç»„åˆå¤šä¸ªæ­¥éª¤\n",
        "â”‚  ğŸ¤– Agents                          â”‚  æ™ºèƒ½å†³ç­–\n",
        "â”‚  ğŸ’¾ Memory                          â”‚  å¯¹è¯å†å²ç®¡ç†\n",
        "â”‚  ğŸ”Œ Integrations                    â”‚  é›†æˆå„ç§ LLM API\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n",
        "\n",
        "**ç±»æ¯”**ï¼š\n",
        "- Transformer = æ±½è½¦å‘åŠ¨æœºè®¾è®¡\n",
        "- LLM = é€ å¥½çš„æ±½è½¦\n",
        "- **LangChain = æ±½è½¦ä¿®ç†å·¥å…·ç®±** â­\n",
        "- å¸®ä½ å¿«é€Ÿç»„è£…ã€ç»´ä¿®ã€å®šåˆ¶æ±½è½¦\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ¨ ä¸¤ç§ä½¿ç”¨æ–¹å¼\n",
        "\n",
        "#### æ–¹å¼1ï¸âƒ£ï¼šå®Œæ•´ä½¿ç”¨ï¼ˆé»‘ç›’ï¼‰\n",
        "\n",
        "```python\n",
        "from langchain import LLMChain\n",
        "\n",
        "# ä¸€è¡Œæå®šï¼Œä½†ä¸çŸ¥é“å†…éƒ¨åŸç†\n",
        "chain = LLMChain.from_config(config)\n",
        "result = chain.run(input)\n",
        "```\n",
        "\n",
        "#### æ–¹å¼2ï¸âƒ£ï¼šæ¨¡å—åŒ–ä½¿ç”¨ï¼ˆæ¨èï¼‰â­â­â­â­â­\n",
        "\n",
        "```python\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# åªç”¨æŸä¸ªå·¥å…·ï¼Œå…¶ä»–è‡ªå·±å†™\n",
        "splitter = RecursiveCharacterTextSplitter()\n",
        "chunks = splitter.split_text(text)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "ç¤ºä¾‹1ï¼šä¸ç”¨ LangChain - è‡ªå·±å®ç° RAGï¼ˆå­¦ä¹ é˜¶æ®µï¼‰\n",
        "\n",
        "ä¼˜ç‚¹ï¼šâœ… å®Œå…¨ç†è§£åŸç†\n",
        "ç¼ºç‚¹ï¼šâŒ åŠŸèƒ½ç®€é™‹\n",
        "\"\"\"\n",
        "\n",
        "class SimpleRAG:\n",
        "    \"\"\"å®Œå…¨è‡ªå·±å®ç°çš„ç®€å• RAG\"\"\"\n",
        "    \n",
        "    def __init__(self, api_key):\n",
        "        self.api_key = api_key\n",
        "        self.texts = []\n",
        "        self.embeddings = []\n",
        "    \n",
        "    def split_text(self, text):\n",
        "        \"\"\"ç®€å•çš„æ–‡æœ¬åˆ†å‰²\"\"\"\n",
        "        # é—®é¢˜ï¼šå¯èƒ½æˆªæ–­å¥å­\n",
        "        chunks = []\n",
        "        chunk_size = 500\n",
        "        for i in range(0, len(text), chunk_size):\n",
        "            chunks.append(text[i:i+chunk_size])\n",
        "        return chunks\n",
        "    \n",
        "    def add_document(self, text):\n",
        "        \"\"\"æ·»åŠ æ–‡æ¡£\"\"\"\n",
        "        chunks = self.split_text(text)\n",
        "        for chunk in chunks:\n",
        "            # è·å– embeddingï¼ˆçœç•¥å®ç°ï¼‰\n",
        "            embedding = self.get_embedding(chunk)\n",
        "            self.texts.append(chunk)\n",
        "            self.embeddings.append(embedding)\n",
        "    \n",
        "    def get_embedding(self, text):\n",
        "        \"\"\"è°ƒç”¨ API è·å–å‘é‡\"\"\"\n",
        "        # å®é™…è°ƒç”¨ API...\n",
        "        pass\n",
        "    \n",
        "    def search(self, query, top_k=3):\n",
        "        \"\"\"æ£€ç´¢ç›¸å…³æ–‡æ¡£\"\"\"\n",
        "        # è®¡ç®—ç›¸ä¼¼åº¦...\n",
        "        pass\n",
        "    \n",
        "    def query(self, question):\n",
        "        \"\"\"é—®ç­”\"\"\"\n",
        "        # æ£€ç´¢ + ç”Ÿæˆ...\n",
        "        pass\n",
        "\n",
        "\n",
        "# è¯„ä»·ï¼š\n",
        "print(\"âœ… ä¼˜ç‚¹ï¼šå®Œå…¨ç†è§£æ¯ä¸€æ­¥\")\n",
        "print(\"âŒ ç¼ºç‚¹ï¼šæ–‡æœ¬åˆ†å‰²å¤ªç®€å•ï¼Œå¯èƒ½æˆªæ–­å¥å­\")\n",
        "print(\"ğŸ¯ é€‚åˆï¼šå­¦ä¹ é˜¶æ®µ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "ç¤ºä¾‹2ï¼šæ··åˆä½¿ç”¨ LangChain - åªç”¨ä¸“ä¸šå·¥å…·ï¼ˆä¼˜åŒ–é˜¶æ®µï¼‰â­â­â­â­â­\n",
        "\n",
        "ä¼˜ç‚¹ï¼šâœ… æ ¸å¿ƒé€»è¾‘è‡ªå·±æŒæ§ + ç»†èŠ‚å·¥å…·ç”¨ä¸“ä¸šçš„\n",
        "æ¨èåº¦ï¼šâ­â­â­â­â­\n",
        "\"\"\"\n",
        "\n",
        "# é¦–å…ˆéœ€è¦å®‰è£…\n",
        "# pip install langchain\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "class ImprovedRAG:\n",
        "    \"\"\"æ··åˆæ–¹æ¡ˆï¼šæ ¸å¿ƒè‡ªå·±å†™ï¼Œå·¥å…·ç”¨ LangChain\"\"\"\n",
        "    \n",
        "    def __init__(self, api_key):\n",
        "        self.api_key = api_key\n",
        "        self.texts = []\n",
        "        self.embeddings = []\n",
        "        \n",
        "        # ğŸ”¥ åªç”¨ LangChain çš„æ–‡æœ¬åˆ†å‰²å™¨\n",
        "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=500,          # å—å¤§å°\n",
        "            chunk_overlap=50,        # é‡å 50ä¸ªå­—ç¬¦\n",
        "            separators=[             # æ™ºèƒ½åˆ†éš”ç¬¦\n",
        "                \"\\n\\n\",              # ä¼˜å…ˆæŒ‰æ®µè½\n",
        "                \"\\n\",                # å…¶æ¬¡æŒ‰è¡Œ\n",
        "                \"ã€‚\", \"ï¼\", \"ï¼Ÿ\",    # ä¸­æ–‡æ ‡ç‚¹\n",
        "                \".\", \"!\", \"?\",       # è‹±æ–‡æ ‡ç‚¹\n",
        "                \" \",                 # ç©ºæ ¼\n",
        "                \"\"                   # æœ€åæ‰æŒ‰å­—ç¬¦\n",
        "            ]\n",
        "        )\n",
        "    \n",
        "    def add_document(self, text):\n",
        "        \"\"\"æ·»åŠ æ–‡æ¡£\"\"\"\n",
        "        # ğŸ”¥ ç”¨ LangChain çš„ä¸“ä¸šåˆ†å‰²å™¨\n",
        "        chunks = self.text_splitter.split_text(text)\n",
        "        \n",
        "        # å…¶ä»–æ­¥éª¤è‡ªå·±å®ç°\n",
        "        for chunk in chunks:\n",
        "            embedding = self.get_embedding(chunk)\n",
        "            self.texts.append(chunk)\n",
        "            self.embeddings.append(embedding)\n",
        "        \n",
        "        print(f\"âœ… æ–‡æ¡£å·²åˆ†å‰²æˆ {len(chunks)} ä¸ªå—\")\n",
        "        return chunks\n",
        "    \n",
        "    def get_embedding(self, text):\n",
        "        \"\"\"è°ƒç”¨ API è·å–å‘é‡ï¼ˆè‡ªå·±å®ç°ï¼‰\"\"\"\n",
        "        # å®é™…è°ƒç”¨ API...\n",
        "        pass\n",
        "    \n",
        "    def search(self, query, top_k=3):\n",
        "        \"\"\"æ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼ˆè‡ªå·±å®ç°ï¼‰\"\"\"\n",
        "        # è®¡ç®—ç›¸ä¼¼åº¦...\n",
        "        pass\n",
        "    \n",
        "    def query(self, question):\n",
        "        \"\"\"é—®ç­”ï¼ˆè‡ªå·±å®ç°ï¼‰\"\"\"\n",
        "        # æ£€ç´¢ + ç”Ÿæˆ...\n",
        "        pass\n",
        "\n",
        "\n",
        "# ========== æ¼”ç¤º LangChain æ–‡æœ¬åˆ†å‰²çš„ä¼˜åŠ¿ ==========\n",
        "\n",
        "# æµ‹è¯•æ–‡æœ¬\n",
        "test_text = \"\"\"\n",
        "äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹\n",
        "\n",
        "äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ã€‚å®ƒä¼å›¾äº†è§£æ™ºèƒ½çš„å®è´¨ï¼Œå¹¶ç”Ÿäº§å‡ºä¸€ç§æ–°çš„èƒ½ä»¥äººç±»æ™ºèƒ½ç›¸ä¼¼çš„æ–¹å¼åšå‡ºååº”çš„æ™ºèƒ½æœºå™¨ã€‚\n",
        "\n",
        "è¯¥é¢†åŸŸçš„ç ”ç©¶åŒ…æ‹¬æœºå™¨äººã€è¯­è¨€è¯†åˆ«ã€å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œä¸“å®¶ç³»ç»Ÿç­‰ã€‚äººå·¥æ™ºèƒ½ä»è¯ç”Ÿä»¥æ¥ï¼Œç†è®ºå’ŒæŠ€æœ¯æ—¥ç›Šæˆç†Ÿï¼Œåº”ç”¨é¢†åŸŸä¹Ÿä¸æ–­æ‰©å¤§ã€‚\n",
        "\n",
        "å¯ä»¥è®¾æƒ³ï¼Œæœªæ¥äººå·¥æ™ºèƒ½å¸¦æ¥çš„ç§‘æŠ€äº§å“ï¼Œå°†ä¼šæ˜¯äººç±»æ™ºæ…§çš„\"å®¹å™¨\"ã€‚äººå·¥æ™ºèƒ½å¯ä»¥å¯¹äººçš„æ„è¯†ã€æ€ç»´çš„ä¿¡æ¯è¿‡ç¨‹è¿›è¡Œæ¨¡æ‹Ÿã€‚\n",
        "\"\"\"\n",
        "\n",
        "# åˆ›å»ºå®ä¾‹\n",
        "rag = ImprovedRAG(api_key=\"your-key\")\n",
        "\n",
        "# ä½¿ç”¨ LangChain åˆ†å‰²æ–‡æœ¬\n",
        "chunks = rag.add_document(test_text)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ğŸ“„ åˆ†å‰²ç»“æœï¼ˆæ¯ä¸ªå—ï¼‰ï¼š\")\n",
        "print(\"=\" * 60)\n",
        "for i, chunk in enumerate(chunks, 1):\n",
        "    print(f\"\\nå— {i}:\")\n",
        "    print(f\"  å†…å®¹: {chunk[:50]}...\")\n",
        "    print(f\"  é•¿åº¦: {len(chunk)} å­—ç¬¦\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ğŸ¯ å¯¹æ¯”æ€»ç»“ï¼š\")\n",
        "print(\"=\" * 60)\n",
        "print(\"ç®€å•åˆ†å‰²ï¼ˆè‡ªå·±å†™ï¼‰ï¼š\")\n",
        "print(\"  âŒ å¯èƒ½åœ¨å¥å­ä¸­é—´æˆªæ–­\")\n",
        "print(\"  âŒ è¯­ä¹‰å®Œæ•´æ€§å·®\")\n",
        "print(\"\\nLangChain åˆ†å‰²ï¼ˆä¸“ä¸šå·¥å…·ï¼‰ï¼š\")\n",
        "print(\"  âœ… ä¼˜å…ˆåœ¨æ®µè½/å¥å­è¾¹ç•Œåˆ†å‰²\")\n",
        "print(\"  âœ… ä¿æŒè¯­ä¹‰å®Œæ•´\")\n",
        "print(\"  âœ… æœ‰é‡å ï¼Œé¿å…ä¿¡æ¯ä¸¢å¤±\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "ç¤ºä¾‹3ï¼šå®Œæ•´ä½¿ç”¨ LangChain - ä¸€ç«™å¼æ–¹æ¡ˆï¼ˆç”Ÿäº§é˜¶æ®µï¼‰\n",
        "\n",
        "ä¼˜ç‚¹ï¼šâœ… å¼€å‘é€Ÿåº¦å¿«ã€åŠŸèƒ½å®Œå–„\n",
        "ç¼ºç‚¹ï¼šâŒ é»‘ç›’ï¼Œä¸æ˜“ç†è§£å†…éƒ¨é€»è¾‘\n",
        "\"\"\"\n",
        "\n",
        "# éœ€è¦å®‰è£…æ›´å¤šç»„ä»¶\n",
        "# pip install langchain langchain-openai chromadb\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.llms import ChatOpenAI\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# ========== å®Œæ•´çš„ LangChain RAG ç³»ç»Ÿ ==========\n",
        "\n",
        "def create_full_langchain_rag(file_path, api_key):\n",
        "    \"\"\"\n",
        "    ä½¿ç”¨ LangChain å®Œæ•´å·¥å…·é“¾åˆ›å»º RAG\n",
        "    \n",
        "    å‡ è¡Œä»£ç æå®šæ‰€æœ‰äº‹æƒ…ï¼\n",
        "    \"\"\"\n",
        "    \n",
        "    # 1. åŠ è½½æ–‡æ¡£\n",
        "    loader = TextLoader(file_path)\n",
        "    documents = loader.load()\n",
        "    \n",
        "    # 2. åˆ†å‰²æ–‡æ¡£\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=500,\n",
        "        chunk_overlap=50\n",
        "    )\n",
        "    splits = text_splitter.split_documents(documents)\n",
        "    \n",
        "    # 3. åˆ›å»ºå‘é‡æ•°æ®åº“\n",
        "    vectorstore = Chroma.from_documents(\n",
        "        documents=splits,\n",
        "        embedding=OpenAIEmbeddings(api_key=api_key)\n",
        "    )\n",
        "    \n",
        "    # 4. åˆ›å»ºé—®ç­”é“¾\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=ChatOpenAI(api_key=api_key, model=\"gpt-4\"),\n",
        "        retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "    )\n",
        "    \n",
        "    return qa_chain\n",
        "\n",
        "\n",
        "# ä½¿ç”¨ç¤ºä¾‹ï¼ˆä¼ªä»£ç ï¼‰\n",
        "\"\"\"\n",
        "# åˆ›å»º RAG ç³»ç»Ÿ\n",
        "qa = create_full_langchain_rag(\"documents.txt\", \"your-api-key\")\n",
        "\n",
        "# ç›´æ¥æé—®\n",
        "answer = qa.run(\"äººå·¥æ™ºèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ\")\n",
        "print(answer)\n",
        "\"\"\"\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸ¯ LangChain å®Œæ•´æ–¹æ¡ˆçš„ç‰¹ç‚¹ï¼š\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nâœ… ä¼˜ç‚¹ï¼š\")\n",
        "print(\"  1. ä»£ç æç®€ï¼ˆ5-10è¡Œæå®šï¼‰\")\n",
        "print(\"  2. åŠŸèƒ½å®Œå–„ï¼ˆåŒ…å«æ‰€æœ‰æœ€ä½³å®è·µï¼‰\")\n",
        "print(\"  3. æ˜“äºç»´æŠ¤ï¼ˆç¤¾åŒºæ”¯æŒå¥½ï¼‰\")\n",
        "print(\"  4. å¿«é€Ÿè¿­ä»£ï¼ˆé€‚åˆç”Ÿäº§ç¯å¢ƒï¼‰\")\n",
        "\n",
        "print(\"\\nâŒ ç¼ºç‚¹ï¼š\")\n",
        "print(\"  1. é»‘ç›’æ“ä½œï¼ˆä¸çŸ¥é“å†…éƒ¨ç»†èŠ‚ï¼‰\")\n",
        "print(\"  2. å­¦ä¹ æ›²çº¿ï¼ˆéœ€è¦ç†è§£ LangChain çš„æ¦‚å¿µï¼‰\")\n",
        "print(\"  3. çµæ´»æ€§ç¨ä½ï¼ˆå—æ¡†æ¶é™åˆ¶ï¼‰\")\n",
        "\n",
        "print(\"\\nğŸ¯ é€‚åˆåœºæ™¯ï¼š\")\n",
        "print(\"  â€¢ å¿«é€ŸåŸå‹éªŒè¯\")\n",
        "print(\"  â€¢ ç”Ÿäº§ç¯å¢ƒä¸Šçº¿\")\n",
        "print(\"  â€¢ å›¢é˜Ÿåä½œå¼€å‘\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3ï¸âƒ£ LangGraph - å¤æ‚ Agent å¼€å‘å·¥å…·\n",
        "\n",
        "### ğŸ¯ å®šä½\n",
        "- **ç±»å‹**ï¼šLangChain çš„å­é¡¹ç›®/æ‰©å±•\n",
        "- **å±‚æ¬¡**ï¼šåº”ç”¨å±‚ï¼ˆä¸“æ³¨äº Agentï¼‰\n",
        "- **ä½œç”¨**ï¼šæ„å»ºå¤æ‚çš„ã€æœ‰çŠ¶æ€çš„ Agent å·¥ä½œæµ\n",
        "- **æ—¶é—´**ï¼š2024å¹´\n",
        "\n",
        "### ğŸ“š æ ¸å¿ƒæ¦‚å¿µ\n",
        "\n",
        "LangGraph ç”¨**å›¾ï¼ˆGraphï¼‰**çš„æ–¹å¼å®šä¹‰ Agent çš„å·¥ä½œæµç¨‹ï¼š\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  ä¼ ç»Ÿ LangChain (çº¿æ€§æµç¨‹)          â”‚\n",
        "â”‚                                     â”‚\n",
        "â”‚  [è¾“å…¥] â†’ [å¤„ç†] â†’ [è¾“å‡º]          â”‚\n",
        "â”‚                                     â”‚\n",
        "â”‚  é—®é¢˜ï¼šä¸æ”¯æŒå¾ªç¯ã€æ¡ä»¶åˆ†æ”¯         â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "\n",
        "           â†“ å‡çº§\n",
        "\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  LangGraph (å›¾ç»“æ„æµç¨‹)             â”‚\n",
        "â”‚                                     â”‚\n",
        "â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚\n",
        "â”‚        â”‚  è§„åˆ’   â”‚                 â”‚\n",
        "â”‚        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                 â”‚\n",
        "â”‚             â”‚                      â”‚\n",
        "â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”              â”‚\n",
        "â”‚      â†“             â†“              â”‚\n",
        "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚\n",
        "â”‚  â”‚ æœç´¢  â”‚    â”‚ è®¡ç®—   â”‚         â”‚\n",
        "â”‚  â””â”€â”€â”€â”¬â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜         â”‚\n",
        "â”‚      â”‚             â”‚              â”‚\n",
        "â”‚      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜              â”‚\n",
        "â”‚             â†“                      â”‚\n",
        "â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚\n",
        "â”‚        â”‚  æ±‡æ€»   â”‚â†â”€â”€â” å¾ªç¯      â”‚\n",
        "â”‚        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â”‚           â”‚\n",
        "â”‚             â”‚         â”‚           â”‚\n",
        "â”‚             â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚\n",
        "â”‚             â†“                      â”‚\n",
        "â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚\n",
        "â”‚        â”‚  è¾“å‡º   â”‚                â”‚\n",
        "â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n",
        "\n",
        "**ç±»æ¯”**ï¼š\n",
        "- LangChain = å•çº¿ç¨‹ç¨‹åºï¼ˆé¡ºåºæ‰§è¡Œï¼‰\n",
        "- **LangGraph = çŠ¶æ€æœº/æµç¨‹å›¾**ï¼ˆæ¡ä»¶åˆ†æ”¯ã€å¾ªç¯ï¼‰\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”‘ å…³é”®ç‰¹æ€§\n",
        "\n",
        "1. **çŠ¶æ€ç®¡ç†**ï¼šè®°ä½æ‰§è¡Œè¿‡ç¨‹ä¸­çš„çŠ¶æ€\n",
        "2. **æ¡ä»¶åˆ†æ”¯**ï¼šæ ¹æ®ç»“æœå†³å®šä¸‹ä¸€æ­¥\n",
        "3. **å¾ªç¯æ”¯æŒ**ï¼šå¯ä»¥è¿”å›å‰é¢çš„èŠ‚ç‚¹\n",
        "4. **å¹¶è¡Œæ‰§è¡Œ**ï¼šå¤šä¸ªèŠ‚ç‚¹åŒæ—¶è¿è¡Œ\n",
        "5. **å¯è§†åŒ–**ï¼šæµç¨‹å›¾ä¸€ç›®äº†ç„¶\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "LangGraph ç¤ºä¾‹ï¼šæ„å»ºä¸€ä¸ªæ™ºèƒ½ç ”ç©¶åŠ©æ‰‹\n",
        "\n",
        "åœºæ™¯ï¼š\n",
        "  ç”¨æˆ·é—®ä¸€ä¸ªé—®é¢˜\n",
        "    â†“\n",
        "  Agent å†³å®šæ˜¯æœç´¢è¿˜æ˜¯è®¡ç®—\n",
        "    â†“\n",
        "  æ‰§è¡Œç›¸åº”æ“ä½œ\n",
        "    â†“\n",
        "  å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œé‡æ–°æœç´¢\n",
        "    â†“\n",
        "  æœ€ç»ˆç”Ÿæˆå›ç­”\n",
        "\"\"\"\n",
        "\n",
        "# éœ€è¦å®‰è£…\n",
        "# pip install langgraph\n",
        "\n",
        "from typing import TypedDict, Annotated\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# ========== 1. å®šä¹‰çŠ¶æ€ ==========\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    \"\"\"Agent çš„çŠ¶æ€\"\"\"\n",
        "    question: str              # ç”¨æˆ·é—®é¢˜\n",
        "    context: str              # æ”¶é›†åˆ°çš„ä¸Šä¸‹æ–‡\n",
        "    answer: str               # æœ€ç»ˆç­”æ¡ˆ\n",
        "    next_action: str          # ä¸‹ä¸€æ­¥åšä»€ä¹ˆ\n",
        "    iteration: int            # å½“å‰è¿­ä»£æ¬¡æ•°\n",
        "\n",
        "\n",
        "# ========== 2. å®šä¹‰å„ä¸ªèŠ‚ç‚¹ï¼ˆæ­¥éª¤ï¼‰==========\n",
        "\n",
        "def planner(state: AgentState) -> AgentState:\n",
        "    \"\"\"è§„åˆ’èŠ‚ç‚¹ï¼šå†³å®šä¸‹ä¸€æ­¥åšä»€ä¹ˆ\"\"\"\n",
        "    question = state[\"question\"]\n",
        "    \n",
        "    # ç®€å•çš„å†³ç­–é€»è¾‘\n",
        "    if \"è®¡ç®—\" in question or \"å¤šå°‘\" in question:\n",
        "        next_action = \"calculate\"\n",
        "    else:\n",
        "        next_action = \"search\"\n",
        "    \n",
        "    print(f\"ğŸ¤” è§„åˆ’ï¼šé—®é¢˜ç±»å‹ â†’ {next_action}\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"next_action\": next_action\n",
        "    }\n",
        "\n",
        "\n",
        "def searcher(state: AgentState) -> AgentState:\n",
        "    \"\"\"æœç´¢èŠ‚ç‚¹ï¼šæ¨¡æ‹Ÿæœç´¢ç›¸å…³ä¿¡æ¯\"\"\"\n",
        "    question = state[\"question\"]\n",
        "    \n",
        "    # æ¨¡æ‹Ÿæœç´¢ç»“æœ\n",
        "    search_result = f\"å…³äº'{question}'çš„æœç´¢ç»“æœï¼šè¿™æ˜¯ç›¸å…³ä¿¡æ¯...\"\n",
        "    \n",
        "    print(f\"ğŸ” æœç´¢ï¼šæ‰¾åˆ°ç›¸å…³ä¿¡æ¯\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"context\": state.get(\"context\", \"\") + \"\\n\" + search_result,\n",
        "        \"iteration\": state.get(\"iteration\", 0) + 1\n",
        "    }\n",
        "\n",
        "\n",
        "def calculator(state: AgentState) -> AgentState:\n",
        "    \"\"\"è®¡ç®—èŠ‚ç‚¹ï¼šæ¨¡æ‹Ÿæ‰§è¡Œè®¡ç®—\"\"\"\n",
        "    question = state[\"question\"]\n",
        "    \n",
        "    # æ¨¡æ‹Ÿè®¡ç®—\n",
        "    calc_result = \"è®¡ç®—ç»“æœï¼š42\"\n",
        "    \n",
        "    print(f\"ğŸ§® è®¡ç®—ï¼šæ‰§è¡Œè®¡ç®—\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"context\": state.get(\"context\", \"\") + \"\\n\" + calc_result,\n",
        "        \"iteration\": state.get(\"iteration\", 0) + 1\n",
        "    }\n",
        "\n",
        "\n",
        "def checker(state: AgentState) -> AgentState:\n",
        "    \"\"\"æ£€æŸ¥èŠ‚ç‚¹ï¼šåˆ¤æ–­ä¿¡æ¯æ˜¯å¦è¶³å¤Ÿ\"\"\"\n",
        "    context = state.get(\"context\", \"\")\n",
        "    iteration = state.get(\"iteration\", 0)\n",
        "    \n",
        "    # ç®€å•çš„åˆ¤æ–­é€»è¾‘\n",
        "    if len(context) > 50 or iteration >= 2:\n",
        "        next_action = \"generate\"\n",
        "    else:\n",
        "        next_action = \"search\"  # éœ€è¦æ›´å¤šä¿¡æ¯\n",
        "    \n",
        "    print(f\"âœ… æ£€æŸ¥ï¼šä¿¡æ¯{'è¶³å¤Ÿ' if next_action == 'generate' else 'ä¸è¶³'}\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"next_action\": next_action\n",
        "    }\n",
        "\n",
        "\n",
        "def generator(state: AgentState) -> AgentState:\n",
        "    \"\"\"ç”ŸæˆèŠ‚ç‚¹ï¼šç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ\"\"\"\n",
        "    question = state[\"question\"]\n",
        "    context = state.get(\"context\", \"\")\n",
        "    \n",
        "    # æ¨¡æ‹Ÿç”Ÿæˆç­”æ¡ˆ\n",
        "    answer = f\"åŸºäºæ”¶é›†çš„ä¿¡æ¯ï¼Œå¯¹äºé—®é¢˜'{question}'çš„å›ç­”æ˜¯ï¼š{context[:50]}...\"\n",
        "    \n",
        "    print(f\"ğŸ’¡ ç”Ÿæˆï¼šå®Œæˆå›ç­”\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"answer\": answer,\n",
        "        \"next_action\": \"end\"\n",
        "    }\n",
        "\n",
        "\n",
        "# ========== 3. è·¯ç”±å‡½æ•°ï¼ˆå†³å®šæµç¨‹èµ°å‘ï¼‰==========\n",
        "\n",
        "def route_after_planner(state: AgentState) -> str:\n",
        "    \"\"\"è§„åˆ’åçš„è·¯ç”±\"\"\"\n",
        "    next_action = state[\"next_action\"]\n",
        "    if next_action == \"search\":\n",
        "        return \"searcher\"\n",
        "    else:\n",
        "        return \"calculator\"\n",
        "\n",
        "\n",
        "def route_after_checker(state: AgentState) -> str:\n",
        "    \"\"\"æ£€æŸ¥åçš„è·¯ç”±\"\"\"\n",
        "    next_action = state[\"next_action\"]\n",
        "    if next_action == \"generate\":\n",
        "        return \"generator\"\n",
        "    else:\n",
        "        return \"searcher\"  # ç»§ç»­æœç´¢\n",
        "\n",
        "\n",
        "# ========== 4. æ„å»ºå›¾ï¼ˆå·¥ä½œæµï¼‰==========\n",
        "\n",
        "def create_agent_graph():\n",
        "    \"\"\"åˆ›å»º LangGraph å·¥ä½œæµ\"\"\"\n",
        "    \n",
        "    # åˆ›å»ºå›¾\n",
        "    workflow = StateGraph(AgentState)\n",
        "    \n",
        "    # æ·»åŠ èŠ‚ç‚¹\n",
        "    workflow.add_node(\"planner\", planner)\n",
        "    workflow.add_node(\"searcher\", searcher)\n",
        "    workflow.add_node(\"calculator\", calculator)\n",
        "    workflow.add_node(\"checker\", checker)\n",
        "    workflow.add_node(\"generator\", generator)\n",
        "    \n",
        "    # è®¾ç½®å…¥å£\n",
        "    workflow.set_entry_point(\"planner\")\n",
        "    \n",
        "    # æ·»åŠ æ¡ä»¶è¾¹ï¼ˆæ ¹æ®çŠ¶æ€å†³å®šæµç¨‹ï¼‰\n",
        "    workflow.add_conditional_edges(\n",
        "        \"planner\",\n",
        "        route_after_planner,\n",
        "        {\n",
        "            \"searcher\": \"searcher\",\n",
        "            \"calculator\": \"calculator\"\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    # æ·»åŠ æ™®é€šè¾¹\n",
        "    workflow.add_edge(\"searcher\", \"checker\")\n",
        "    workflow.add_edge(\"calculator\", \"checker\")\n",
        "    \n",
        "    # æ·»åŠ æ¡ä»¶è¾¹ï¼ˆå¯èƒ½å¾ªç¯ï¼‰\n",
        "    workflow.add_conditional_edges(\n",
        "        \"checker\",\n",
        "        route_after_checker,\n",
        "        {\n",
        "            \"searcher\": \"searcher\",  # å¾ªç¯å›å»\n",
        "            \"generator\": \"generator\"\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    # ç»“æŸ\n",
        "    workflow.add_edge(\"generator\", END)\n",
        "    \n",
        "    # ç¼–è¯‘å›¾\n",
        "    app = workflow.compile()\n",
        "    \n",
        "    return app\n",
        "\n",
        "\n",
        "# ========== 5. è¿è¡Œç¤ºä¾‹ ==========\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸš€ LangGraph Agent å·¥ä½œæµæ¼”ç¤º\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# åˆ›å»º Agent\n",
        "agent = create_agent_graph()\n",
        "\n",
        "# æµ‹è¯•é—®é¢˜\n",
        "test_question = \"äººå·¥æ™ºèƒ½çš„åº”ç”¨æœ‰å“ªäº›ï¼Ÿ\"\n",
        "\n",
        "print(f\"\\nâ“ ç”¨æˆ·é—®é¢˜: {test_question}\\n\")\n",
        "\n",
        "# åˆå§‹çŠ¶æ€\n",
        "initial_state = {\n",
        "    \"question\": test_question,\n",
        "    \"context\": \"\",\n",
        "    \"answer\": \"\",\n",
        "    \"next_action\": \"\",\n",
        "    \"iteration\": 0\n",
        "}\n",
        "\n",
        "# è¿è¡Œ Agent\n",
        "result = agent.invoke(initial_state)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"âœ¨ æœ€ç»ˆç»“æœï¼š\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"ç­”æ¡ˆ: {result['answer']}\")\n",
        "print(f\"è¿­ä»£æ¬¡æ•°: {result['iteration']}\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4ï¸âƒ£ RAGFlow - å®Œæ•´çš„ RAG äº§å“\n",
        "\n",
        "### ğŸ¯ å®šä½\n",
        "- **ç±»å‹**ï¼šå¼€æºçš„ RAG å¼•æ“/å®Œæ•´äº§å“\n",
        "- **å±‚æ¬¡**ï¼šäº§å“å±‚ï¼ˆæœ€ä¸Šå±‚ï¼‰\n",
        "- **ä½œç”¨**ï¼šæä¾›å¼€ç®±å³ç”¨çš„ RAG è§£å†³æ–¹æ¡ˆ\n",
        "- **æ—¶é—´**ï¼š2024å¹´\n",
        "\n",
        "### ğŸ“š æ ¸å¿ƒç‰¹ç‚¹\n",
        "\n",
        "RAGFlow æ˜¯ä¸€ä¸ª**å®Œæ•´çš„åº”ç”¨ç³»ç»Ÿ**ï¼Œä¸ä»…ä»…æ˜¯ä»£ç åº“ï¼š\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  RAGFlow å®Œæ•´ç³»ç»Ÿ                        â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚  ğŸ–¥ï¸  Web UI                             â”‚  ç½‘é¡µç®¡ç†ç•Œé¢\n",
        "â”‚  ğŸ“„ æ–‡æ¡£ç®¡ç†                             â”‚  ä¸Šä¼ ã€ç»„ç»‡æ–‡æ¡£\n",
        "â”‚  âœ‚ï¸  æ™ºèƒ½åˆ†å—                            â”‚  å¤šç§åˆ†å—ç­–ç•¥\n",
        "â”‚  ğŸ—ƒï¸  å‘é‡å­˜å‚¨                            â”‚  å†…ç½®å‘é‡æ•°æ®åº“\n",
        "â”‚  ğŸ” æ£€ç´¢å¼•æ“                             â”‚  é«˜çº§æ£€ç´¢ç®—æ³•\n",
        "â”‚  ğŸ’¬ å¯¹è¯ç®¡ç†                             â”‚  å¤šè½®å¯¹è¯\n",
        "â”‚  ğŸ“Š åˆ†æé¢æ¿                             â”‚  æ€§èƒ½ç›‘æ§\n",
        "â”‚  ğŸ”Œ API æ¥å£                             â”‚  ç¨‹åºåŒ–è°ƒç”¨\n",
        "â”‚  ğŸ¨ å¤šæ¨¡æ€æ”¯æŒ                           â”‚  æ–‡æœ¬ã€å›¾ç‰‡ã€PDF\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n",
        "\n",
        "**ç±»æ¯”ï¼š**\n",
        "- LangChain = æ±½è½¦é›¶ä»¶å’Œå·¥å…·ï¼ˆéœ€è¦ç»„è£…ï¼‰\n",
        "- LangGraph = é«˜çº§å·¥å…·ï¼ˆå¤æ‚ç»„è£…ï¼‰\n",
        "- **RAGFlow = å®Œæ•´çš„æ±½è½¦**ï¼ˆå¼€ç®±å³ç”¨ï¼‰\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸš€ éƒ¨ç½²å’Œä½¿ç”¨\n",
        "\n",
        "RAGFlow æ˜¯é€šè¿‡ Docker éƒ¨ç½²çš„å®Œæ•´åº”ç”¨ï¼š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "RAGFlow éƒ¨ç½²å’Œä½¿ç”¨æŒ‡å—\n",
        "\n",
        "æ³¨æ„ï¼šè¿™ä¸æ˜¯ Python ä»£ç ï¼Œè€Œæ˜¯éƒ¨ç½²æ­¥éª¤\n",
        "\"\"\"\n",
        "\n",
        "# ========== 1. éƒ¨ç½² RAGFlow ==========\n",
        "\n",
        "\"\"\"\n",
        "# ç¬¬ä¸€æ­¥ï¼šå…‹éš†ä»“åº“\n",
        "git clone https://github.com/infiniflow/ragflow.git\n",
        "cd ragflow\n",
        "\n",
        "# ç¬¬äºŒæ­¥ï¼šå¯åŠ¨æœåŠ¡ï¼ˆDockerï¼‰\n",
        "docker-compose up -d\n",
        "\n",
        "# ç¬¬ä¸‰æ­¥ï¼šè®¿é—® Web UI\n",
        "æµè§ˆå™¨æ‰“å¼€: http://localhost\n",
        "\n",
        "# å°±è¿™ä¹ˆç®€å•ï¼ä¸éœ€è¦å†™ä»£ç \n",
        "\"\"\"\n",
        "\n",
        "# ========== 2. é€šè¿‡ Web UI ä½¿ç”¨ï¼ˆé›¶ä»£ç ï¼‰==========\n",
        "\n",
        "\"\"\"\n",
        "åœ¨æµè§ˆå™¨ä¸­æ“ä½œï¼š\n",
        "\n",
        "1. åˆ›å»ºçŸ¥è¯†åº“\n",
        "   - ç‚¹å‡»\"æ–°å»ºçŸ¥è¯†åº“\"\n",
        "   - è¾“å…¥åç§°å’Œæè¿°\n",
        "\n",
        "2. ä¸Šä¼ æ–‡æ¡£\n",
        "   - æ”¯æŒ PDF, Word, TXT, Markdown\n",
        "   - æ”¯æŒå¤šä¸ªæ–‡ä»¶æ‰¹é‡ä¸Šä¼ \n",
        "\n",
        "3. é…ç½®åˆ†å—ç­–ç•¥\n",
        "   - é€‰æ‹©åˆ†å—å¤§å°\n",
        "   - é€‰æ‹©é‡å å¤§å°\n",
        "   - é€‰æ‹©åˆ†å—æ–¹å¼ï¼ˆæ™ºèƒ½/å›ºå®šï¼‰\n",
        "\n",
        "4. åˆ›å»ºå¯¹è¯\n",
        "   - é€‰æ‹©çŸ¥è¯†åº“\n",
        "   - é€‰æ‹© LLM æ¨¡å‹\n",
        "   - å¼€å§‹å¯¹è¯\n",
        "\n",
        "å®Œå…¨ä¸éœ€è¦å†™ä»£ç ï¼\n",
        "\"\"\"\n",
        "\n",
        "# ========== 3. é€šè¿‡ API ä½¿ç”¨ï¼ˆç¼–ç¨‹æ–¹å¼ï¼‰==========\n",
        "\n",
        "import requests\n",
        "import json\n",
        "\n",
        "def use_ragflow_api():\n",
        "    \"\"\"é€šè¿‡ API è°ƒç”¨ RAGFlow\"\"\"\n",
        "    \n",
        "    # RAGFlow API ç«¯ç‚¹\n",
        "    base_url = \"http://localhost:9380\"\n",
        "    \n",
        "    # 1. åˆ›å»ºå¯¹è¯ä¼šè¯\n",
        "    session_response = requests.post(\n",
        "        f\"{base_url}/api/new_conversation\",\n",
        "        json={\n",
        "            \"kb_id\": \"your_knowledge_base_id\",\n",
        "            \"llm_id\": \"your_llm_id\"\n",
        "        }\n",
        "    )\n",
        "    session_id = session_response.json()[\"session_id\"]\n",
        "    \n",
        "    # 2. å‘é€é—®é¢˜\n",
        "    query_response = requests.post(\n",
        "        f\"{base_url}/api/completion\",\n",
        "        json={\n",
        "            \"session_id\": session_id,\n",
        "            \"question\": \"äººå·¥æ™ºèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ\"\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    answer = query_response.json()[\"answer\"]\n",
        "    \n",
        "    return answer\n",
        "\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸš€ RAGFlow ä½¿ç”¨æ–¹å¼\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\næ–¹å¼1ï¸âƒ£ï¼šWeb UIï¼ˆæ¨èï¼‰â­â­â­â­â­\")\n",
        "print(\"  âœ… å®Œå…¨é›¶ä»£ç \")\n",
        "print(\"  âœ… å¯è§†åŒ–æ“ä½œ\")\n",
        "print(\"  âœ… é€‚åˆéæŠ€æœ¯äººå‘˜\")\n",
        "print(\"  âœ… å¿«é€ŸåŸå‹éªŒè¯\")\n",
        "\n",
        "print(\"\\næ–¹å¼2ï¸âƒ£ï¼šAPI è°ƒç”¨\")\n",
        "print(\"  âœ… ç¼–ç¨‹æ§åˆ¶\")\n",
        "print(\"  âœ… é›†æˆåˆ°ç°æœ‰ç³»ç»Ÿ\")\n",
        "print(\"  âœ… è‡ªåŠ¨åŒ–æµç¨‹\")\n",
        "\n",
        "print(\"\\næ–¹å¼3ï¸âƒ£ï¼šå†…åµŒä½¿ç”¨\")\n",
        "print(\"  âœ… ä¿®æ”¹æºä»£ç \")\n",
        "print(\"  âœ… æ·±åº¦å®šåˆ¶\")\n",
        "print(\"  âš ï¸  éœ€è¦äº†è§£ä»£ç ç»“æ„\")\n",
        "\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ“Š RAGFlow çš„å†…éƒ¨æ¶æ„\n",
        "\n",
        "RAGFlow å†…éƒ¨å…¶å®ä¹Ÿä½¿ç”¨äº†å¾ˆå¤šæŠ€æœ¯ï¼š\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  RAGFlow äº§å“                       â”‚\n",
        "â”‚                                     â”‚\n",
        "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\n",
        "â”‚  â”‚  Web UI (å‰ç«¯)                â”‚ â”‚\n",
        "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\n",
        "â”‚             â”‚                       â”‚\n",
        "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\n",
        "â”‚  â”‚  Backend API (åç«¯)           â”‚ â”‚\n",
        "â”‚  â”‚  â€¢ å¯èƒ½ä½¿ç”¨ LangChain         â”‚ â”‚\n",
        "â”‚  â”‚  â€¢ å¯èƒ½ä½¿ç”¨ LangGraph         â”‚ â”‚\n",
        "â”‚  â”‚  â€¢ å‘é‡æ•°æ®åº“ (Milvus/ES)    â”‚ â”‚\n",
        "â”‚  â”‚  â€¢ æ–‡æ¡£å¤„ç†å¼•æ“               â”‚ â”‚\n",
        "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\n",
        "â”‚             â†“                       â”‚\n",
        "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\n",
        "â”‚  â”‚  è°ƒç”¨ LLM API                 â”‚ â”‚\n",
        "â”‚  â”‚  (GPT-4, GLM-4, ...)         â”‚ â”‚\n",
        "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ¯ RAGFlow vs è‡ªå·±å†™ä»£ç \n",
        "\n",
        "| ç»´åº¦ | è‡ªå·±å†™ | LangChain | RAGFlow |\n",
        "|------|-------|-----------|---------|\n",
        "| **å¼€å‘æ—¶é—´** | æ•°å‘¨ | æ•°å¤© | æ•°å°æ—¶ |\n",
        "| **ä»£ç é‡** | 1000+ è¡Œ | 100+ è¡Œ | 0 è¡Œ |\n",
        "| **UI ç•Œé¢** | éœ€è¦è‡ªå·±å¼€å‘ | éœ€è¦è‡ªå·±å¼€å‘ | âœ… å†…ç½® |\n",
        "| **æ–‡æ¡£ç®¡ç†** | éœ€è¦è‡ªå·±å®ç° | éœ€è¦è‡ªå·±å®ç° | âœ… å†…ç½® |\n",
        "| **æ€§èƒ½ç›‘æ§** | éœ€è¦è‡ªå·±å®ç° | éœ€è¦è‡ªå·±å®ç° | âœ… å†…ç½® |\n",
        "| **å®šåˆ¶çµæ´»æ€§** | â­â­â­â­â­ | â­â­â­â­ | â­â­ |\n",
        "| **å­¦ä¹ æˆæœ¬** | é«˜ | ä¸­ | ä½ |\n",
        "| **é€‚åˆäººç¾¤** | å¼€å‘è€… | å¼€å‘è€… | æ‰€æœ‰äºº |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ å››è€…å…³ç³»å®Œæ•´æ€»ç»“\n",
        "\n",
        "### 1ï¸âƒ£ å±‚æ¬¡å…³ç³»\n",
        "\n",
        "```\n",
        "ä»æŠ½è±¡åˆ°å…·ä½“ï¼š\n",
        "\n",
        "Transformer (æŠ€æœ¯åŸç†)\n",
        "    â†“ è®­ç»ƒå‡º\n",
        "å¤§è¯­è¨€æ¨¡å‹ (GPT-4, GLM-4, ...)\n",
        "    â†“ è°ƒç”¨\n",
        "LangChain (å¼€å‘æ¡†æ¶)\n",
        "    â”œâ”€ LangGraph (å¤æ‚ Agent æ‰©å±•)\n",
        "    â””â”€ å¼€å‘å‡º\n",
        "RAGFlow (å®Œæ•´äº§å“)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 2ï¸âƒ£ ç±»æ¯”å…³ç³»\n",
        "\n",
        "| æŠ€æœ¯ | ç±»æ¯” | è¯´æ˜ |\n",
        "|------|------|------|\n",
        "| **Transformer** | ğŸ—ï¸ å»ºç­‘è®¾è®¡åŸç† | ç†è®º/æ¶æ„ |\n",
        "| **GPT-4/GLM-4** | ğŸ¢ å»ºå¥½çš„å¤§æ¥¼ | è®­ç»ƒå¥½çš„æ¨¡å‹ |\n",
        "| **LangChain** | ğŸ”§ è£…ä¿®å·¥å…·ç®± | å¼€å‘æ¡†æ¶ |\n",
        "| **LangGraph** | ğŸ¨ è®¾è®¡è½¯ä»¶ | é«˜çº§å·¥å…· |\n",
        "| **RAGFlow** | ğŸ  ç²¾è£…ä¿®æˆ¿å­ | å®Œæ•´äº§å“ |\n",
        "\n",
        "---\n",
        "\n",
        "### 3ï¸âƒ£ ä½¿ç”¨åœºæ™¯å¯¹æ¯”\n",
        "\n",
        "| åœºæ™¯ | æ¨èæ–¹æ¡ˆ | åŸå›  |\n",
        "|------|---------|------|\n",
        "| å­¦ä¹  AI åŸç† | Transformer | ç†è§£åº•å±‚ |\n",
        "| å­¦ä¹  RAG å¼€å‘ | è‡ªå·±å®ç° | æŒæ¡æ ¸å¿ƒ |\n",
        "| ä¼˜åŒ– RAG æ€§èƒ½ | LangChain éƒ¨åˆ†å·¥å…· | å¹³è¡¡ç†è§£å’Œæ•ˆæœ |\n",
        "| å¼€å‘ç®€å• RAG | LangChain | å¿«é€Ÿé«˜æ•ˆ |\n",
        "| å¼€å‘å¤æ‚ Agent | LangGraph | æ”¯æŒå¤æ‚æµç¨‹ |\n",
        "| å¿«é€Ÿä¸Šçº¿äº§å“ | RAGFlow | é›¶ä»£ç éƒ¨ç½² |\n",
        "| éæŠ€æœ¯äººå‘˜ä½¿ç”¨ | RAGFlow | å¯è§†åŒ–æ“ä½œ |\n",
        "\n",
        "---\n",
        "\n",
        "### 4ï¸âƒ£ å­¦ä¹ è·¯å¾„å»ºè®®\n",
        "\n",
        "```\n",
        "æ¨èå­¦ä¹ é¡ºåºï¼ˆåº”ç”¨å¼€å‘è€…ï¼‰ï¼š\n",
        "\n",
        "ç¬¬1é˜¶æ®µï¼šç†è§£åŸç† (1-2å‘¨)\n",
        "  â”œâ”€ äº†è§£ Transformer åŸºæœ¬æ¦‚å¿µ\n",
        "  â”œâ”€ è‡ªå·±å®ç°ç®€å• RAG\n",
        "  â””â”€ ç†è§£æ¯ä¸€æ­¥çš„åŸç†\n",
        "\n",
        "ç¬¬2é˜¶æ®µï¼šä¼˜åŒ–å®è·µ (2-3å‘¨)\n",
        "  â”œâ”€ å¼•å…¥ LangChain çš„å•ä¸ªå·¥å…·\n",
        "  â”œâ”€ å¦‚ï¼šRecursiveCharacterTextSplitter\n",
        "  â””â”€ æ ¸å¿ƒé€»è¾‘ä»è‡ªå·±æŒæ§\n",
        "\n",
        "ç¬¬3é˜¶æ®µï¼šä½“éªŒäº§å“ (1å‘¨)\n",
        "  â”œâ”€ éƒ¨ç½² RAGFlow\n",
        "  â”œâ”€ çœ‹çœ‹å®Œæ•´äº§å“çš„åŠŸèƒ½\n",
        "  â””â”€ å¯¹æ¯”è‡ªå·±å®ç°çš„å·®è·\n",
        "\n",
        "ç¬¬4é˜¶æ®µï¼šé«˜çº§å¼€å‘ (æ ¹æ®éœ€è¦)\n",
        "  â”œâ”€ å¦‚æœéœ€è¦å¤æ‚ Agent â†’ å­¦ä¹  LangGraph\n",
        "  â””â”€ å¦‚æœéœ€è¦å¿«é€Ÿä¸Šçº¿ â†’ ä½¿ç”¨å®Œæ•´ LangChain\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "å¯è§†åŒ–å¯¹æ¯”ï¼šå››ä¸ªæŠ€æœ¯çš„ç‰¹å¾é›·è¾¾å›¾\n",
        "\"\"\"\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# è®¾ç½®ä¸­æ–‡å­—ä½“\n",
        "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# å®šä¹‰è¯„ä»·ç»´åº¦\n",
        "categories = ['å­¦ä¹ éš¾åº¦', 'å¼€å‘é€Ÿåº¦', 'çµæ´»æ€§', 'åŠŸèƒ½å®Œæ•´æ€§', 'å®šåˆ¶åŒ–èƒ½åŠ›']\n",
        "N = len(categories)\n",
        "\n",
        "# å„æŠ€æœ¯åœ¨å„ç»´åº¦çš„å¾—åˆ†ï¼ˆ1-5åˆ†ï¼‰\n",
        "# æ³¨æ„ï¼šå­¦ä¹ éš¾åº¦æ˜¯è¶Šä½è¶Šå¥½ï¼Œè¿™é‡Œçš„åˆ†æ•°è¡¨ç¤º\"æ˜“å­¦ç¨‹åº¦\"\n",
        "transformer_scores = [2, 1, 5, 1, 5]  # éš¾å­¦ï¼Œæ…¢ï¼Œçµæ´»ï¼ŒåŠŸèƒ½å°‘ï¼Œé«˜å®šåˆ¶\n",
        "langchain_scores = [3, 4, 4, 3, 4]    # ä¸­ç­‰ï¼Œè¾ƒå¿«ï¼Œè¾ƒçµæ´»ï¼ŒåŠŸèƒ½ä¸­ç­‰ï¼Œè¾ƒé«˜å®šåˆ¶\n",
        "langgraph_scores = [2, 3, 5, 4, 5]    # è¾ƒéš¾ï¼Œä¸­ç­‰ï¼Œå¾ˆçµæ´»ï¼ŒåŠŸèƒ½è¾ƒå¤šï¼Œé«˜å®šåˆ¶\n",
        "ragflow_scores = [5, 5, 2, 5, 2]      # æ˜“å­¦ï¼Œå¿«ï¼Œä½çµæ´»ï¼ŒåŠŸèƒ½å®Œæ•´ï¼Œä½å®šåˆ¶\n",
        "\n",
        "# åˆ›å»ºé›·è¾¾å›¾\n",
        "angles = np.linspace(0, 2 * np.pi, N, endpoint=False).tolist()\n",
        "angles += angles[:1]  # é—­åˆ\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
        "\n",
        "# ç»˜åˆ¶æ¯ä¸ªæŠ€æœ¯çš„é›·è¾¾å›¾\n",
        "def plot_radar(scores, label, color, linestyle='-'):\n",
        "    scores += scores[:1]  # é—­åˆ\n",
        "    ax.plot(angles, scores, 'o-', linewidth=2, label=label, color=color, linestyle=linestyle)\n",
        "    ax.fill(angles, scores, alpha=0.15, color=color)\n",
        "\n",
        "plot_radar(transformer_scores, 'Transformer', '#FF6B6B', '--')\n",
        "plot_radar(langchain_scores, 'LangChain', '#4ECDC4', '-')\n",
        "plot_radar(langgraph_scores, 'LangGraph', '#95E1D3', '-.')\n",
        "plot_radar(ragflow_scores, 'RAGFlow', '#FFD93D', '-')\n",
        "\n",
        "# è®¾ç½®å›¾è¡¨\n",
        "ax.set_xticks(angles[:-1])\n",
        "ax.set_xticklabels(categories, size=12)\n",
        "ax.set_ylim(0, 5)\n",
        "ax.set_yticks([1, 2, 3, 4, 5])\n",
        "ax.set_yticklabels(['1', '2', '3', '4', '5'], size=10)\n",
        "ax.grid(True)\n",
        "\n",
        "# æ·»åŠ å›¾ä¾‹\n",
        "plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=12)\n",
        "\n",
        "plt.title('å››ä¸ªæŠ€æœ¯çš„ç‰¹å¾å¯¹æ¯”é›·è¾¾å›¾', size=16, pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ğŸ“Š é›·è¾¾å›¾è§£è¯»ï¼š\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nğŸ”´ Transformerï¼ˆçº¢è‰²è™šçº¿ï¼‰ï¼š\")\n",
        "print(\"  â€¢ å­¦ä¹ éš¾åº¦é«˜ï¼ˆéœ€è¦æ·±åº¦å­¦ä¹ åŸºç¡€ï¼‰\")\n",
        "print(\"  â€¢ å¼€å‘é€Ÿåº¦æ…¢ï¼ˆéœ€è¦ä»é›¶è®­ç»ƒï¼‰\")\n",
        "print(\"  â€¢ çµæ´»æ€§å’Œå®šåˆ¶åŒ–èƒ½åŠ›æœ€å¼º\")\n",
        "\n",
        "print(\"\\nğŸ”µ LangChainï¼ˆé’è‰²å®çº¿ï¼‰ï¼š\")\n",
        "print(\"  â€¢ å„æ–¹é¢æ¯”è¾ƒå¹³è¡¡\")\n",
        "print(\"  â€¢ é€‚åˆå¤§å¤šæ•°åº”ç”¨å¼€å‘åœºæ™¯\")\n",
        "print(\"  â€¢ å­¦ä¹ æˆæœ¬å’Œæ”¶ç›Šæ¯”è¾ƒåˆç†\")\n",
        "\n",
        "print(\"\\nğŸŸ¢ LangGraphï¼ˆç»¿è‰²ç‚¹åˆ’çº¿ï¼‰ï¼š\")\n",
        "print(\"  â€¢ åŠŸèƒ½å¼ºå¤§ä½†å­¦ä¹ æ›²çº¿é™¡å³­\")\n",
        "print(\"  â€¢ é€‚åˆå¤æ‚çš„ Agent ç³»ç»Ÿ\")\n",
        "print(\"  â€¢ é«˜çµæ´»æ€§å’Œå®šåˆ¶åŒ–èƒ½åŠ›\")\n",
        "\n",
        "print(\"\\nğŸŸ¡ RAGFlowï¼ˆé»„è‰²å®çº¿ï¼‰ï¼š\")\n",
        "print(\"  â€¢ å­¦ä¹ æœ€ç®€å•ã€å¼€å‘æœ€å¿«\")\n",
        "print(\"  â€¢ åŠŸèƒ½æœ€å®Œæ•´ï¼ˆå¼€ç®±å³ç”¨ï¼‰\")\n",
        "print(\"  â€¢ ä½†çµæ´»æ€§å’Œå®šåˆ¶åŒ–è¾ƒä½\")\n",
        "\n",
        "print(\"\\nğŸ¯ é€‰æ‹©å»ºè®®ï¼š\")\n",
        "print(\"  â€¢ å­¦ä¹ é˜¶æ®µ â†’ Transformer æ¦‚å¿µ + è‡ªå·±å®ç°\")\n",
        "print(\"  â€¢ ä¼˜åŒ–é˜¶æ®µ â†’ LangChain éƒ¨åˆ†å·¥å…·\")\n",
        "print(\"  â€¢ å¤æ‚ Agent â†’ LangGraph\")\n",
        "print(\"  â€¢ å¿«é€Ÿä¸Šçº¿ â†’ RAGFlow\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "å¯è§†åŒ–ï¼šæŠ€æœ¯æ ˆæ¼”è¿›æ—¶é—´çº¿\n",
        "\"\"\"\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from datetime import datetime\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "# æ—¶é—´çº¿æ•°æ®\n",
        "events = [\n",
        "    {\n",
        "        'year': 2017,\n",
        "        'name': 'Transformer',\n",
        "        'description': 'Google å‘å¸ƒè®ºæ–‡\\n\"Attention is All You Need\"',\n",
        "        'color': '#FF6B6B',\n",
        "        'y': 4\n",
        "    },\n",
        "    {\n",
        "        'year': 2018,\n",
        "        'name': 'BERT / GPT-1',\n",
        "        'description': 'Google BERT\\nOpenAI GPT-1',\n",
        "        'color': '#F06292',\n",
        "        'y': 3.2\n",
        "    },\n",
        "    {\n",
        "        'year': 2020,\n",
        "        'name': 'GPT-3',\n",
        "        'description': 'OpenAI GPT-3\\n1750äº¿å‚æ•°',\n",
        "        'color': '#BA68C8',\n",
        "        'y': 2.4\n",
        "    },\n",
        "    {\n",
        "        'year': 2022,\n",
        "        'name': 'LangChain',\n",
        "        'description': 'LangChain æ¡†æ¶å‘å¸ƒ\\nç®€åŒ– LLM åº”ç”¨å¼€å‘',\n",
        "        'color': '#4ECDC4',\n",
        "        'y': 1.6\n",
        "    },\n",
        "    {\n",
        "        'year': 2023,\n",
        "        'name': 'GPT-4 / GLM',\n",
        "        'description': 'GPT-4 å‘å¸ƒ\\næ™ºè°± GLM ç³»åˆ—',\n",
        "        'color': '#9575CD',\n",
        "        'y': 2.8\n",
        "    },\n",
        "    {\n",
        "        'year': 2024,\n",
        "        'name': 'LangGraph\\nRAGFlow',\n",
        "        'description': 'LangGraph å‘å¸ƒ\\nRAGFlow å¼€æº',\n",
        "        'color': '#FFD93D',\n",
        "        'y': 1.2\n",
        "    }\n",
        "]\n",
        "\n",
        "# ç»˜åˆ¶æ—¶é—´è½´\n",
        "ax.plot([2017, 2024], [0, 0], 'k-', linewidth=3, zorder=1)\n",
        "\n",
        "# ç»˜åˆ¶æ¯ä¸ªäº‹ä»¶\n",
        "for event in events:\n",
        "    year = event['year']\n",
        "    y = event['y']\n",
        "    \n",
        "    # ç»˜åˆ¶è¿æ¥çº¿\n",
        "    ax.plot([year, year], [0, y], color=event['color'], linewidth=2, linestyle='--', alpha=0.6)\n",
        "    \n",
        "    # ç»˜åˆ¶äº‹ä»¶ç‚¹\n",
        "    ax.scatter(year, 0, s=200, c=event['color'], zorder=3, edgecolors='white', linewidths=2)\n",
        "    \n",
        "    # ç»˜åˆ¶äº‹ä»¶æ¡†\n",
        "    rect = patches.FancyBboxPatch(\n",
        "        (year - 0.3, y - 0.15),\n",
        "        0.6, 0.8,\n",
        "        boxstyle=\"round,pad=0.1\",\n",
        "        linewidth=2,\n",
        "        edgecolor=event['color'],\n",
        "        facecolor='white',\n",
        "        zorder=2\n",
        "    )\n",
        "    ax.add_patch(rect)\n",
        "    \n",
        "    # æ·»åŠ æ–‡æœ¬\n",
        "    ax.text(year, y + 0.25, event['name'], \n",
        "            ha='center', va='bottom', fontsize=11, fontweight='bold',\n",
        "            color=event['color'])\n",
        "    ax.text(year, y - 0.05, event['description'], \n",
        "            ha='center', va='top', fontsize=9,\n",
        "            color='#333333')\n",
        "\n",
        "# è®¾ç½®åæ ‡è½´\n",
        "ax.set_xlim(2016, 2025)\n",
        "ax.set_ylim(-0.5, 5)\n",
        "ax.set_xlabel('å¹´ä»½', fontsize=14, fontweight='bold')\n",
        "ax.set_title('AI æŠ€æœ¯æ ˆæ¼”è¿›æ—¶é—´çº¿', fontsize=16, fontweight='bold', pad=20)\n",
        "\n",
        "# éšè— y è½´\n",
        "ax.set_yticks([])\n",
        "ax.spines['left'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['top'].set_visible(False)\n",
        "\n",
        "# æ·»åŠ æ³¨é‡Š\n",
        "ax.text(2020.5, 4.5, \n",
        "        'ä»åº•å±‚æ¶æ„ â†’ åº”ç”¨æ¡†æ¶ â†’ å®Œæ•´äº§å“', \n",
        "        fontsize=12, \n",
        "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3),\n",
        "        ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸ“… æŠ€æœ¯æ¼”è¿›æ—¶é—´çº¿\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\n2017å¹´ï¼šTransformer æ¶æ„è¯ç”Ÿ\")\n",
        "print(\"  â””â”€ é©å‘½æ€§çš„æ³¨æ„åŠ›æœºåˆ¶\")\n",
        "print(\"  â””â”€ æˆä¸ºæ‰€æœ‰ç°ä»£ LLM çš„åŸºç¡€\")\n",
        "\n",
        "print(\"\\n2018-2020å¹´ï¼šå¤§æ¨¡å‹çˆ†å‘\")\n",
        "print(\"  â””â”€ BERT, GPT-1/2/3 é™†ç»­å‘å¸ƒ\")\n",
        "print(\"  â””â”€ å‚æ•°é‡ä»ç™¾ä¸‡çº§åˆ°åƒäº¿çº§\")\n",
        "\n",
        "print(\"\\n2022å¹´ï¼šåº”ç”¨æ¡†æ¶å‡ºç°\")\n",
        "print(\"  â””â”€ LangChain è®© LLM åº”ç”¨å¼€å‘å˜ç®€å•\")\n",
        "print(\"  â””â”€ å¼€å‘è€…å¯ä»¥å¿«é€Ÿæ„å»º AI åº”ç”¨\")\n",
        "\n",
        "print(\"\\n2023å¹´ï¼šæ¨¡å‹æ€§èƒ½é£è·ƒ\")\n",
        "print(\"  â””â”€ GPT-4 æ¥è¿‘äººç±»æ°´å¹³\")\n",
        "print(\"  â””â”€ å›½äº§æ¨¡å‹ï¼ˆGLMï¼‰å¿«é€Ÿè¿½èµ¶\")\n",
        "\n",
        "print(\"\\n2024å¹´ï¼šå·¥å…·ç”Ÿæ€æˆç†Ÿ\")\n",
        "print(\"  â””â”€ LangGraph æ”¯æŒå¤æ‚ Agent\")\n",
        "print(\"  â””â”€ RAGFlow ç­‰äº§å“å¼€ç®±å³ç”¨\")\n",
        "print(\"  â””â”€ AI åº”ç”¨å¼€å‘è¿›å…¥\\\"å·¥ä¸šåŒ–\\\"æ—¶ä»£\")\n",
        "\n",
        "print(\"\\nğŸ¯ å½“å‰é˜¶æ®µï¼ˆ2024-2025ï¼‰ï¼š\")\n",
        "print(\"  â€¢ åº•å±‚æ¶æ„ï¼šæˆç†Ÿç¨³å®š\")\n",
        "print(\"  â€¢ æ¨¡å‹èƒ½åŠ›ï¼šæ¥è¿‘äººç±»\")\n",
        "print(\"  â€¢ å¼€å‘å·¥å…·ï¼šä¸°å¯Œå®Œå–„\")\n",
        "print(\"  â€¢ åº”ç”¨äº§å“ï¼šç™¾èŠ±é½æ”¾\")\n",
        "print(\"  â­ æœ€ä½³å­¦ä¹ æ—¶æœºï¼\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ å®æˆ˜å†³ç­–ï¼šæˆ‘åº”è¯¥é€‰æ‹©å“ªä¸ªï¼Ÿ\n",
        "\n",
        "### å†³ç­–æ ‘\n",
        "\n",
        "```\n",
        "å¼€å§‹ï¼šæˆ‘è¦å¼€å‘ä¸€ä¸ª AI åº”ç”¨\n",
        "\n",
        "â”œâ”€ é—®é¢˜1ï¼šä½ çš„ç›®æ ‡æ˜¯ä»€ä¹ˆï¼Ÿ\n",
        "â”‚\n",
        "â”œâ”€ A. å­¦ä¹ å’Œç†è§£åŸç†\n",
        "â”‚   â””â”€ æ¨èæ–¹æ¡ˆï¼š\n",
        "â”‚       1. äº†è§£ Transformer æ¦‚å¿µï¼ˆç†è®ºå­¦ä¹ ï¼‰\n",
        "â”‚       2. è‡ªå·±ä»é›¶å®ç°ç®€å• RAGï¼ˆå®æˆ˜ï¼‰\n",
        "â”‚       3. é€æ­¥å¼•å…¥ LangChain çš„å•ä¸ªå·¥å…·\n",
        "â”‚       ä¼˜ç‚¹ï¼šâœ… æ·±å…¥ç†è§£æ¯ä¸€æ­¥\n",
        "â”‚       æ—¶é—´ï¼š2-4å‘¨\n",
        "â”‚\n",
        "â”œâ”€ B. å¿«é€Ÿå¼€å‘ç®€å•åº”ç”¨\n",
        "â”‚   â””â”€ æ¨èæ–¹æ¡ˆï¼š\n",
        "â”‚       1. ç›´æ¥ä½¿ç”¨ LangChain\n",
        "â”‚       2. å‚è€ƒå®˜æ–¹æ–‡æ¡£å’Œç¤ºä¾‹\n",
        "â”‚       ä¼˜ç‚¹ï¼šâœ… å¿«é€Ÿä¸Šçº¿\n",
        "â”‚       æ—¶é—´ï¼š3-5å¤©\n",
        "â”‚\n",
        "â”œâ”€ C. å¼€å‘å¤æ‚çš„ Agent ç³»ç»Ÿ\n",
        "â”‚   â””â”€ ä½ çš„ Agent éœ€è¦ä»€ä¹ˆï¼Ÿ\n",
        "â”‚       â”œâ”€ çº¿æ€§æµç¨‹ï¼ˆæé—®â†’æ£€ç´¢â†’å›ç­”ï¼‰\n",
        "â”‚       â”‚   â””â”€ ç”¨ LangChain å³å¯\n",
        "â”‚       â”‚\n",
        "â”‚       â””â”€ å¤æ‚æµç¨‹ï¼ˆéœ€è¦å¾ªç¯ã€åˆ†æ”¯ã€çŠ¶æ€ç®¡ç†ï¼‰\n",
        "â”‚           â””â”€ ç”¨ LangGraph\n",
        "â”‚           ä¾‹å¦‚ï¼š\n",
        "â”‚           â€¢ å¤šæ­¥æ¨ç†\n",
        "â”‚           â€¢ å·¥å…·è°ƒç”¨é“¾\n",
        "â”‚           â€¢ è‡ªæˆ‘çº é”™\n",
        "â”‚           æ—¶é—´ï¼š1-2å‘¨å­¦ä¹  + é¡¹ç›®å¼€å‘\n",
        "â”‚\n",
        "â””â”€ D. å¿«é€Ÿä¸Šçº¿äº§å“/æ¼”ç¤º\n",
        "    â””â”€ æ¨èæ–¹æ¡ˆï¼š\n",
        "        1. éƒ¨ç½² RAGFlow\n",
        "        2. é€šè¿‡ Web UI é…ç½®\n",
        "        3. å¯¼å‡º API ä¾›ä¸šåŠ¡è°ƒç”¨\n",
        "        ä¼˜ç‚¹ï¼šâœ… é›¶ä»£ç ã€åŠŸèƒ½å®Œæ•´\n",
        "        æ—¶é—´ï¼š1å¤©éƒ¨ç½² + é…ç½®\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ¯ é’ˆå¯¹ä½ çš„æƒ…å†µ\n",
        "\n",
        "**ä½ ç›®å‰çš„é˜¶æ®µï¼šå­¦ä¹  RAG å¼€å‘**\n",
        "\n",
        "**æ¨èè·¯å¾„ï¼š**\n",
        "\n",
        "```\n",
        "ç¬¬1å‘¨ï¼šè‡ªå·±å®ç° âœ… (ä½ å·²ç»å®Œæˆ)\n",
        "  â”œâ”€ ç†è§£æ–‡æ¡£åŠ è½½ã€åˆ‡åˆ†\n",
        "  â”œâ”€ ç†è§£å‘é‡å­˜å‚¨ã€æ£€ç´¢\n",
        "  â””â”€ ç†è§£ RAG çš„å®Œæ•´æµç¨‹\n",
        "\n",
        "ç¬¬2å‘¨ï¼šä¼˜åŒ–å®æˆ˜ â† (ä½ ç°åœ¨åœ¨è¿™é‡Œ)\n",
        "  â”œâ”€ å¼•å…¥ LangChain çš„ RecursiveCharacterTextSplitter\n",
        "  â”œâ”€ å¯¹æ¯”è‡ªå·±å®ç°çš„ç®€å•åˆ‡åˆ†\n",
        "  â””â”€ ç†è§£ä¸ºä»€ä¹ˆä¸“ä¸šå·¥å…·æ›´å¥½\n",
        "\n",
        "ç¬¬3å‘¨ï¼šä½“éªŒå®Œæ•´äº§å“\n",
        "  â”œâ”€ éƒ¨ç½² RAGFlow\n",
        "  â”œâ”€ çœ‹çœ‹å•†ä¸šçº§äº§å“çš„åŠŸèƒ½\n",
        "  â””â”€ å¯¹æ¯”ä½ çš„å®ç°ï¼Œæ‰¾å·®è·\n",
        "\n",
        "ç¬¬4å‘¨åŠä»¥åï¼šæ ¹æ®éœ€æ±‚é€‰æ‹©\n",
        "  â”œâ”€ å¦‚æœé¡¹ç›®ç®€å• â†’ ç”¨ LangChain\n",
        "  â”œâ”€ å¦‚æœéœ€è¦å¤æ‚ Agent â†’ å­¦ LangGraph\n",
        "  â””â”€ å¦‚æœå¿«é€Ÿä¸Šçº¿ â†’ ç”¨ RAGFlow\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“š å­¦ä¹ èµ„æºæ¨è\n",
        "\n",
        "### 1ï¸âƒ£ Transformer å­¦ä¹ èµ„æº\n",
        "\n",
        "**è®ºæ–‡ï¼š**\n",
        "- ğŸ“„ [Attention is All You Need (2017)](https://arxiv.org/abs/1706.03762)\n",
        "- ğŸ“„ ä¸­æ–‡ç¿»è¯‘å’Œè§£è¯»ï¼ˆçŸ¥ä¹ã€CSDN æœ‰å¾ˆå¤šï¼‰\n",
        "\n",
        "**è§†é¢‘æ•™ç¨‹ï¼š**\n",
        "- ğŸ¥ æå®æ¯…ã€Šæ·±åº¦å­¦ä¹ ã€‹è¯¾ç¨‹ - Transformer éƒ¨åˆ†\n",
        "- ğŸ¥ 3Blue1Brown - ç¥ç»ç½‘ç»œå¯è§†åŒ–ç³»åˆ—\n",
        "\n",
        "**ä»£ç å®ç°ï¼š**\n",
        "- ğŸ’» [The Annotated Transformer](http://nlp.seas.harvard.edu/annotated-transformer/)\n",
        "- ğŸ’» [nanoGPT](https://github.com/karpathy/nanoGPT) - Andrej Karpathy çš„æ•™å­¦ç‰ˆ GPT\n",
        "\n",
        "---\n",
        "\n",
        "### 2ï¸âƒ£ LangChain å­¦ä¹ èµ„æº\n",
        "\n",
        "**å®˜æ–¹èµ„æºï¼š**\n",
        "- ğŸ“– [å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/)\n",
        "- ğŸ’» [GitHub ä»“åº“](https://github.com/langchain-ai/langchain)\n",
        "- ğŸ“š [ç¤ºä¾‹ä»£ç ](https://github.com/langchain-ai/langchain/tree/master/cookbook)\n",
        "\n",
        "**æ¨èæ•™ç¨‹ï¼š**\n",
        "- ğŸ¥ [å®˜æ–¹ YouTube é¢‘é“](https://www.youtube.com/@LangChain)\n",
        "- ğŸ“ [ä¸­æ–‡æ•™ç¨‹](https://www.langchain.com.cn/)\n",
        "\n",
        "**å®æˆ˜é¡¹ç›®ï¼š**\n",
        "```python\n",
        "# å®‰è£…\n",
        "pip install langchain langchain-openai\n",
        "\n",
        "# ç®€å•ç¤ºä¾‹\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=50\n",
        ")\n",
        "chunks = splitter.split_text(\"ä½ çš„æ–‡æœ¬...\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 3ï¸âƒ£ LangGraph å­¦ä¹ èµ„æº\n",
        "\n",
        "**å®˜æ–¹èµ„æºï¼š**\n",
        "- ğŸ“– [å®˜æ–¹æ–‡æ¡£](https://langchain-ai.github.io/langgraph/)\n",
        "- ğŸ’» [GitHub ä»“åº“](https://github.com/langchain-ai/langgraph)\n",
        "- ğŸ“š [ç¤ºä¾‹æ•™ç¨‹](https://github.com/langchain-ai/langgraph/tree/main/examples)\n",
        "\n",
        "**å­¦ä¹ å»ºè®®ï¼š**\n",
        "1. å…ˆæŒæ¡ LangChain åŸºç¡€\n",
        "2. ç†è§£çŠ¶æ€æœºå’Œå›¾çš„æ¦‚å¿µ\n",
        "3. è·Ÿç€å®˜æ–¹ tutorial å®è·µ\n",
        "\n",
        "---\n",
        "\n",
        "### 4ï¸âƒ£ RAGFlow å­¦ä¹ èµ„æº\n",
        "\n",
        "**å®˜æ–¹èµ„æºï¼š**\n",
        "- ğŸ’» [GitHub ä»“åº“](https://github.com/infiniflow/ragflow)\n",
        "- ğŸ“– [å®˜æ–¹æ–‡æ¡£](https://ragflow.io/docs/dev/)\n",
        "- ğŸ¬ [Demo è§†é¢‘](https://ragflow.io/)\n",
        "\n",
        "**å¿«é€Ÿå¼€å§‹ï¼š**\n",
        "```bash\n",
        "# å…‹éš†ä»“åº“\n",
        "git clone https://github.com/infiniflow/ragflow.git\n",
        "\n",
        "# å¯åŠ¨æœåŠ¡\n",
        "cd ragflow\n",
        "docker-compose up -d\n",
        "\n",
        "# è®¿é—® Web UI\n",
        "# http://localhost\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 5ï¸âƒ£ ç»¼åˆå­¦ä¹ å¹³å°\n",
        "\n",
        "**ä¸­æ–‡ç¤¾åŒºï¼š**\n",
        "- ğŸŒ [LangChain ä¸­æ–‡ç½‘](https://www.langchain.com.cn/)\n",
        "- ğŸ’¬ çŸ¥ä¹ AI è¯é¢˜\n",
        "- ğŸ’¬ CSDN AI ä¸“åŒº\n",
        "\n",
        "**è‹±æ–‡èµ„æºï¼š**\n",
        "- ğŸŒ [Hugging Face](https://huggingface.co/)\n",
        "- ğŸ’¬ [Reddit r/MachineLearning](https://www.reddit.com/r/MachineLearning/)\n",
        "- ğŸ’¬ [LangChain Discord](https://discord.gg/langchain)\n",
        "\n",
        "**å®æˆ˜é¡¹ç›®ï¼š**\n",
        "- ğŸ’» [Awesome LangChain](https://github.com/kyrolabs/awesome-langchain)\n",
        "- ğŸ’» [LangChain Templates](https://github.com/langchain-ai/langchain/tree/master/templates)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸ“š å­¦ä¹ èµ„æºå·²æ•´ç†å®Œæ¯•ï¼\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nğŸ¯ å­¦ä¹ é¡ºåºå»ºè®®ï¼š\")\n",
        "print(\"  1. Transformer æ¦‚å¿µï¼ˆç†è§£åº•å±‚ï¼‰\")\n",
        "print(\"  2. LangChain åŸºç¡€ï¼ˆå®æˆ˜å¼€å‘ï¼‰\")\n",
        "print(\"  3. RAGFlow ä½“éªŒï¼ˆäº§å“æ€ç»´ï¼‰\")\n",
        "print(\"  4. LangGraph è¿›é˜¶ï¼ˆå¤æ‚ç³»ç»Ÿï¼‰\")\n",
        "print(\"\\nğŸ’¡ è®°ä½ï¼š\")\n",
        "print(\"  â€¢ ä¸è¦è¢«æŠ€æœ¯åè¯å“å€’\")\n",
        "print(\"  â€¢ ä»ç®€å•é¡¹ç›®å¼€å§‹\")\n",
        "print(\"  â€¢ è¾¹å­¦è¾¹åšæœ€æœ‰æ•ˆ\")\n",
        "print(\"  â€¢ åŠ å…¥ç¤¾åŒºäº’ç›¸å­¦ä¹ \")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ ç»ˆææ€»ç»“\n",
        "\n",
        "### ä¸€å¥è¯è®°ä½å››è€…å…³ç³»\n",
        "\n",
        "```\n",
        "Transformer â†’ LLM â†’ LangChain/LangGraph â†’ RAGFlow\n",
        "   åŸç†    â†’ äº§å“ â†’    å·¥å…·ç®±        â†’ å®Œæ•´åº”ç”¨\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ¯ æ ¸å¿ƒè¦ç‚¹\n",
        "\n",
        "1. **Transformer ä¸æ˜¯å·¥å…·ï¼Œæ˜¯ç†è®º**\n",
        "   - å°±åƒ\"å†…ç‡ƒæœºåŸç†\"ä¸æ˜¯ä¸€è¾†è½¦\n",
        "   - äº†è§£æ¦‚å¿µå³å¯ï¼Œä¸éœ€è¦æ·±å…¥\n",
        "   - é™¤éä½ è¦åšç®—æ³•ç ”ç©¶\n",
        "\n",
        "2. **LangChain æ˜¯æ¨¡å—åŒ–çš„**\n",
        "   - å¯ä»¥åªç”¨å…¶ä¸­ä¸€ä¸ªå·¥å…·ï¼ˆå¦‚ Text Splitterï¼‰\n",
        "   - ä¸éœ€è¦å…¨ç›˜æ¥å—æ•´ä¸ªæ¡†æ¶\n",
        "   - æ¨èï¼šæ ¸å¿ƒè‡ªå·±å†™ + å·¥å…·ç”¨ä¸“ä¸šçš„\n",
        "\n",
        "3. **LangGraph æ˜¯ LangChain çš„æ‰©å±•**\n",
        "   - ä¸æ˜¯æ›¿ä»£å…³ç³»ï¼Œæ˜¯è¡¥å……å…³ç³»\n",
        "   - ä¸“é—¨ç”¨äºå¤æ‚ Agent å¼€å‘\n",
        "   - ç®€å•åº”ç”¨ç”¨ä¸ä¸Š\n",
        "\n",
        "4. **RAGFlow æ˜¯å®Œæ•´äº§å“**\n",
        "   - å¼€ç®±å³ç”¨ï¼Œé›¶ä»£ç \n",
        "   - é€‚åˆå¿«é€ŸéªŒè¯æƒ³æ³•\n",
        "   - ä½†å®šåˆ¶åŒ–èƒ½åŠ›æœ‰é™\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ’¡ å­¦ä¹ å»ºè®®\n",
        "\n",
        "**å¯¹äºåº”ç”¨å¼€å‘è€…ï¼ˆä½ ï¼‰ï¼š**\n",
        "\n",
        "```\n",
        "âœ… å¿…å­¦ï¼š\n",
        "  â€¢ RAG åŸºæœ¬åŸç†ï¼ˆè‡ªå·±å®ç°ä¸€éï¼‰\n",
        "  â€¢ LangChain çš„éƒ¨åˆ†å·¥å…·ä½¿ç”¨\n",
        "  â€¢ å‘é‡æ•°æ®åº“çš„æ¦‚å¿µ\n",
        "\n",
        "âš ï¸ é€‰å­¦ï¼š\n",
        "  â€¢ Transformer è¯¦ç»†åŸç†ï¼ˆçŸ¥é“æ¦‚å¿µå³å¯ï¼‰\n",
        "  â€¢ LangGraphï¼ˆéœ€è¦å¤æ‚ Agent æ—¶å†å­¦ï¼‰\n",
        "\n",
        "âŒ ä¸æ€¥ï¼š\n",
        "  â€¢ æ¨¡å‹è®­ç»ƒï¼ˆç®—æ³•å·¥ç¨‹å¸ˆçš„é¢†åŸŸï¼‰\n",
        "  â€¢ æ¨¡å‹å¾®è°ƒï¼ˆç­‰ä½ éœ€è¦æ—¶å†è¯´ï¼‰\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨\n",
        "\n",
        "**æœ¬å‘¨ä»»åŠ¡ï¼š**\n",
        "1. âœ… ç†è§£å››è€…çš„å…³ç³»å’Œå®šä½\n",
        "2. ğŸ“ åœ¨ä½ çš„ RAG é¡¹ç›®ä¸­å¼•å…¥ LangChain çš„ Text Splitter\n",
        "3. ğŸ” å¯¹æ¯”æ•ˆæœï¼Œçœ‹çœ‹æ˜¯å¦æœ‰æ”¹å–„\n",
        "\n",
        "**ä¸‹å‘¨ä»»åŠ¡ï¼š**\n",
        "1. ğŸ¯ å®Œå–„ä½ çš„ RAG ç³»ç»Ÿ\n",
        "2. ğŸ“Š æµ‹è¯•ä¸åŒçš„ chunk size å’Œ overlap\n",
        "3. ğŸ’¾ å°è¯•ä¸åŒçš„å‘é‡æ•°æ®åº“\n",
        "\n",
        "**æœªæ¥è§„åˆ’ï¼š**\n",
        "1. ğŸŒŸ éƒ¨ç½² RAGFlowï¼Œä½“éªŒå®Œæ•´äº§å“\n",
        "2. ğŸ¤– å¦‚æœéœ€è¦ï¼Œå­¦ä¹  LangGraph\n",
        "3. ğŸš€ å¼€å‘è‡ªå·±çš„ AI åº”ç”¨\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ‰ ç»“è¯­\n",
        "\n",
        "**æ­å–œä½ å®Œæˆäº†è¿™ä¸ªæ•™ç¨‹ï¼**\n",
        "\n",
        "ä½ ç°åœ¨åº”è¯¥æ¸…æ¥šåœ°çŸ¥é“ï¼š\n",
        "- âœ… Transformer æ˜¯ä»€ä¹ˆï¼ˆåº•å±‚æ¶æ„ï¼‰\n",
        "- âœ… LangChain æ˜¯ä»€ä¹ˆï¼ˆå¼€å‘å·¥å…·ï¼‰\n",
        "- âœ… LangGraph æ˜¯ä»€ä¹ˆï¼ˆAgent å·¥å…·ï¼‰\n",
        "- âœ… RAGFlow æ˜¯ä»€ä¹ˆï¼ˆå®Œæ•´äº§å“ï¼‰\n",
        "- âœ… å®ƒä»¬ä¹‹é—´çš„å…³ç³»\n",
        "- âœ… ä»€ä¹ˆæ—¶å€™ç”¨å“ªä¸ª\n",
        "\n",
        "**è®°ä½ï¼š**\n",
        "- ğŸ’ª ä¸è¦è¢«æŠ€æœ¯åè¯å“å€’\n",
        "- ğŸ¯ ä»ç®€å•é¡¹ç›®å¼€å§‹\n",
        "- ğŸ”„ è¾¹å­¦è¾¹åšæœ€æœ‰æ•ˆ\n",
        "- ğŸ¤ é‡åˆ°é—®é¢˜å°±æŸ¥èµ„æ–™ã€é—®ç¤¾åŒº\n",
        "\n",
        "**ä½ å·²ç»åœ¨æ­£ç¡®çš„é“è·¯ä¸Šäº†ï¼ç»§ç»­åŠ æ²¹ï¼ğŸš€**\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“ äº¤æµä¸åé¦ˆ\n",
        "\n",
        "å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜ï¼š\n",
        "1. é‡æ–°é˜…è¯»è¿™ä¸ª Notebook\n",
        "2. æŸ¥çœ‹å®˜æ–¹æ–‡æ¡£\n",
        "3. åœ¨ç¤¾åŒºæé—®\n",
        "4. å®è·µä¸­ä¸æ–­å°è¯•\n",
        "\n",
        "**Happy Coding! ğŸŠ**\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
