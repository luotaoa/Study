{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸš€ RAGé¡¹ç›®å®æˆ˜å…¥é—¨æŒ‡å—ï¼ˆæ™ºè°±AIç‰ˆæœ¬ï¼‰\n",
        "\n",
        "## ğŸ¯ å­¦ä¹ ç›®æ ‡\n",
        "\n",
        "é€šè¿‡æœ¬æŒ‡å—ï¼Œæ‚¨å°†ï¼š\n",
        "1. âœ… äº†è§£RAGé¡¹ç›®çš„å‰ç½®çŸ¥è¯†\n",
        "2. âœ… æ­å»ºå®Œæ•´çš„å¼€å‘ç¯å¢ƒ\n",
        "3. âœ… å®ç°ç¬¬ä¸€ä¸ªèƒ½è¿è¡Œçš„RAGç³»ç»Ÿ\n",
        "4. âœ… ç†è§£RAGçš„æ ¸å¿ƒç»„ä»¶\n",
        "5. âœ… æŒæ¡é€æ­¥æ‰©å±•çš„æ–¹æ³•\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“‹ å‰ç½®çŸ¥è¯†è‡ªæŸ¥è¡¨\n",
        "\n",
        "### âœ… å¿…é¡»æŒæ¡ï¼ˆæ‚¨å·²ç»å…·å¤‡ï¼‰\n",
        "\n",
        "- [x] **PythonåŸºç¡€**ï¼šå˜é‡ã€å‡½æ•°ã€ç±»\n",
        "- [x] **åŸºæœ¬æ•°æ®ç»“æ„**ï¼šåˆ—è¡¨ã€å­—å…¸\n",
        "- [x] **æ–‡ä»¶æ“ä½œ**ï¼šè¯»å†™æ–‡ä»¶\n",
        "\n",
        "### ğŸŸ¡ éœ€è¦äº†è§£ï¼ˆå¯ä»¥è¾¹åšè¾¹å­¦ï¼‰\n",
        "\n",
        "- [ ] **å‘é‡æ•°æ®åº“æ¦‚å¿µ**ï¼šå·²å­¦ä¹ ç†è®ºï¼Œå®è·µä¸­ä¼šç”¨åˆ°\n",
        "- [ ] **APIè°ƒç”¨**ï¼šä¼šç”¨requestsæˆ–SDKè°ƒç”¨æ¥å£\n",
        "- [ ] **å¼‚å¸¸å¤„ç†**ï¼štry-exceptåŸºæœ¬ç”¨æ³•\n",
        "\n",
        "### ğŸ”µ å¯é€‰ï¼ˆæœ‰æ›´å¥½ï¼Œæ²¡æœ‰ä¹Ÿè¡Œï¼‰\n",
        "\n",
        "- [ ] **Docker**ï¼šæ–¹ä¾¿éƒ¨ç½²å‘é‡æ•°æ®åº“\n",
        "- [ ] **å¼‚æ­¥ç¼–ç¨‹**ï¼šasync/awaitï¼ˆå¯ä»¥æå‡æ€§èƒ½ï¼‰\n",
        "- [ ] **Webæ¡†æ¶**ï¼šFlask/FastAPIï¼ˆå¦‚æœè¦åšAPIæœåŠ¡ï¼‰\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ å­¦ä¹ è·¯å¾„ï¼šä¸‰ä¸ªé˜¶æ®µ\n",
        "\n",
        "### é˜¶æ®µ1ï¼šæœ€ç®€RAGï¼ˆ1-2å¤©ï¼‰â­ ä»è¿™é‡Œå¼€å§‹\n",
        "\n",
        "**ç›®æ ‡ï¼š**è·‘é€šä¸€ä¸ªæœ€ç®€å•çš„RAGç³»ç»Ÿ\n",
        "\n",
        "**æ ¸å¿ƒåŠŸèƒ½ï¼š**\n",
        "- è¯»å–æœ¬åœ°æ–‡æ¡£ï¼ˆtxt/mdï¼‰\n",
        "- ä½¿ç”¨æ™ºè°±AI Embeddingï¼ˆembedding-2æ¨¡å‹ï¼‰\n",
        "- å­˜å‚¨åˆ°æœ¬åœ°ï¼ˆä¸ç”¨å‘é‡åº“ï¼‰\n",
        "- ç®€å•æ£€ç´¢+é—®ç­”\n",
        "\n",
        "**æŠ€æœ¯æ ˆï¼š**\n",
        "```python\n",
        "- Python 3.8+\n",
        "- zhipuaiåº“ï¼ˆæ™ºè°±AI SDKï¼‰\n",
        "- numpyï¼ˆå‘é‡è®¡ç®—ï¼‰\n",
        "```\n",
        "\n",
        "**éš¾åº¦ï¼š** â­ é€‚åˆå…¥é—¨\n",
        "\n",
        "---\n",
        "\n",
        "### é˜¶æ®µ2ï¼šæ ‡å‡†RAGï¼ˆ3-5å¤©ï¼‰\n",
        "\n",
        "**æ–°å¢åŠŸèƒ½ï¼š**\n",
        "- æ¥å…¥å‘é‡æ•°æ®åº“ï¼ˆMilvus/ChromaDBï¼‰\n",
        "- æ”¯æŒæ›´å¤šæ–‡æ¡£ç±»å‹ï¼ˆPDFã€Wordï¼‰\n",
        "- ä¼˜åŒ–æ£€ç´¢æ•ˆæœ\n",
        "\n",
        "**æŠ€æœ¯æ ˆï¼š**\n",
        "```python\n",
        "- é˜¶æ®µ1 +\n",
        "- pymilvus / chromadbï¼ˆå‘é‡åº“ï¼‰\n",
        "- langchainï¼ˆRAGæ¡†æ¶ï¼‰\n",
        "- pypdf / docxï¼ˆæ–‡æ¡£è§£æï¼‰\n",
        "```\n",
        "\n",
        "**éš¾åº¦ï¼š** â­â­ \n",
        "\n",
        "---\n",
        "\n",
        "### é˜¶æ®µ3ï¼šç”Ÿäº§çº§RAGï¼ˆ1-2å‘¨ï¼‰\n",
        "\n",
        "**æ–°å¢åŠŸèƒ½ï¼š**\n",
        "- APIæœåŠ¡åŒ–ï¼ˆFastAPIï¼‰\n",
        "- æµå¼è¾“å‡º\n",
        "- å¤šè½®å¯¹è¯\n",
        "- ç›‘æ§å’Œæ—¥å¿—\n",
        "\n",
        "**æŠ€æœ¯æ ˆï¼š**\n",
        "```python\n",
        "- é˜¶æ®µ2 +\n",
        "- fastapiï¼ˆWebæ¡†æ¶ï¼‰\n",
        "- redisï¼ˆç¼“å­˜ï¼‰\n",
        "- dockerï¼ˆéƒ¨ç½²ï¼‰\n",
        "```\n",
        "\n",
        "**éš¾åº¦ï¼š** â­â­â­\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ’¡ å»ºè®®ï¼šä»é˜¶æ®µ1å¼€å§‹ï¼\n",
        "\n",
        "å…ˆæŠŠæœ€ç®€å•çš„ç‰ˆæœ¬è·‘é€šï¼Œç†è§£æ ¸å¿ƒåŸç†ï¼Œå†é€æ­¥æ‰©å±•ã€‚\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ› ï¸ é˜¶æ®µ1ï¼šæœ€ç®€RAGå®æˆ˜\n",
        "\n",
        "### é¡¹ç›®ç»“æ„\n",
        "\n",
        "```\n",
        "simple-rag/\n",
        "â”œâ”€â”€ documents/          # å­˜æ”¾æ–‡æ¡£\n",
        "â”‚   â”œâ”€â”€ doc1.txt\n",
        "â”‚   â””â”€â”€ doc2.txt\n",
        "â”œâ”€â”€ simple_rag.py      # ä¸»ç¨‹åº\n",
        "â”œâ”€â”€ requirements.txt   # ä¾èµ–\n",
        "â””â”€â”€ README.md\n",
        "```\n",
        "\n",
        "### æ ¸å¿ƒæµç¨‹\n",
        "\n",
        "```\n",
        "1. æ–‡æ¡£åŠ è½½ â†’ åˆ†å—\n",
        "2. ç”ŸæˆEmbedding â†’ å­˜å‚¨\n",
        "3. ç”¨æˆ·æé—® â†’ ç”Ÿæˆé—®é¢˜Embedding\n",
        "4. ç›¸ä¼¼åº¦æœç´¢ â†’ æ‰¾åˆ°ç›¸å…³æ–‡æ¡£\n",
        "5. æ–‡æ¡£+é—®é¢˜ â†’ å‘ç»™LLM â†’ ç”Ÿæˆç­”æ¡ˆ\n",
        "```\n",
        "\n",
        "è®©æˆ‘ä»¬ä¸€æ­¥æ­¥å®ç°ï¼\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“¦ æ­¥éª¤1ï¼šç¯å¢ƒé…ç½®\n",
        "\n",
        "### 1.1 åˆ›å»ºé¡¹ç›®ç›®å½•\n",
        "\n",
        "```bash\n",
        "mkdir simple-rag\n",
        "cd simple-rag\n",
        "mkdir documents\n",
        "```\n",
        "\n",
        "### 1.2 åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰\n",
        "\n",
        "```bash\n",
        "# Windows\n",
        "python -m venv venv\n",
        "venv\\Scripts\\activate\n",
        "\n",
        "# Mac/Linux\n",
        "python3 -m venv venv\n",
        "source venv/bin/activate\n",
        "```\n",
        "\n",
        "### 1.3 å®‰è£…ä¾èµ–\n",
        "\n",
        "åˆ›å»º `requirements.txt`ï¼š\n",
        "\n",
        "```txt\n",
        "zhipuai>=2.0.0\n",
        "numpy>=1.24.0\n",
        "python-dotenv>=1.0.0\n",
        "```\n",
        "\n",
        "å®‰è£…ï¼š\n",
        "\n",
        "```bash\n",
        "pip install -r requirements.txt\n",
        "```\n",
        "\n",
        "### 1.4 é…ç½®APIå¯†é’¥\n",
        "\n",
        "åˆ›å»º `.env` æ–‡ä»¶ï¼š\n",
        "\n",
        "```bash\n",
        "ZHIPUAI_API_KEY=your_api_key_here\n",
        "```\n",
        "\n",
        "**å¦‚ä½•è·å–æ™ºè°±AI APIå¯†é’¥ï¼š**\n",
        "1. è®¿é—® https://open.bigmodel.cn/\n",
        "2. æ³¨å†Œ/ç™»å½•è´¦å·\n",
        "3. åœ¨æ§åˆ¶å°åˆ›å»ºAPIå¯†é’¥\n",
        "4. å¤åˆ¶å¯†é’¥åˆ° `.env` æ–‡ä»¶ä¸­\n",
        "\n",
        "**æ™ºè°±AIçš„ä¼˜åŠ¿ï¼š**\n",
        "- âœ… å›½å†…è®¿é—®é€Ÿåº¦å¿«\n",
        "- âœ… ä»·æ ¼ç›¸å¯¹ä¾¿å®œ\n",
        "- âœ… æ”¯æŒä¸­æ–‡æ•ˆæœå¥½\n",
        "- âœ… æœ‰å…è´¹é¢åº¦å¯ç”¨\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ’» æ­¥éª¤2ï¼šå®Œæ•´ä»£ç å®ç°\n",
        "\n",
        "ä¸‹é¢æ˜¯ä¸€ä¸ªå®Œæ•´çš„ã€å¯è¿è¡Œçš„æœ€ç®€RAGç³»ç»Ÿï¼š\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'openai'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List, Tuple\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'openai'"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "æœ€ç®€RAGç³»ç»Ÿ - å®Œæ•´å®ç°\n",
        "simple_rag.py\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from openai import OpenAI\n",
        "from typing import List, Tuple\n",
        "import json\n",
        "\n",
        "# ============================================\n",
        "# ç¬¬1éƒ¨åˆ†ï¼šæ–‡æ¡£å¤„ç†\n",
        "# ============================================\n",
        "\n",
        "class DocumentLoader:\n",
        "    \"\"\"æ–‡æ¡£åŠ è½½å™¨\"\"\"\n",
        "    \n",
        "    def load_documents(self, folder_path: str) -> List[str]:\n",
        "        \"\"\"ä»æ–‡ä»¶å¤¹åŠ è½½æ‰€æœ‰txtæ–‡æ¡£\"\"\"\n",
        "        documents = []\n",
        "        \n",
        "        for filename in os.listdir(folder_path):\n",
        "            if filename.endswith('.txt'):\n",
        "                filepath = os.path.join(folder_path, filename)\n",
        "                with open(filepath, 'r', encoding='utf-8') as f:\n",
        "                    content = f.read()\n",
        "                    documents.append(content)\n",
        "                print(f\"âœ… åŠ è½½æ–‡æ¡£: {filename}\")\n",
        "        \n",
        "        return documents\n",
        "    \n",
        "    def split_text(self, text: str, chunk_size: int = 500) -> List[str]:\n",
        "        \"\"\"å°†æ–‡æœ¬åˆ†å—\n",
        "        \n",
        "        Args:\n",
        "            text: åŸå§‹æ–‡æœ¬\n",
        "            chunk_size: æ¯å—çš„å­—ç¬¦æ•°\n",
        "        \"\"\"\n",
        "        chunks = []\n",
        "        \n",
        "        # ç®€å•æŒ‰å­—ç¬¦æ•°åˆ†å—\n",
        "        for i in range(0, len(text), chunk_size):\n",
        "            chunk = text[i:i + chunk_size]\n",
        "            chunks.append(chunk)\n",
        "        \n",
        "        return chunks\n",
        "\n",
        "print(\"âœ… DocumentLoader å®šä¹‰å®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# ç¬¬2éƒ¨åˆ†ï¼šå‘é‡å­˜å‚¨ï¼ˆç®€å•ç‰ˆï¼Œä¸ç”¨å‘é‡åº“ï¼‰\n",
        "# ============================================\n",
        "\n",
        "class SimpleVectorStore:\n",
        "    \"\"\"ç®€å•çš„å‘é‡å­˜å‚¨ï¼ˆå†…å­˜å­˜å‚¨ï¼‰\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.texts = []      # å­˜å‚¨åŸå§‹æ–‡æœ¬\n",
        "        self.embeddings = [] # å­˜å‚¨å¯¹åº”çš„å‘é‡\n",
        "        \n",
        "    def add(self, text: str, embedding: List[float]):\n",
        "        \"\"\"æ·»åŠ æ–‡æœ¬å’Œå‘é‡\"\"\"\n",
        "        self.texts.append(text)\n",
        "        self.embeddings.append(embedding)\n",
        "    \n",
        "    def search(self, query_embedding: List[float], top_k: int = 3) -> List[Tuple[str, float]]:\n",
        "        \"\"\"æœç´¢æœ€ç›¸ä¼¼çš„æ–‡æ¡£\n",
        "        \n",
        "        Args:\n",
        "            query_embedding: æŸ¥è¯¢å‘é‡\n",
        "            top_k: è¿”å›å‰kä¸ªç»“æœ\n",
        "            \n",
        "        Returns:\n",
        "            [(æ–‡æœ¬, ç›¸ä¼¼åº¦åˆ†æ•°), ...]\n",
        "        \"\"\"\n",
        "        if not self.embeddings:\n",
        "            return []\n",
        "        \n",
        "        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦\n",
        "        query_vec = np.array(query_embedding)\n",
        "        \n",
        "        similarities = []\n",
        "        for i, emb in enumerate(self.embeddings):\n",
        "            emb_vec = np.array(emb)\n",
        "            \n",
        "            # ä½™å¼¦ç›¸ä¼¼åº¦å…¬å¼\n",
        "            similarity = np.dot(query_vec, emb_vec) / (\n",
        "                np.linalg.norm(query_vec) * np.linalg.norm(emb_vec)\n",
        "            )\n",
        "            \n",
        "            similarities.append((self.texts[i], float(similarity)))\n",
        "        \n",
        "        # æŒ‰ç›¸ä¼¼åº¦æ’åºï¼Œè¿”å›top_k\n",
        "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "        return similarities[:top_k]\n",
        "    \n",
        "    def save(self, filepath: str):\n",
        "        \"\"\"ä¿å­˜åˆ°æ–‡ä»¶\"\"\"\n",
        "        data = {\n",
        "            'texts': self.texts,\n",
        "            'embeddings': self.embeddings\n",
        "        }\n",
        "        with open(filepath, 'w', encoding='utf-8') as f:\n",
        "            json.dump(data, f, ensure_ascii=False)\n",
        "        print(f\"âœ… å‘é‡åº“å·²ä¿å­˜åˆ°: {filepath}\")\n",
        "    \n",
        "    def load(self, filepath: str):\n",
        "        \"\"\"ä»æ–‡ä»¶åŠ è½½\"\"\"\n",
        "        with open(filepath, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        self.texts = data['texts']\n",
        "        self.embeddings = data['embeddings']\n",
        "        print(f\"âœ… å‘é‡åº“å·²åŠ è½½ï¼Œå…± {len(self.texts)} æ¡è®°å½•\")\n",
        "\n",
        "print(\"âœ… SimpleVectorStore å®šä¹‰å®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# ç¬¬3éƒ¨åˆ†ï¼šRAGæ ¸å¿ƒç±»\n",
        "# ============================================\n",
        "\n",
        "class SimpleRAG:\n",
        "    \"\"\"ç®€å•çš„RAGç³»ç»Ÿ\"\"\"\n",
        "    \n",
        "    def __init__(self, api_key: str, base_url: str = None):\n",
        "        \"\"\"åˆå§‹åŒ–\n",
        "        \n",
        "        Args:\n",
        "            api_key: OpenAI APIå¯†é’¥\n",
        "            base_url: APIåœ°å€ï¼ˆå¯é€‰ï¼Œç”¨äºä»£ç†ï¼‰\n",
        "        \"\"\"\n",
        "        if base_url:\n",
        "            self.client = OpenAI(api_key=api_key, base_url=base_url)\n",
        "        else:\n",
        "            self.client = OpenAI(api_key=api_key)\n",
        "        \n",
        "        self.doc_loader = DocumentLoader()\n",
        "        self.vector_store = SimpleVectorStore()\n",
        "        \n",
        "        print(\"âœ… SimpleRAG åˆå§‹åŒ–å®Œæˆ\")\n",
        "    \n",
        "    def get_embedding(self, text: str) -> List[float]:\n",
        "        \"\"\"è·å–æ–‡æœ¬çš„Embeddingå‘é‡\"\"\"\n",
        "        response = self.client.embeddings.create(\n",
        "            model=\"text-embedding-ada-002\",  # OpenAIçš„embeddingæ¨¡å‹\n",
        "            input=text\n",
        "        )\n",
        "        return response.data[0].embedding\n",
        "    \n",
        "    def index_documents(self, folder_path: str):\n",
        "        \"\"\"ç´¢å¼•æ–‡æ¡£ï¼ˆæ„å»ºå‘é‡åº“ï¼‰\"\"\"\n",
        "        print(f\"\\nğŸ“š å¼€å§‹ç´¢å¼•æ–‡æ¡£...\")\n",
        "        \n",
        "        # 1. åŠ è½½æ–‡æ¡£\n",
        "        documents = self.doc_loader.load_documents(folder_path)\n",
        "        print(f\"âœ… å…±åŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£\")\n",
        "        \n",
        "        # 2. åˆ†å—\n",
        "        all_chunks = []\n",
        "        for doc in documents:\n",
        "            chunks = self.doc_loader.split_text(doc, chunk_size=500)\n",
        "            all_chunks.extend(chunks)\n",
        "        print(f\"âœ… å…±åˆ†æˆ {len(all_chunks)} ä¸ªæ–‡æœ¬å—\")\n",
        "        \n",
        "        # 3. ç”ŸæˆEmbeddingå¹¶å­˜å‚¨\n",
        "        print(\"ğŸ”„ æ­£åœ¨ç”Ÿæˆå‘é‡...\")\n",
        "        for i, chunk in enumerate(all_chunks):\n",
        "            embedding = self.get_embedding(chunk)\n",
        "            self.vector_store.add(chunk, embedding)\n",
        "            \n",
        "            if (i + 1) % 10 == 0:\n",
        "                print(f\"   è¿›åº¦: {i + 1}/{len(all_chunks)}\")\n",
        "        \n",
        "        print(\"âœ… å‘é‡ç”Ÿæˆå®Œæˆï¼\")\n",
        "    \n",
        "    def query(self, question: str, top_k: int = 3) -> str:\n",
        "        \"\"\"æŸ¥è¯¢é—®é¢˜\n",
        "        \n",
        "        Args:\n",
        "            question: ç”¨æˆ·é—®é¢˜\n",
        "            top_k: æ£€ç´¢å¤šå°‘ä¸ªç›¸å…³æ–‡æ¡£\n",
        "            \n",
        "        Returns:\n",
        "            LLMç”Ÿæˆçš„ç­”æ¡ˆ\n",
        "        \"\"\"\n",
        "        print(f\"\\nâ“ é—®é¢˜: {question}\")\n",
        "        \n",
        "        # 1. å°†é—®é¢˜è½¬æˆå‘é‡\n",
        "        print(\"ğŸ”„ æ­£åœ¨æ£€ç´¢ç›¸å…³æ–‡æ¡£...\")\n",
        "        question_embedding = self.get_embedding(question)\n",
        "        \n",
        "        # 2. æ£€ç´¢ç›¸ä¼¼æ–‡æ¡£\n",
        "        results = self.vector_store.search(question_embedding, top_k=top_k)\n",
        "        \n",
        "        if not results:\n",
        "            return \"âŒ æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ–‡æ¡£\"\n",
        "        \n",
        "        # 3. æ‰“å°æ£€ç´¢ç»“æœ\n",
        "        print(f\"âœ… æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£:\")\n",
        "        for i, (text, score) in enumerate(results):\n",
        "            print(f\"   {i+1}. ç›¸ä¼¼åº¦: {score:.3f} - {text[:50]}...\")\n",
        "        \n",
        "        # 4. æ„å»ºprompt\n",
        "        context = \"\\n\\n\".join([text for text, score in results])\n",
        "        \n",
        "        prompt = f\"\"\"è¯·åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ã€‚å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯´\"æ–‡æ¡£ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯\"ã€‚\n",
        "\n",
        "æ–‡æ¡£å†…å®¹ï¼š\n",
        "{context}\n",
        "\n",
        "é—®é¢˜ï¼š{question}\n",
        "\n",
        "å›ç­”ï¼š\"\"\"\n",
        "        \n",
        "        # 5. è°ƒç”¨LLMç”Ÿæˆç­”æ¡ˆ\n",
        "        print(\"ğŸ”„ æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ...\")\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.7\n",
        "        )\n",
        "        \n",
        "        answer = response.choices[0].message.content\n",
        "        return answer\n",
        "\n",
        "print(\"âœ… SimpleRAG å®šä¹‰å®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ® æ­¥éª¤3ï¼šä½¿ç”¨ç¤ºä¾‹\n",
        "\n",
        "ä¸‹é¢æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨è¿™ä¸ªRAGç³»ç»Ÿï¼š\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# ä½¿ç”¨ç¤ºä¾‹ï¼ˆæ³¨é‡Šæ‰ï¼Œå› ä¸ºéœ€è¦çœŸå®çš„APIå¯†é’¥ï¼‰\n",
        "# ============================================\n",
        "\n",
        "\"\"\"\n",
        "# 1. å‡†å¤‡æµ‹è¯•æ–‡æ¡£\n",
        "import os\n",
        "os.makedirs('documents', exist_ok=True)\n",
        "\n",
        "# åˆ›å»ºæµ‹è¯•æ–‡æ¡£1\n",
        "with open('documents/ai_intro.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write('''\n",
        "äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligence, AIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ã€‚\n",
        "å®ƒä¼å›¾äº†è§£æ™ºèƒ½çš„å®è´¨ï¼Œå¹¶ç”Ÿäº§å‡ºä¸€ç§æ–°çš„èƒ½ä»¥äººç±»æ™ºèƒ½ç›¸ä¼¼çš„æ–¹å¼åšå‡ºååº”çš„æ™ºèƒ½æœºå™¨ã€‚\n",
        "è¯¥é¢†åŸŸçš„ç ”ç©¶åŒ…æ‹¬æœºå™¨äººã€è¯­è¨€è¯†åˆ«ã€å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œä¸“å®¶ç³»ç»Ÿç­‰ã€‚\n",
        "\n",
        "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒï¼Œæ˜¯ä½¿è®¡ç®—æœºå…·æœ‰æ™ºèƒ½çš„æ ¹æœ¬é€”å¾„ã€‚\n",
        "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒä½¿ç”¨ç¥ç»ç½‘ç»œæ¥å­¦ä¹ æ•°æ®çš„è¡¨ç¤ºã€‚\n",
        "''')\n",
        "\n",
        "# åˆ›å»ºæµ‹è¯•æ–‡æ¡£2\n",
        "with open('documents/rag_intro.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write('''\n",
        "RAGï¼ˆRetrieval Augmented Generationï¼‰æ˜¯ä¸€ç§ç»“åˆæ£€ç´¢å’Œç”Ÿæˆçš„AIæŠ€æœ¯ã€‚\n",
        "å®ƒé€šè¿‡æ£€ç´¢ç›¸å…³æ–‡æ¡£æ¥å¢å¼ºå¤§è¯­è¨€æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ã€‚\n",
        "\n",
        "RAGçš„æ ¸å¿ƒä¼˜åŠ¿åŒ…æ‹¬ï¼š\n",
        "1. å¯ä»¥ä½¿ç”¨æœ€æ–°çš„ã€ç§æœ‰çš„æ•°æ®\n",
        "2. å‡å°‘å¤§æ¨¡å‹çš„å¹»è§‰é—®é¢˜\n",
        "3. ç­”æ¡ˆå¯ä»¥è¿½æº¯æ¥æº\n",
        "4. ä¸éœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹\n",
        "\n",
        "RAGç³»ç»Ÿé€šå¸¸åŒ…å«ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šæ–‡æ¡£æ£€ç´¢å™¨ã€å‘é‡æ•°æ®åº“å’Œå¤§è¯­è¨€æ¨¡å‹ã€‚\n",
        "''')\n",
        "\n",
        "print(\"âœ… æµ‹è¯•æ–‡æ¡£åˆ›å»ºå®Œæˆ\")\n",
        "\n",
        "# 2. åˆå§‹åŒ–RAGç³»ç»Ÿï¼ˆéœ€è¦çœŸå®çš„APIå¯†é’¥ï¼‰\n",
        "# rag = SimpleRAG(\n",
        "#     api_key=\"your-api-key-here\",\n",
        "#     base_url=\"https://api.openai.com/v1\"  # å¯é€‰\n",
        "# )\n",
        "\n",
        "# 3. ç´¢å¼•æ–‡æ¡£\n",
        "# rag.index_documents('documents')\n",
        "\n",
        "# å¯é€‰ï¼šä¿å­˜å‘é‡åº“\n",
        "# rag.vector_store.save('vector_store.json')\n",
        "\n",
        "# 4. æŸ¥è¯¢\n",
        "# answer = rag.query(\"ä»€ä¹ˆæ˜¯RAGï¼Ÿ\")\n",
        "# print(f\"\\nğŸ’¡ ç­”æ¡ˆ:\\n{answer}\")\n",
        "\n",
        "# answer = rag.query(\"æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ çš„å…³ç³»æ˜¯ä»€ä¹ˆï¼Ÿ\")\n",
        "# print(f\"\\nğŸ’¡ ç­”æ¡ˆ:\\n{answer}\")\n",
        "\"\"\"\n",
        "\n",
        "print(\"ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹ä»£ç å·²å‡†å¤‡ï¼ˆéœ€è¦å–æ¶ˆæ³¨é‡Šå¹¶æä¾›çœŸå®APIå¯†é’¥ï¼‰\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ å®é™…è¿è¡Œæ­¥éª¤\n",
        "\n",
        "### 1. å°†ä¸Šé¢çš„ä»£ç ä¿å­˜ä¸º `simple_rag.py`\n",
        "\n",
        "### 2. åœ¨ `documents/` ç›®å½•åˆ›å»ºæµ‹è¯•æ–‡æ¡£\n",
        "\n",
        "åˆ›å»º `documents/ai_intro.txt`ï¼š\n",
        "```\n",
        "äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligence, AIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ã€‚\n",
        "å®ƒä¼å›¾äº†è§£æ™ºèƒ½çš„å®è´¨ï¼Œå¹¶ç”Ÿäº§å‡ºä¸€ç§æ–°çš„èƒ½ä»¥äººç±»æ™ºèƒ½ç›¸ä¼¼çš„æ–¹å¼åšå‡ºååº”çš„æ™ºèƒ½æœºå™¨ã€‚\n",
        "è¯¥é¢†åŸŸçš„ç ”ç©¶åŒ…æ‹¬æœºå™¨äººã€è¯­è¨€è¯†åˆ«ã€å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œä¸“å®¶ç³»ç»Ÿç­‰ã€‚\n",
        "```\n",
        "\n",
        "åˆ›å»º `documents/rag_intro.txt`ï¼š\n",
        "```\n",
        "RAGï¼ˆRetrieval Augmented Generationï¼‰æ˜¯ä¸€ç§ç»“åˆæ£€ç´¢å’Œç”Ÿæˆçš„AIæŠ€æœ¯ã€‚\n",
        "å®ƒé€šè¿‡æ£€ç´¢ç›¸å…³æ–‡æ¡£æ¥å¢å¼ºå¤§è¯­è¨€æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ã€‚\n",
        "RAGçš„æ ¸å¿ƒä¼˜åŠ¿åŒ…æ‹¬ï¼šå¯ä»¥ä½¿ç”¨æœ€æ–°æ•°æ®ã€å‡å°‘å¹»è§‰ã€ç­”æ¡ˆå¯è¿½æº¯ã€‚\n",
        "```\n",
        "\n",
        "### 3. è¿è¡Œä¸»ç¨‹åº\n",
        "\n",
        "åˆ›å»º `main.py`ï¼š\n",
        "\n",
        "```python\n",
        "from simple_rag import SimpleRAG\n",
        "import os\n",
        "\n",
        "# ä»ç¯å¢ƒå˜é‡è¯»å–APIå¯†é’¥\n",
        "api_key = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "# åˆå§‹åŒ–RAG\n",
        "rag = SimpleRAG(api_key=api_key)\n",
        "\n",
        "# ç´¢å¼•æ–‡æ¡£\n",
        "rag.index_documents('documents')\n",
        "\n",
        "# ä¿å­˜å‘é‡åº“ï¼ˆå¯é€‰ï¼‰\n",
        "rag.vector_store.save('vector_store.json')\n",
        "\n",
        "# å¼€å§‹é—®ç­”\n",
        "while True:\n",
        "    question = input(\"\\nè¯·è¾“å…¥é—®é¢˜ï¼ˆè¾“å…¥'quit'é€€å‡ºï¼‰: \")\n",
        "    \n",
        "    if question.lower() == 'quit':\n",
        "        break\n",
        "    \n",
        "    answer = rag.query(question)\n",
        "    print(f\"\\nğŸ’¡ ç­”æ¡ˆ:\\n{answer}\\n\")\n",
        "    print(\"-\" * 50)\n",
        "```\n",
        "\n",
        "### 4. è¿è¡Œ\n",
        "\n",
        "```bash\n",
        "python main.py\n",
        "```\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ” ä»£ç è¯¦è§£\n",
        "\n",
        "### æ ¸å¿ƒæµç¨‹å›¾\n",
        "\n",
        "```\n",
        "ç”¨æˆ·é—®é¢˜: \"ä»€ä¹ˆæ˜¯RAG?\"\n",
        "    â†“\n",
        "1. è½¬æˆå‘é‡ (get_embedding)\n",
        "    [0.23, -0.45, 0.67, ...]\n",
        "    â†“\n",
        "2. å‘é‡æ£€ç´¢ (vector_store.search)\n",
        "    æ‰¾åˆ°æœ€ç›¸ä¼¼çš„3ä¸ªæ–‡æ¡£å—\n",
        "    â†“\n",
        "3. æ„å»ºPrompt\n",
        "    \"åŸºäºä»¥ä¸‹æ–‡æ¡£: [æ–‡æ¡£1][æ–‡æ¡£2][æ–‡æ¡£3]\n",
        "     é—®é¢˜: ä»€ä¹ˆæ˜¯RAG?\"\n",
        "    â†“\n",
        "4. å‘ç»™LLM (client.chat.completions.create)\n",
        "    â†“\n",
        "5. è¿”å›ç­”æ¡ˆ\n",
        "    \"RAGæ˜¯ä¸€ç§ç»“åˆæ£€ç´¢å’Œç”Ÿæˆçš„AIæŠ€æœ¯...\"\n",
        "```\n",
        "\n",
        "### å…³é”®ä»£ç è§£æ\n",
        "\n",
        "#### 1. ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—\n",
        "\n",
        "```python\n",
        "similarity = np.dot(query_vec, emb_vec) / (\n",
        "    np.linalg.norm(query_vec) * np.linalg.norm(emb_vec)\n",
        ")\n",
        "```\n",
        "\n",
        "**å«ä¹‰ï¼š**\n",
        "- `np.dot()`: å‘é‡ç‚¹ç§¯\n",
        "- `np.linalg.norm()`: å‘é‡é•¿åº¦\n",
        "- ä½™å¼¦ç›¸ä¼¼åº¦ = ç‚¹ç§¯ / (é•¿åº¦1 Ã— é•¿åº¦2)\n",
        "- èŒƒå›´ï¼š-1åˆ°1ï¼Œè¶Šæ¥è¿‘1è¶Šç›¸ä¼¼\n",
        "\n",
        "#### 2. Promptå·¥ç¨‹\n",
        "\n",
        "```python\n",
        "prompt = f\"\"\"è¯·åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ã€‚\n",
        "\n",
        "æ–‡æ¡£å†…å®¹ï¼š\n",
        "{context}\n",
        "\n",
        "é—®é¢˜ï¼š{question}\n",
        "\n",
        "å›ç­”ï¼š\"\"\"\n",
        "```\n",
        "\n",
        "**è¦ç‚¹ï¼š**\n",
        "- æ˜ç¡®æŒ‡ç¤ºLLMåŸºäºæ–‡æ¡£å›ç­”\n",
        "- æä¾›å®Œæ•´çš„ä¸Šä¸‹æ–‡\n",
        "- æ¸…æ™°çš„é—®é¢˜é™ˆè¿°\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸš¨ å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ\n",
        "\n",
        "### Q1: æ²¡æœ‰OpenAI APIæ€ä¹ˆåŠï¼Ÿ\n",
        "\n",
        "**æ–¹æ¡ˆAï¼šä½¿ç”¨å›½å†…APIï¼ˆæ¨èï¼‰**\n",
        "\n",
        "```python\n",
        "# æ™ºè°±AI GLM-4\n",
        "from zhipuai import ZhipuAI\n",
        "\n",
        "client = ZhipuAI(api_key=\"your-key\")\n",
        "response = client.embeddings.create(\n",
        "    model=\"embedding-2\",\n",
        "    input=\"æ–‡æœ¬å†…å®¹\"\n",
        ")\n",
        "```\n",
        "\n",
        "**æ–¹æ¡ˆBï¼šä½¿ç”¨å¼€æºæ¨¡å‹**\n",
        "\n",
        "```python\n",
        "# ä½¿ç”¨sentence-transformersï¼ˆæœ¬åœ°è¿è¡Œï¼‰\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')\n",
        "embedding = model.encode(\"æ–‡æœ¬å†…å®¹\")\n",
        "```\n",
        "\n",
        "**æ–¹æ¡ˆCï¼šä½¿ç”¨Ollamaï¼ˆæœ¬åœ°è¿è¡Œï¼‰**\n",
        "\n",
        "```bash\n",
        "# å®‰è£…Ollama\n",
        "# ä¸‹è½½æ¨¡å‹\n",
        "ollama pull qwen:7b\n",
        "\n",
        "# Pythonè°ƒç”¨\n",
        "import ollama\n",
        "response = ollama.embeddings(model='qwen', prompt='æ–‡æœ¬å†…å®¹')\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Q2: APIè°ƒç”¨å¤ªæ…¢æ€ä¹ˆåŠï¼Ÿ\n",
        "\n",
        "**è§£å†³æ–¹æ¡ˆï¼šæ‰¹é‡å¤„ç†**\n",
        "\n",
        "```python\n",
        "def get_embeddings_batch(self, texts: List[str]) -> List[List[float]]:\n",
        "    \"\"\"æ‰¹é‡è·å–embedding\"\"\"\n",
        "    response = self.client.embeddings.create(\n",
        "        model=\"text-embedding-ada-002\",\n",
        "        input=texts  # ä¸€æ¬¡å‘é€å¤šä¸ªæ–‡æœ¬\n",
        "    )\n",
        "    return [data.embedding for data in response.data]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Q3: æ–‡æ¡£å¤ªå¤§æ€ä¹ˆåŠï¼Ÿ\n",
        "\n",
        "**è§£å†³æ–¹æ¡ˆï¼šæ™ºèƒ½åˆ†å—**\n",
        "\n",
        "```python\n",
        "def split_text_smart(self, text: str, chunk_size: int = 500):\n",
        "    \"\"\"æŒ‰æ®µè½æ™ºèƒ½åˆ†å—\"\"\"\n",
        "    paragraphs = text.split('\\n\\n')\n",
        "    \n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    \n",
        "    for para in paragraphs:\n",
        "        if len(current_chunk) + len(para) < chunk_size:\n",
        "            current_chunk += para + \"\\n\\n\"\n",
        "        else:\n",
        "            if current_chunk:\n",
        "                chunks.append(current_chunk)\n",
        "            current_chunk = para + \"\\n\\n\"\n",
        "    \n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk)\n",
        "    \n",
        "    return chunks\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Q4: æ£€ç´¢ç»“æœä¸å‡†ç¡®ï¼Ÿ\n",
        "\n",
        "**è§£å†³æ–¹æ¡ˆï¼šè°ƒæ•´å‚æ•°**\n",
        "\n",
        "```python\n",
        "# 1. å¢åŠ æ£€ç´¢æ•°é‡\n",
        "results = self.vector_store.search(query_embedding, top_k=5)  # ä»3æ”¹åˆ°5\n",
        "\n",
        "# 2. æ·»åŠ ç›¸ä¼¼åº¦é˜ˆå€¼\n",
        "filtered_results = [\n",
        "    (text, score) for text, score in results \n",
        "    if score > 0.7  # åªè¦ç›¸ä¼¼åº¦>0.7çš„\n",
        "]\n",
        "\n",
        "# 3. é‡æ–°æ’åºï¼ˆRe-rankingï¼‰\n",
        "# ä½¿ç”¨æ›´å¤æ‚çš„æ¨¡å‹å¯¹åˆç­›ç»“æœé‡æ–°æ‰“åˆ†\n",
        "```\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ ç»ƒä¹ ä»»åŠ¡\n",
        "\n",
        "### ä»»åŠ¡1ï¼šåŸºç¡€ç‰ˆï¼ˆå¿…åšï¼‰â­\n",
        "\n",
        "**ç›®æ ‡ï¼š**è·‘é€šä¸Šé¢çš„ä»£ç \n",
        "\n",
        "**æ­¥éª¤ï¼š**\n",
        "1. âœ… å®‰è£…ä¾èµ–\n",
        "2. âœ… åˆ›å»ºæµ‹è¯•æ–‡æ¡£ï¼ˆè‡³å°‘2ä¸ªtxtæ–‡ä»¶ï¼‰\n",
        "3. âœ… è¿è¡Œä»£ç ï¼ŒæˆåŠŸé—®ç­”\n",
        "4. âœ… æµ‹è¯•ä¸åŒçš„é—®é¢˜\n",
        "\n",
        "**éªŒæ”¶æ ‡å‡†ï¼š**\n",
        "- èƒ½æˆåŠŸç´¢å¼•æ–‡æ¡£\n",
        "- èƒ½æ­£ç¡®å›ç­”åŸºäºæ–‡æ¡£çš„é—®é¢˜\n",
        "- ç†è§£æ•´ä¸ªæµç¨‹\n",
        "\n",
        "---\n",
        "\n",
        "### ä»»åŠ¡2ï¼šæ”¹è¿›ç‰ˆï¼ˆæ¨èï¼‰â­â­\n",
        "\n",
        "**ç›®æ ‡ï¼š**æ·»åŠ æ–°åŠŸèƒ½\n",
        "\n",
        "**å¯é€‰æ”¹è¿›ï¼š**\n",
        "1. âœ… æ·»åŠ æ–‡æ¡£å…ƒæ•°æ®ï¼ˆæ–‡ä»¶åã€åˆ›å»ºæ—¶é—´ï¼‰\n",
        "2. âœ… åœ¨ç­”æ¡ˆä¸­æ˜¾ç¤ºå¼•ç”¨æ¥æº\n",
        "3. âœ… æ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼ï¼ˆmdã€pdfï¼‰\n",
        "4. âœ… æ·»åŠ ç®€å•çš„Webç•Œé¢ï¼ˆStreamlitï¼‰\n",
        "\n",
        "**æç¤ºï¼šå¼•ç”¨æ¥æºå®ç°**\n",
        "\n",
        "```python\n",
        "def query_with_source(self, question: str) -> Tuple[str, List[str]]:\n",
        "    \"\"\"æŸ¥è¯¢å¹¶è¿”å›æ¥æº\"\"\"\n",
        "    # ... æ£€ç´¢ä»£ç  ...\n",
        "    \n",
        "    # è®°å½•æ¥æº\n",
        "    sources = [f\"æ–‡æ¡£ç‰‡æ®µ{i+1}: {text[:100]}...\" \n",
        "               for i, (text, score) in enumerate(results)]\n",
        "    \n",
        "    # åœ¨promptä¸­è¦æ±‚æ ‡æ³¨æ¥æº\n",
        "    prompt = f\"\"\"åŸºäºä»¥ä¸‹æ–‡æ¡£å›ç­”ï¼Œå¹¶æ ‡æ³¨å¼•ç”¨äº†å“ªäº›æ–‡æ¡£ã€‚\n",
        "\n",
        "æ–‡æ¡£1: {results[0][0]}\n",
        "æ–‡æ¡£2: {results[1][0]}\n",
        "...\n",
        "\n",
        "é—®é¢˜: {question}\"\"\"\n",
        "    \n",
        "    answer = # ... LLMè°ƒç”¨ ...\n",
        "    \n",
        "    return answer, sources\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ä»»åŠ¡3ï¼šå‘é‡åº“ç‰ˆï¼ˆè¿›é˜¶ï¼‰â­â­â­\n",
        "\n",
        "**ç›®æ ‡ï¼š**æ¥å…¥çœŸå®å‘é‡æ•°æ®åº“\n",
        "\n",
        "**æ­¥éª¤ï¼š**\n",
        "1. âœ… å®‰è£…ChromaDBï¼ˆæœ€ç®€å•çš„å‘é‡åº“ï¼‰\n",
        "   ```bash\n",
        "   pip install chromadb\n",
        "   ```\n",
        "\n",
        "2. âœ… æ›¿æ¢SimpleVectorStoreä¸ºChromaDB\n",
        "\n",
        "```python\n",
        "import chromadb\n",
        "\n",
        "class ChromaVectorStore:\n",
        "    def __init__(self):\n",
        "        self.client = chromadb.Client()\n",
        "        self.collection = self.client.create_collection(\"documents\")\n",
        "    \n",
        "    def add(self, text: str, embedding: List[float]):\n",
        "        self.collection.add(\n",
        "            embeddings=[embedding],\n",
        "            documents=[text],\n",
        "            ids=[f\"doc_{len(self.collection.get()['ids'])}\"]\n",
        "        )\n",
        "    \n",
        "    def search(self, query_embedding: List[float], top_k: int = 3):\n",
        "        results = self.collection.query(\n",
        "            query_embeddings=[query_embedding],\n",
        "            n_results=top_k\n",
        "        )\n",
        "        return list(zip(results['documents'][0], results['distances'][0]))\n",
        "```\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“š æ¨èå­¦ä¹ èµ„æº\n",
        "\n",
        "### å®˜æ–¹æ–‡æ¡£\n",
        "\n",
        "1. **OpenAI APIæ–‡æ¡£**\n",
        "   - https://platform.openai.com/docs\n",
        "   - å­¦ä¹ Embeddingå’ŒChat APIçš„ç”¨æ³•\n",
        "\n",
        "2. **ChromaDBæ–‡æ¡£**\n",
        "   - https://docs.trychroma.com/\n",
        "   - æœ€ç®€å•çš„å‘é‡æ•°æ®åº“\n",
        "\n",
        "3. **LangChainæ–‡æ¡£**\n",
        "   - https://python.langchain.com/\n",
        "   - RAGæ¡†æ¶ï¼Œé˜¶æ®µ2ä¼šç”¨åˆ°\n",
        "\n",
        "### è§†é¢‘æ•™ç¨‹\n",
        "\n",
        "1. **YouTubeæœç´¢ï¼š**\n",
        "   - \"RAG tutorial\"\n",
        "   - \"Build RAG from scratch\"\n",
        "   - \"LangChain RAG\"\n",
        "\n",
        "2. **Bç«™æœç´¢ï¼š**\n",
        "   - \"RAGæ•™ç¨‹\"\n",
        "   - \"å¤§æ¨¡å‹åº”ç”¨å¼€å‘\"\n",
        "\n",
        "### å¼€æºé¡¹ç›®å‚è€ƒ\n",
        "\n",
        "1. **LangChain RAGç¤ºä¾‹**\n",
        "   ```bash\n",
        "   git clone https://github.com/langchain-ai/langchain\n",
        "   cd langchain/templates/rag-*\n",
        "   ```\n",
        "\n",
        "2. **Awesome-RAG**\n",
        "   - https://github.com/Awesome-LLM-RAG/Awesome-RAG\n",
        "   - RAGç›¸å…³èµ„æºåˆé›†\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ—ºï¸ åç»­å­¦ä¹ è·¯çº¿\n",
        "\n",
        "### å®Œæˆé˜¶æ®µ1åï¼Œæ¥ä¸‹æ¥å­¦ä»€ä¹ˆï¼Ÿ\n",
        "\n",
        "```\n",
        "é˜¶æ®µ1ï¼ˆå½“å‰ï¼‰\n",
        "  â†“\n",
        "äº†è§£æ ¸å¿ƒæ¦‚å¿µ âœ…\n",
        "  â†“\n",
        "é˜¶æ®µ2ï¼šæ ‡å‡†RAG\n",
        "  - å­¦ä¹ LangChainæ¡†æ¶\n",
        "  - æ¥å…¥Milvus/Pinecone\n",
        "  - æ–‡æ¡£è§£æï¼ˆPDFã€Wordï¼‰\n",
        "  - ä¼˜åŒ–æ£€ç´¢æ•ˆæœ\n",
        "  â†“\n",
        "é˜¶æ®µ3ï¼šé«˜çº§ç‰¹æ€§\n",
        "  - å¤šè½®å¯¹è¯\n",
        "  - æµå¼è¾“å‡º\n",
        "  - Agentèƒ½åŠ›\n",
        "  â†“\n",
        "é˜¶æ®µ4ï¼šç”Ÿäº§éƒ¨ç½²\n",
        "  - APIæœåŠ¡åŒ–\n",
        "  - æ€§èƒ½ä¼˜åŒ–\n",
        "  - ç›‘æ§å’Œæ—¥å¿—\n",
        "```\n",
        "\n",
        "### æ¨èçš„å­¦ä¹ é¡ºåº\n",
        "\n",
        "1. **ç¬¬1å‘¨ï¼šé˜¶æ®µ1**\n",
        "   - è·‘é€šæœ¬æ–‡æ¡£çš„ä»£ç \n",
        "   - å®Œæˆä»»åŠ¡1å’Œä»»åŠ¡2\n",
        "   - ç†è§£RAGçš„æ ¸å¿ƒåŸç†\n",
        "\n",
        "2. **ç¬¬2å‘¨ï¼šé˜¶æ®µ2**\n",
        "   - å­¦ä¹ LangChainåŸºç¡€\n",
        "   - æ¥å…¥å‘é‡æ•°æ®åº“\n",
        "   - å¤„ç†æ›´å¤æ‚çš„æ–‡æ¡£\n",
        "\n",
        "3. **ç¬¬3-4å‘¨ï¼šå®æˆ˜é¡¹ç›®**\n",
        "   - é€‰æ‹©ä¸€ä¸ªçœŸå®åœºæ™¯ï¼ˆå¦‚ä¸ªäººçŸ¥è¯†åº“ï¼‰\n",
        "   - å®Œæ•´å®ç°ä¸€ä¸ªRAGåº”ç”¨\n",
        "   - éƒ¨ç½²å¹¶å®é™…ä½¿ç”¨\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ’¡ å…³é”®è¦ç‚¹æ€»ç»“\n",
        "\n",
        "### âœ… RAGçš„æ ¸å¿ƒåªæœ‰5æ­¥\n",
        "\n",
        "1. **æ–‡æ¡£åŠ è½½** â†’ è¯»å–æ–‡æ¡£\n",
        "2. **æ–‡æ¡£åˆ†å—** â†’ åˆ‡æˆå°æ®µ\n",
        "3. **ç”Ÿæˆå‘é‡** â†’ Embedding\n",
        "4. **å‘é‡æ£€ç´¢** â†’ æ‰¾ç›¸ä¼¼æ–‡æ¡£\n",
        "5. **LLMç”Ÿæˆ** â†’ åŸºäºæ–‡æ¡£å›ç­”\n",
        "\n",
        "### âœ… æœ€å°å¯è¿è¡Œç³»ç»Ÿéœ€è¦\n",
        "\n",
        "- âœ… PythonåŸºç¡€\n",
        "- âœ… OpenAI APIï¼ˆæˆ–æ›¿ä»£å“ï¼‰\n",
        "- âœ… 200è¡Œä»£ç \n",
        "- âœ… åŠå¤©æ—¶é—´\n",
        "\n",
        "### âœ… ä¸éœ€è¦ï¼ˆåˆæœŸï¼‰\n",
        "\n",
        "- âŒ å¤æ‚çš„å‘é‡æ•°æ®åº“\n",
        "- âŒ LangChainæ¡†æ¶\n",
        "- âŒ ç”Ÿäº§çº§éƒ¨ç½²\n",
        "- âŒ åˆ†å¸ƒå¼æ¶æ„\n",
        "\n",
        "### âœ… å­¦ä¹ å»ºè®®\n",
        "\n",
        "1. **å…ˆè·‘é€šï¼Œå†ä¼˜åŒ–**\n",
        "   - ä¸è¦ä¸€å¼€å§‹å°±è¿½æ±‚å®Œç¾\n",
        "   - å…ˆå®ç°æœ€ç®€ç‰ˆæœ¬\n",
        "   - ç†è§£åŸç†åå†æ”¹è¿›\n",
        "\n",
        "2. **åŠ¨æ‰‹æœ€é‡è¦**\n",
        "   - çœ‹100éä¸å¦‚å†™1é\n",
        "   - é‡åˆ°é—®é¢˜ç°æŸ¥æ–‡æ¡£\n",
        "   - è¾¹åšè¾¹å­¦æ•ˆç‡æœ€é«˜\n",
        "\n",
        "3. **ä»ç®€å•æ–‡æ¡£å¼€å§‹**\n",
        "   - å…ˆç”¨txtæ–‡ä»¶æµ‹è¯•\n",
        "   - ä¸è¦ä¸€å¼€å§‹å°±å¤„ç†PDFã€Word\n",
        "   - æ–‡æ¡£å†…å®¹è¦å°‘ï¼ˆå‡ åƒå­—å³å¯ï¼‰\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ ä¸‹ä¸€æ­¥è¡ŒåŠ¨æ¸…å•\n",
        "\n",
        "### ä»Šå¤©å°±å¯ä»¥åšçš„ï¼ˆ1-2å°æ—¶ï¼‰\n",
        "\n",
        "- [ ] åˆ›å»ºé¡¹ç›®ç›®å½•\n",
        "- [ ] å®‰è£…ä¾èµ–ï¼ˆpip installï¼‰\n",
        "- [ ] åˆ›å»º2-3ä¸ªæµ‹è¯•æ–‡æ¡£\n",
        "- [ ] å‡†å¤‡APIå¯†é’¥ï¼ˆOpenAIæˆ–æ›¿ä»£å“ï¼‰\n",
        "- [ ] å¤åˆ¶æœ¬æ–‡æ¡£çš„ä»£ç \n",
        "\n",
        "### æœ¬å‘¨å®Œæˆï¼ˆ2-3å¤©ï¼‰\n",
        "\n",
        "- [ ] è·‘é€šå®Œæ•´æµç¨‹\n",
        "- [ ] æµ‹è¯•10ä¸ªä¸åŒé—®é¢˜\n",
        "- [ ] ç†è§£æ¯è¡Œä»£ç çš„å«ä¹‰\n",
        "- [ ] å®Œæˆä»»åŠ¡1ï¼ˆåŸºç¡€ç‰ˆï¼‰\n",
        "- [ ] å°è¯•ä»»åŠ¡2ï¼ˆæ”¹è¿›ç‰ˆï¼‰\n",
        "\n",
        "### ä¸‹å‘¨ç›®æ ‡ï¼ˆ1å‘¨ï¼‰\n",
        "\n",
        "- [ ] å­¦ä¹ LangChainåŸºç¡€\n",
        "- [ ] æ¥å…¥ChromaDB\n",
        "- [ ] æ”¯æŒPDFæ–‡æ¡£\n",
        "- [ ] åšä¸€ä¸ªç®€å•çš„Webç•Œé¢\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… å‡†å¤‡å¥½å¼€å§‹äº†å—ï¼Ÿ\n",
        "\n",
        "**ç°åœ¨å°±åŠ¨æ‰‹å§ï¼** ğŸš€\n",
        "\n",
        "è®°ä½ï¼š\n",
        "- é‡åˆ°é—®é¢˜å¾ˆæ­£å¸¸ï¼Œå¤šæŸ¥æ–‡æ¡£\n",
        "- ä»æœ€ç®€å•çš„å¼€å§‹\n",
        "- æ¯å¤©è¿›æ­¥ä¸€ç‚¹ç‚¹\n",
        "\n",
        "**ç¥æ‚¨å­¦ä¹ é¡ºåˆ©ï¼** ğŸ’ª\n",
        "\n",
        "---\n",
        "\n",
        "**æ–‡æ¡£åˆ›å»ºæ—¶é—´ï¼š** 2025-11-21  \n",
        "**ä½œè€…ï¼š** AI Assistant  \n",
        "**ç‰ˆæœ¬ï¼š** 1.0\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
