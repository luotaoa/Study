{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ“š è¯å‘é‡æ˜¯å¦‚ä½•è®­ç»ƒå‡ºæ¥çš„ï¼Ÿ\n",
        "\n",
        "## ğŸ¯ æ ¸å¿ƒé—®é¢˜\n",
        "\n",
        "**æ–‡å­—æ˜¯å¦‚ä½•è½¬æ¢æˆå‘é‡çš„ï¼Ÿ**\n",
        "\n",
        "ç®€å•å›ç­”ï¼š\n",
        "- âœ… æ˜¯çš„ï¼Œ**é€šè¿‡å¤§é‡æ•°æ®è®­ç»ƒå‡ºæ¥çš„**\n",
        "- âŒ ä¸æ˜¯\"è§„å®š\"çš„ï¼Œè€Œæ˜¯æ¨¡å‹**è‡ªå·±å­¦ä¹ **å‡ºæ¥çš„\n",
        "- ğŸ“ è¿™ä¸ªè¿‡ç¨‹å«åš **\"å­¦ä¹ è¯å‘é‡\"ï¼ˆWord Embeddingsï¼‰**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ’¡ ä»æœ€ç®€å•çš„ä¾‹å­å¼€å§‹\n",
        "\n",
        "### 1ï¸âƒ£ æœ€åŸå§‹çš„æ–¹æ³•ï¼šOne-Hotç¼–ç ï¼ˆä¸å¥½ç”¨ï¼‰\n",
        "\n",
        "å‡è®¾æˆ‘ä»¬æœ‰è¯æ±‡è¡¨ï¼š`[\"æˆ‘\", \"çˆ±\", \"å­¦ä¹ \", \"ç¼–ç¨‹\", \"AI\"]`\n",
        "\n",
        "**One-Hotç¼–ç ï¼ˆç‹¬çƒ­ç¼–ç ï¼‰ï¼š**\n",
        "```\n",
        "\"æˆ‘\"    â†’ [1, 0, 0, 0, 0]\n",
        "\"çˆ±\"    â†’ [0, 1, 0, 0, 0]\n",
        "\"å­¦ä¹ \"  â†’ [0, 0, 1, 0, 0]\n",
        "\"ç¼–ç¨‹\"  â†’ [0, 0, 0, 1, 0]\n",
        "\"AI\"    â†’ [0, 0, 0, 0, 1]\n",
        "```\n",
        "\n",
        "**é—®é¢˜ï¼š**\n",
        "- âŒ å‘é‡å¤ªé•¿ï¼ˆè¯æ±‡é‡æœ‰å‡ ä¸‡ä¸ªï¼Œå‘é‡å°±æœ‰å‡ ä¸‡ç»´ï¼‰\n",
        "- âŒ æ²¡æœ‰è¯­ä¹‰ä¿¡æ¯ï¼ˆ\"çˆ±\"å’Œ\"å–œæ¬¢\"åº”è¯¥ç›¸ä¼¼ï¼Œä½†å‘é‡å®Œå…¨ä¸åŒï¼‰\n",
        "- âŒ ç¨€ç–ï¼ˆå…¨æ˜¯0ï¼Œåªæœ‰ä¸€ä¸ª1ï¼‰\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# è®¾ç½®ä¸­æ–‡å­—ä½“\n",
        "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# æ¼”ç¤ºOne-Hotç¼–ç \n",
        "vocab = [\"æˆ‘\", \"çˆ±\", \"å­¦ä¹ \", \"ç¼–ç¨‹\", \"AI\"]\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "def one_hot_encode(word, vocab):\n",
        "    \"\"\"One-Hotç¼–ç \"\"\"\n",
        "    vector = np.zeros(len(vocab))\n",
        "    if word in vocab:\n",
        "        idx = vocab.index(word)\n",
        "        vector[idx] = 1\n",
        "    return vector\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"âŒ One-Hotç¼–ç çš„é—®é¢˜\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for word in vocab:\n",
        "    vec = one_hot_encode(word, vocab)\n",
        "    print(f\"'{word}' â†’ {vec}\")\n",
        "\n",
        "# è®¡ç®—ç›¸ä¼¼åº¦\n",
        "vec_love = one_hot_encode(\"çˆ±\", vocab)\n",
        "vec_learn = one_hot_encode(\"å­¦ä¹ \", vocab)\n",
        "\n",
        "similarity = np.dot(vec_love, vec_learn)\n",
        "print(f\"\\n'çˆ±'å’Œ'å­¦ä¹ 'çš„ç›¸ä¼¼åº¦: {similarity}\")\n",
        "print(\"âŒ å®Œå…¨ä¸ç›¸ä¼¼ï¼ä½†å®ƒä»¬åœ¨è¯­ä¹‰ä¸Šå¯èƒ½æœ‰å…³è”...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸš€ 2ï¸âƒ£ ç°ä»£æ–¹æ³•ï¼šè®­ç»ƒè¯å‘é‡ï¼ˆå¥½ç”¨ï¼ï¼‰\n",
        "\n",
        "### æ ¸å¿ƒæ€æƒ³ï¼š**\"ä½ å¯ä»¥é€šè¿‡ä¸€ä¸ªè¯çš„é‚»å±…äº†è§£è¿™ä¸ªè¯\"**\n",
        "\n",
        "**ä¾‹å­ï¼š**\n",
        "```\n",
        "\"æˆ‘å–œæ¬¢åƒè‹¹æœ\"  â† \"è‹¹æœ\"çš„é‚»å±…æ˜¯\"åƒ\"\n",
        "\"æˆ‘å–œæ¬¢åƒé¦™è•‰\"  â† \"é¦™è•‰\"çš„é‚»å±…æ˜¯\"åƒ\"\n",
        "â†’ \"è‹¹æœ\"å’Œ\"é¦™è•‰\"åº”è¯¥ç›¸ä¼¼ï¼\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### è®­ç»ƒè¿‡ç¨‹ï¼ˆä»¥Word2Vecä¸ºä¾‹ï¼‰\n",
        "\n",
        "#### Step 1: å‡†å¤‡å¤§é‡æ–‡æœ¬æ•°æ®\n",
        "```\n",
        "æˆ‘çˆ±å­¦ä¹ ç¼–ç¨‹\n",
        "æˆ‘å–œæ¬¢å­¦ä¹ AI\n",
        "ç¼–ç¨‹å¾ˆæœ‰è¶£\n",
        "AIæ”¹å˜ä¸–ç•Œ\n",
        "...\n",
        "ï¼ˆç™¾ä¸‡ã€åƒä¸‡ä¸ªå¥å­ï¼‰\n",
        "```\n",
        "\n",
        "#### Step 2: ç¥ç»ç½‘ç»œå­¦ä¹ \n",
        "```\n",
        "ç›®æ ‡ï¼šæ ¹æ®ä¸Šä¸‹æ–‡é¢„æµ‹ç›®æ ‡è¯\n",
        "\n",
        "è¾“å…¥ï¼š\"æˆ‘\" \"å­¦ä¹ \"  ï¼ˆä¸Šä¸‹æ–‡ï¼‰\n",
        "è¾“å‡ºï¼š\"çˆ±\"          ï¼ˆç›®æ ‡è¯ï¼‰\n",
        "\n",
        "è®­ç»ƒè¿‡ç¨‹ï¼š\n",
        "1. éšæœºåˆå§‹åŒ–æ¯ä¸ªè¯çš„å‘é‡\n",
        "2. ç”¨ç¥ç»ç½‘ç»œå­¦ä¹ \n",
        "3. è°ƒæ•´å‘é‡ï¼Œè®©é¢„æµ‹æ›´å‡†ç¡®\n",
        "4. é‡å¤ç™¾ä¸‡æ¬¡\n",
        "```\n",
        "\n",
        "#### Step 3: å¾—åˆ°è¯å‘é‡\n",
        "```\n",
        "\"æˆ‘\"    â†’ [0.2, 0.5, -0.1, 0.8, ...]  ï¼ˆ300ç»´ï¼‰\n",
        "\"çˆ±\"    â†’ [0.3, 0.4, -0.2, 0.7, ...]  ï¼ˆ300ç»´ï¼‰\n",
        "\"å­¦ä¹ \"  â†’ [0.25, 0.45, -0.15, 0.75, ...]\n",
        "```\n",
        "\n",
        "**ç¥å¥‡çš„åœ°æ–¹ï¼š**\n",
        "- âœ… è¯­ä¹‰ç›¸ä¼¼çš„è¯ï¼Œå‘é‡ä¹Ÿç›¸ä¼¼ï¼\n",
        "- âœ… \"çˆ±\"å’Œ\"å–œæ¬¢\"çš„å‘é‡å¾ˆæ¥è¿‘\n",
        "- âœ… ç”šè‡³æœ‰æ•°å­¦å…³ç³»ï¼š`å‘é‡(\"å›½ç‹\") - å‘é‡(\"ç”·äºº\") + å‘é‡(\"å¥³äºº\") â‰ˆ å‘é‡(\"å¥³ç‹\")`\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”¬ ä¸‰ç§ä¸»æµçš„è®­ç»ƒæ–¹æ³•\n",
        "\n",
        "### æ–¹æ³•1: Word2Vecï¼ˆ2013å¹´ï¼‰\n",
        "\n",
        "**åŸç†ï¼š** é€šè¿‡é¢„æµ‹ä¸Šä¸‹æ–‡æ¥å­¦ä¹ \n",
        "\n",
        "**ä¸¤ç§æ¨¡å¼ï¼š**\n",
        "1. **CBOWï¼ˆè¿ç»­è¯è¢‹ï¼‰ï¼š** ç”¨å‘¨å›´çš„è¯é¢„æµ‹ä¸­å¿ƒè¯\n",
        "   ```\n",
        "   è¾“å…¥ï¼š[\"æˆ‘\", \"å­¦ä¹ \", \"ç¼–ç¨‹\"] \n",
        "   è¾“å‡ºï¼š\"çˆ±\"\n",
        "   ```\n",
        "\n",
        "2. **Skip-gramï¼š** ç”¨ä¸­å¿ƒè¯é¢„æµ‹å‘¨å›´çš„è¯\n",
        "   ```\n",
        "   è¾“å…¥ï¼š\"çˆ±\"\n",
        "   è¾“å‡ºï¼š[\"æˆ‘\", \"å­¦ä¹ \", \"ç¼–ç¨‹\"]\n",
        "   ```\n",
        "\n",
        "**è®­ç»ƒæ•°æ®ï¼š** ç»´åŸºç™¾ç§‘ã€æ–°é—»æ–‡ç« ç­‰ï¼ˆæ•°åäº¿ä¸ªè¯ï¼‰\n",
        "\n",
        "**è¾“å‡ºï¼š** æ¯ä¸ªè¯ä¸€ä¸ªå›ºå®šçš„å‘é‡ï¼ˆé€šå¸¸300ç»´ï¼‰\n",
        "\n",
        "---\n",
        "\n",
        "### æ–¹æ³•2: GloVeï¼ˆ2014å¹´ï¼‰\n",
        "\n",
        "**åŸç†ï¼š** åŸºäºè¯çš„å…±ç°ç»Ÿè®¡\n",
        "\n",
        "```\n",
        "ç»Ÿè®¡ï¼š\"è‹¹æœ\"å’Œ\"åƒ\"åœ¨æ–‡æœ¬ä¸­ä¸€èµ·å‡ºç°äº†1000æ¬¡\n",
        "     \"è‹¹æœ\"å’Œ\"ç”µè„‘\"ä¸€èµ·å‡ºç°äº†50æ¬¡\n",
        "â†’ \"è‹¹æœ\"æ›´å¯èƒ½å’Œ\"åƒ\"ç›¸å…³ï¼ˆæ°´æœä¹‰ï¼‰\n",
        "```\n",
        "\n",
        "**è®­ç»ƒæ•°æ®ï¼š** åŒæ ·æ˜¯å¤§é‡æ–‡æœ¬\n",
        "\n",
        "---\n",
        "\n",
        "### æ–¹æ³•3: Transformer-based Embeddingsï¼ˆ2018å¹´è‡³ä»Šï¼‰â­\n",
        "\n",
        "**ä»£è¡¨ï¼š** BERT, GPT, OpenAI Embeddings\n",
        "\n",
        "**è¿›åŒ–ï¼š** ä¸å†æ˜¯\"ä¸€è¯ä¸€å‘é‡\"ï¼\n",
        "\n",
        "```\n",
        "ä¾‹å­ï¼š\n",
        "\"æˆ‘åœ¨é“¶è¡Œå·¥ä½œ\"     â† \"é“¶è¡Œ\"è¡¨ç¤ºé‡‘èæœºæ„\n",
        "\"æˆ‘ååœ¨æ²³é“¶è¡Œ\"     â† \"é“¶è¡Œ\"è¡¨ç¤ºæ²³è¾¹\n",
        "\n",
        "Word2Vec: \"é“¶è¡Œ\"æ°¸è¿œæ˜¯åŒä¸€ä¸ªå‘é‡ âŒ\n",
        "BERT:     \"é“¶è¡Œ\"æ ¹æ®ä¸Šä¸‹æ–‡æœ‰ä¸åŒå‘é‡ âœ…\n",
        "```\n",
        "\n",
        "**è®­ç»ƒæ–¹å¼ï¼š**\n",
        "1. **é¢„è®­ç»ƒï¼š** åœ¨æµ·é‡æ–‡æœ¬ä¸Šå­¦ä¹ ï¼ˆå¦‚æ•´ä¸ªäº’è”ç½‘çš„æ–‡æœ¬ï¼‰\n",
        "2. **æ©ç è¯­è¨€æ¨¡å‹ï¼š** é®ä½ä¸€äº›è¯ï¼Œè®©æ¨¡å‹é¢„æµ‹\n",
        "   ```\n",
        "   \"æˆ‘[MASK]å­¦ä¹ ç¼–ç¨‹\" â†’ é¢„æµ‹\"çˆ±\"æˆ–\"å–œæ¬¢\"\n",
        "   ```\n",
        "\n",
        "**è¾“å‡ºï¼š** æ•´ä¸ªå¥å­çš„å‘é‡è¡¨ç¤ºï¼ˆé€šå¸¸768ç»´æˆ–æ›´é«˜ï¼‰\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ RAGä¸­ä½¿ç”¨çš„Embeddingæ¨¡å‹\n",
        "\n",
        "### å¸¸ç”¨æ¨¡å‹ï¼š\n",
        "\n",
        "| æ¨¡å‹ | ç»´åº¦ | ç‰¹ç‚¹ | è®­ç»ƒæ•°æ®è§„æ¨¡ |\n",
        "|------|------|------|-------------|\n",
        "| **OpenAI text-embedding-ada-002** | 1536 | æœ€å¸¸ç”¨ | æ•°åƒäº¿token |\n",
        "| **BERT-base** | 768 | å¼€æº | 33äº¿è¯ |\n",
        "| **Sentence-BERT** | 768 | ä¸“é—¨ä¼˜åŒ–å¥å­ç›¸ä¼¼åº¦ | æ•°åäº¿å¥å­å¯¹ |\n",
        "| **M3Eï¼ˆä¸­æ–‡ï¼‰** | 768 | ä¸­æ–‡ä¼˜åŒ– | æ•°åäº¿ä¸­æ–‡token |\n",
        "| **bgeï¼ˆä¸­æ–‡ï¼‰** | 1024 | ä¸­æ–‡æœ€å¼º | ç™¾äº¿ä¸­æ–‡token |\n",
        "\n",
        "---\n",
        "\n",
        "### è®­ç»ƒè§„æ¨¡å¯¹æ¯”ï¼š\n",
        "\n",
        "```\n",
        "ğŸ“Š è®­ç»ƒæ•°æ®è§„æ¨¡ï¼š\n",
        "\n",
        "Word2Vec (2013):  \n",
        "  â””â”€ æ•°åäº¿è¯\n",
        "\n",
        "BERT (2018):\n",
        "  â””â”€ 33äº¿è¯ï¼ˆè‹±æ–‡ç»´åŸºç™¾ç§‘ + BookCorpusï¼‰\n",
        "\n",
        "GPT-3 (2020):\n",
        "  â””â”€ 3000äº¿è¯ï¼ˆå‡ ä¹æ•´ä¸ªäº’è”ç½‘ï¼‰\n",
        "\n",
        "OpenAI Embeddings (2022):\n",
        "  â””â”€ æ•°åƒäº¿tokenï¼ˆåŒ…æ‹¬ä»£ç ã€è®ºæ–‡ã€ç½‘é¡µç­‰ï¼‰\n",
        "```\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ§ª å®æˆ˜æ¼”ç¤ºï¼šç”¨Pythonè·å–è¯å‘é‡\n",
        "\n",
        "### æ–¹æ³•1: ä½¿ç”¨é¢„è®­ç»ƒçš„Word2Vec\n",
        "\n",
        "```python\n",
        "# éœ€è¦å®‰è£…: pip install gensim\n",
        "import gensim.downloader as api\n",
        "\n",
        "# ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆGoogleåœ¨1000äº¿è¯ä¸Šè®­ç»ƒçš„ï¼‰\n",
        "model = api.load(\"word2vec-google-news-300\")\n",
        "\n",
        "# è·å–è¯å‘é‡\n",
        "vector = model['computer']  # 300ç»´å‘é‡\n",
        "print(vector)\n",
        "\n",
        "# æ‰¾ç›¸ä¼¼è¯\n",
        "similar = model.most_similar('computer')\n",
        "# è¾“å‡º: ['computers', 'software', 'hardware', ...]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### æ–¹æ³•2: ä½¿ç”¨OpenAI APIï¼ˆRAGæœ€å¸¸ç”¨ï¼‰\n",
        "\n",
        "```python\n",
        "# éœ€è¦å®‰è£…: pip install openai\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=\"your-api-key\")\n",
        "\n",
        "# è·å–æ–‡æœ¬çš„embedding\n",
        "text = \"äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œ\"\n",
        "response = client.embeddings.create(\n",
        "    model=\"text-embedding-ada-002\",\n",
        "    input=text\n",
        ")\n",
        "\n",
        "vector = response.data[0].embedding  # 1536ç»´å‘é‡\n",
        "print(f\"å‘é‡ç»´åº¦: {len(vector)}\")\n",
        "print(f\"å‰5ä¸ªå€¼: {vector[:5]}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### æ–¹æ³•3: ä½¿ç”¨HuggingFaceï¼ˆå¼€æºå…è´¹ï¼‰\n",
        "\n",
        "```python\n",
        "# éœ€è¦å®‰è£…: pip install sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# åŠ è½½æ¨¡å‹ï¼ˆç¬¬ä¸€æ¬¡ä¼šä¸‹è½½ï¼‰\n",
        "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
        "\n",
        "# è·å–å¥å­embedding\n",
        "sentences = [\"æˆ‘å–œæ¬¢ç¼–ç¨‹\", \"æˆ‘çƒ­çˆ±å†™ä»£ç \", \"ä»Šå¤©å¤©æ°”å¾ˆå¥½\"]\n",
        "embeddings = model.encode(sentences)\n",
        "\n",
        "print(f\"å‘é‡ç»´åº¦: {embeddings.shape}\")  # (3, 384)\n",
        "\n",
        "# è®¡ç®—ç›¸ä¼¼åº¦\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "similarities = cosine_similarity(embeddings)\n",
        "print(similarities)\n",
        "# å‰ä¸¤å¥ç›¸ä¼¼åº¦å¾ˆé«˜ï¼\n",
        "```\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ“Š ç®€åŒ–æ¼”ç¤ºï¼šæ¨¡æ‹Ÿè¯å‘é‡çš„è®­ç»ƒè¿‡ç¨‹\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"ğŸ“ æ¨¡æ‹ŸWord2Vecè®­ç»ƒï¼ˆç®€åŒ–ç‰ˆï¼‰\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# å‡è®¾æˆ‘ä»¬æœ‰è¿™äº›è®­ç»ƒæ•°æ®\n",
        "training_data = [\n",
        "    \"æˆ‘ çˆ± å­¦ä¹  ç¼–ç¨‹\",\n",
        "    \"æˆ‘ å–œæ¬¢ å­¦ä¹  AI\",\n",
        "    \"ç¼–ç¨‹ å¾ˆ æœ‰è¶£\",\n",
        "    \"AI å¾ˆ å¼ºå¤§\",\n",
        "    \"æˆ‘ çˆ± ç¼–ç¨‹ å’Œ AI\",\n",
        "    \"å­¦ä¹  ç¼–ç¨‹ å¾ˆ æœ‰è¶£\",\n",
        "]\n",
        "\n",
        "# æ„å»ºè¯æ±‡è¡¨\n",
        "vocab = set()\n",
        "for sentence in training_data:\n",
        "    vocab.update(sentence.split())\n",
        "vocab = sorted(list(vocab))\n",
        "\n",
        "print(f\"\\nè¯æ±‡è¡¨ï¼ˆ{len(vocab)}ä¸ªè¯ï¼‰: {vocab}\")\n",
        "\n",
        "# éšæœºåˆå§‹åŒ–è¯å‘é‡ï¼ˆç»´åº¦=3ï¼Œæ–¹ä¾¿å¯è§†åŒ–ï¼‰\n",
        "np.random.seed(42)\n",
        "word_vectors = {}\n",
        "for word in vocab:\n",
        "    word_vectors[word] = np.random.randn(3)\n",
        "\n",
        "print(\"\\nåˆå§‹è¯å‘é‡ï¼ˆéšæœºï¼‰:\")\n",
        "for word in [\"æˆ‘\", \"çˆ±\", \"AI\"]:\n",
        "    print(f\"'{word}': {word_vectors[word]}\")\n",
        "\n",
        "print(\"\\nğŸ’¡ çœŸå®è®­ç»ƒä¸­ï¼š\")\n",
        "print(\"  1. æ¨¡å‹ä¼šçœ‹æ•°ç™¾ä¸‡ä¸ªå¥å­\")\n",
        "print(\"  2. é€šè¿‡ç¥ç»ç½‘ç»œä¸æ–­è°ƒæ•´è¿™äº›å‘é‡\")\n",
        "print(\"  3. è®©ç»å¸¸ä¸€èµ·å‡ºç°çš„è¯çš„å‘é‡æ›´ç›¸ä¼¼\")\n",
        "print(\"  4. æœ€ç»ˆå¾—åˆ°æœ‰æ„ä¹‰çš„è¯å‘é‡\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ¨ å¯è§†åŒ–ï¼šå‡è®¾æˆ‘ä»¬å·²ç»è®­ç»ƒå¥½äº†è¯å‘é‡\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ¨ è®­ç»ƒåçš„è¯å‘é‡ï¼ˆå‡è®¾ï¼‰\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# å‡è®¾è¿™æ˜¯è®­ç»ƒå¥½çš„å‘é‡ï¼ˆä¸ºäº†å¯è§†åŒ–ï¼Œæˆ‘ä»¬æ‰‹åŠ¨è®¾ç½®äº†æœ‰æ„ä¹‰çš„å€¼ï¼‰\n",
        "trained_vectors = {\n",
        "    \"æˆ‘\": np.array([0.8, 0.2, 0.1]),\n",
        "    \"çˆ±\": np.array([0.3, 0.9, 0.2]),\n",
        "    \"å–œæ¬¢\": np.array([0.35, 0.85, 0.25]),  # å’Œ\"çˆ±\"å¾ˆç›¸ä¼¼ï¼\n",
        "    \"å­¦ä¹ \": np.array([0.2, 0.3, 0.8]),\n",
        "    \"ç¼–ç¨‹\": np.array([0.1, 0.25, 0.9]),  # å’Œ\"å­¦ä¹ \"ç›¸ä¼¼\n",
        "    \"AI\": np.array([0.15, 0.2, 0.85]),   # å’Œ\"ç¼–ç¨‹\"ç›¸ä¼¼\n",
        "    \"æœ‰è¶£\": np.array([0.5, 0.7, 0.4]),\n",
        "    \"å¼ºå¤§\": np.array([0.6, 0.65, 0.5]),  # å’Œ\"æœ‰è¶£\"æœ‰ç‚¹ç›¸ä¼¼\n",
        "}\n",
        "\n",
        "# è®¡ç®—ç›¸ä¼¼åº¦\n",
        "def cosine_sim(v1, v2):\n",
        "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
        "\n",
        "print(\"\\nğŸ“Š è¯è¯­ç›¸ä¼¼åº¦ï¼š\")\n",
        "pairs = [\n",
        "    (\"çˆ±\", \"å–œæ¬¢\"),\n",
        "    (\"å­¦ä¹ \", \"ç¼–ç¨‹\"),\n",
        "    (\"ç¼–ç¨‹\", \"AI\"),\n",
        "    (\"çˆ±\", \"ç¼–ç¨‹\"),\n",
        "]\n",
        "\n",
        "for w1, w2 in pairs:\n",
        "    sim = cosine_sim(trained_vectors[w1], trained_vectors[w2])\n",
        "    print(f\"'{w1}' â†” '{w2}': {sim:.3f}\")\n",
        "\n",
        "print(\"\\nâœ… çœ‹ï¼è¯­ä¹‰ç›¸ä¼¼çš„è¯ï¼Œå‘é‡ä¹Ÿç›¸ä¼¼äº†ï¼\")\n",
        "\n",
        "# 3Då¯è§†åŒ–\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# ç»˜åˆ¶è¯å‘é‡\n",
        "colors = ['red', 'blue', 'blue', 'green', 'green', 'green', 'orange', 'orange']\n",
        "for i, (word, vec) in enumerate(trained_vectors.items()):\n",
        "    ax.scatter(vec[0], vec[1], vec[2], c=colors[i], s=200, alpha=0.6)\n",
        "    ax.text(vec[0], vec[1], vec[2], word, fontsize=14, fontweight='bold')\n",
        "    # ç»˜åˆ¶ä»åŸç‚¹åˆ°è¯å‘é‡çš„ç®­å¤´\n",
        "    ax.quiver(0, 0, 0, vec[0], vec[1], vec[2], \n",
        "             color=colors[i], alpha=0.3, arrow_length_ratio=0.1)\n",
        "\n",
        "ax.set_xlabel('ç»´åº¦1', fontsize=12)\n",
        "ax.set_ylabel('ç»´åº¦2', fontsize=12)\n",
        "ax.set_zlabel('ç»´åº¦3', fontsize=12)\n",
        "ax.set_title('è¯å‘é‡çš„3Då¯è§†åŒ–\\nï¼ˆç›¸ä¼¼çš„è¯é å¾—æ›´è¿‘ï¼‰', fontsize=14, fontweight='bold')\n",
        "\n",
        "# è®¾ç½®å›¾ä¾‹\n",
        "from matplotlib.patches import Patch\n",
        "legend_elements = [\n",
        "    Patch(facecolor='red', label='äººç§°'),\n",
        "    Patch(facecolor='blue', label='æƒ…æ„ŸåŠ¨è¯'),\n",
        "    Patch(facecolor='green', label='æŠ€æœ¯è¯æ±‡'),\n",
        "    Patch(facecolor='orange', label='å½¢å®¹è¯')\n",
        "]\n",
        "ax.legend(handles=legend_elements, loc='upper right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nğŸ’¡ è§‚å¯Ÿï¼š\")\n",
        "print(\"  - 'çˆ±'å’Œ'å–œæ¬¢'ï¼ˆè“è‰²ï¼‰é å¾—å¾ˆè¿‘\")\n",
        "print(\"  - 'å­¦ä¹ 'ã€'ç¼–ç¨‹'ã€'AI'ï¼ˆç»¿è‰²ï¼‰èšåœ¨ä¸€èµ·\")\n",
        "print(\"  - 'æœ‰è¶£'å’Œ'å¼ºå¤§'ï¼ˆæ©™è‰²ï¼‰ä¹Ÿæ¯”è¾ƒæ¥è¿‘\")\n",
        "print(\"  â†’ è¿™å°±æ˜¯è®­ç»ƒçš„ç»“æœï¼\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ æ€»ç»“ï¼šæ–‡å­—å¦‚ä½•å˜æˆå‘é‡\n",
        "\n",
        "### âœ… å›ç­”ä½ çš„é—®é¢˜ï¼š\n",
        "\n",
        "**1. æ˜¯å¤§é‡æ•°æ®è®­ç»ƒå‡ºæ¥çš„å—ï¼Ÿ**\n",
        "- âœ… **æ˜¯çš„ï¼** éœ€è¦æ•°åäº¿ç”šè‡³æ•°åƒäº¿ä¸ªè¯çš„è®­ç»ƒæ•°æ®\n",
        "- è®­ç»ƒæ—¶é—´ï¼šå‡ å¤©åˆ°å‡ å‘¨ï¼ˆç”¨å¤§é‡GPUï¼‰\n",
        "\n",
        "**2. æ˜¯è§„å®šçš„å—ï¼Ÿ**\n",
        "- âŒ **ä¸æ˜¯ï¼** ä¸æ˜¯äººä¸ºè§„å®šï¼Œè€Œæ˜¯æ¨¡å‹è‡ªå·±å­¦ä¹ çš„\n",
        "- ç ”ç©¶äººå‘˜åªè®¾è®¡äº†è®­ç»ƒæ–¹æ³•ï¼Œå…·ä½“çš„å‘é‡å€¼æ˜¯æ¨¡å‹å­¦å‡ºæ¥çš„\n",
        "\n",
        "**3. å‘é‡çš„ç»´åº¦æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ**\n",
        "- æ¯ä¸ªç»´åº¦æ²¡æœ‰æ˜ç¡®çš„å«ä¹‰ï¼ˆä¸åƒ\"é•¿åº¦\"ã€\"å®½åº¦\"è¿™æ ·çš„ç‰©ç†ç»´åº¦ï¼‰\n",
        "- ä½†æ•´ä½“ä¸Šæ•æ‰äº†è¯çš„è¯­ä¹‰ä¿¡æ¯\n",
        "- å¸¸è§ç»´åº¦ï¼š100-300ï¼ˆWord2Vecï¼‰ã€768ï¼ˆBERTï¼‰ã€1536ï¼ˆOpenAIï¼‰\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¥ å…³é”®è¦ç‚¹ï¼š\n",
        "\n",
        "```\n",
        "è®­ç»ƒè¿‡ç¨‹ï¼ˆç®€åŒ–ï¼‰ï¼š\n",
        "\n",
        "1. è¾“å…¥ï¼šå¤§é‡æ–‡æœ¬ï¼ˆç»´åŸºç™¾ç§‘ã€æ–°é—»ã€ä¹¦ç±...ï¼‰\n",
        "   â””â”€ \"æˆ‘çˆ±å­¦ä¹ ç¼–ç¨‹\"\n",
        "   â””â”€ \"AIæ”¹å˜ä¸–ç•Œ\"\n",
        "   â””â”€ ...\n",
        "\n",
        "2. è®­ç»ƒä»»åŠ¡ï¼š\n",
        "   æ–¹æ¡ˆA: æ ¹æ®ä¸Šä¸‹æ–‡é¢„æµ‹ç›®æ ‡è¯ (Word2Vec)\n",
        "   æ–¹æ¡ˆB: å¡«ç©ºé¢˜ (BERT)\n",
        "   æ–¹æ¡ˆC: ç»­å†™å¥å­ (GPT)\n",
        "\n",
        "3. å­¦ä¹ è¿‡ç¨‹ï¼š\n",
        "   â””â”€ éšæœºåˆå§‹åŒ–æ¯ä¸ªè¯çš„å‘é‡\n",
        "   â””â”€ ç”¨ç¥ç»ç½‘ç»œåšé¢„æµ‹\n",
        "   â””â”€ é¢„æµ‹é”™äº†å°±è°ƒæ•´å‘é‡\n",
        "   â””â”€ é‡å¤æ•°ç™¾ä¸‡æ¬¡\n",
        "\n",
        "4. è¾“å‡ºï¼šè®­ç»ƒå¥½çš„è¯å‘é‡\n",
        "   â””â”€ \"çˆ±\" â†’ [0.31, 0.89, -0.21, ...]\n",
        "   â””â”€ \"å–œæ¬¢\" â†’ [0.35, 0.85, -0.18, ...]\n",
        "   â””â”€ ç›¸ä¼¼çš„è¯ï¼Œå‘é‡ä¹Ÿç›¸ä¼¼ï¼\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ¯ åœ¨RAGä¸­çš„åº”ç”¨ï¼š\n",
        "\n",
        "```python\n",
        "# RAGçš„å®Œæ•´æµç¨‹ï¼š\n",
        "\n",
        "1. å‡†å¤‡æ–‡æ¡£ï¼š\n",
        "   doc1 = \"Pythonæ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€\"\n",
        "   doc2 = \"AIå¯ä»¥å¸®åŠ©å†™ä»£ç \"\n",
        "   doc3 = \"ä»Šå¤©å¤©æ°”å¾ˆå¥½\"\n",
        "\n",
        "2. ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è½¬æˆå‘é‡ï¼š\n",
        "   vec1 = embedding_model.encode(doc1)  # [0.2, 0.8, ...]\n",
        "   vec2 = embedding_model.encode(doc2)  # [0.25, 0.75, ...]\n",
        "   vec3 = embedding_model.encode(doc3)  # [0.9, 0.1, ...]\n",
        "\n",
        "3. ç”¨æˆ·æé—®ï¼š\n",
        "   query = \"å¦‚ä½•å­¦ä¹ ç¼–ç¨‹ï¼Ÿ\"\n",
        "   query_vec = embedding_model.encode(query)  # [0.22, 0.78, ...]\n",
        "\n",
        "4. è®¡ç®—ç›¸ä¼¼åº¦ï¼Œæ‰¾æœ€ç›¸å…³æ–‡æ¡£ï¼š\n",
        "   similarity1 = cosine_similarity(query_vec, vec1)  # 0.95 âœ…\n",
        "   similarity2 = cosine_similarity(query_vec, vec2)  # 0.82\n",
        "   similarity3 = cosine_similarity(query_vec, vec3)  # 0.12\n",
        "   \n",
        "   â†’ è¿”å›doc1ï¼ˆæœ€ç›¸å…³ï¼‰\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ’ª ä¸‹ä¸€æ­¥å­¦ä¹ ï¼š\n",
        "\n",
        "1. âœ… ä½ å·²ç»ç†è§£äº†è¯å‘é‡çš„åŸç†\n",
        "2. âœ… ä½ çŸ¥é“äº†ä½™å¼¦ç›¸ä¼¼åº¦çš„ä½œç”¨\n",
        "3. ğŸ“š æ¥ä¸‹æ¥å¯ä»¥å­¦ä¹ ï¼š\n",
        "   - å¦‚ä½•ä½¿ç”¨OpenAI APIè·å–embedding\n",
        "   - å¦‚ä½•å»ºç«‹å‘é‡æ•°æ®åº“ï¼ˆChroma, Milvusï¼‰\n",
        "   - å¦‚ä½•å®ç°å®Œæ•´çš„RAGç³»ç»Ÿ\n",
        "\n",
        "**æŸ¥çœ‹ï¼š** `RAGä¸Agentå­¦ä¹ è·¯çº¿å›¾.ipynb`\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ” å¸¸è§é—®é¢˜\n",
        "\n",
        "### Q1: ä¸ºä»€ä¹ˆéœ€è¦è¿™ä¹ˆå¤šè®­ç»ƒæ•°æ®ï¼Ÿ\n",
        "**A:** å› ä¸ºè¦å­¦ä¹ æ•°ä¸‡ä¸ªè¯çš„è¯­ä¹‰ï¼æ¯ä¸ªè¯åœ¨ä¸åŒè¯­å¢ƒä¸­çš„å«ä¹‰éƒ½è¦å­¦ä¼šã€‚\n",
        "\n",
        "### Q2: è®­ç»ƒä¸€æ¬¡è¦å¤šä¹…ï¼Ÿ\n",
        "**A:** \n",
        "- Word2Vec: å‡ å°æ—¶åˆ°å‡ å¤©ï¼ˆå•æœºï¼‰\n",
        "- BERT: å‡ å¤©åˆ°å‡ å‘¨ï¼ˆå¤šGPUï¼‰\n",
        "- GPT-3: æ•°æœˆï¼ˆæ•°åƒå—GPUï¼‰\n",
        "\n",
        "### Q3: æˆ‘éœ€è¦è‡ªå·±è®­ç»ƒå—ï¼Ÿ\n",
        "**A:** \n",
        "- âŒ **é€šå¸¸ä¸éœ€è¦ï¼** ç›´æ¥ç”¨é¢„è®­ç»ƒå¥½çš„æ¨¡å‹\n",
        "- âœ… å¼€æºæ¨¡å‹ï¼šHuggingFaceä¸Šæœ‰å‡ åƒä¸ª\n",
        "- âœ… å•†ä¸šAPIï¼šOpenAI, Cohereç­‰\n",
        "\n",
        "### Q4: ä¸åŒè¯­è¨€çš„è¯å‘é‡èƒ½ä¸€èµ·ç”¨å—ï¼Ÿ\n",
        "**A:** \n",
        "- âŒ ä¸åŒæ¨¡å‹è®­ç»ƒçš„å‘é‡ä¸å…¼å®¹\n",
        "- âœ… ä½†æœ‰å¤šè¯­è¨€æ¨¡å‹ï¼šmBERT, XLM-Rç­‰\n",
        "- âœ… è¿™äº›æ¨¡å‹çš„ä¸­æ–‡å’Œè‹±æ–‡å‘é‡åœ¨åŒä¸€ä¸ªç©ºé—´\n",
        "\n",
        "### Q5: å‘é‡ç»´åº¦è¶Šé«˜è¶Šå¥½å—ï¼Ÿ\n",
        "**A:** \n",
        "- âš–ï¸ ä¸ä¸€å®šï¼è¦æƒè¡¡æ€§èƒ½å’Œé€Ÿåº¦\n",
        "- 300ç»´ï¼šå¾ˆå¿«ï¼Œæ•ˆæœä¸é”™\n",
        "- 768ç»´ï¼šæ•ˆæœæ›´å¥½ï¼Œé€Ÿåº¦è¿˜è¡Œ\n",
        "- 1536ç»´ï¼šæ•ˆæœæœ€å¥½ï¼Œä½†æ›´æ…¢ã€æ›´å ç©ºé—´\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ‰ æ­å–œï¼\n",
        "\n",
        "ä½ ç°åœ¨ç†è§£äº†RAGç³»ç»Ÿçš„æ ¸å¿ƒåŸºç¡€ï¼š\n",
        "- âœ… è¯å‘é‡æ˜¯å¦‚ä½•è®­ç»ƒçš„\n",
        "- âœ… ä¸ºä»€ä¹ˆå‘é‡èƒ½è¡¨ç¤ºè¯­ä¹‰\n",
        "- âœ… å¦‚ä½•ç”¨å‘é‡æ‰¾ç›¸ä¼¼æ–‡æ¡£\n",
        "\n",
        "**ç»§ç»­å­¦ä¹ RAGï¼** ğŸš€\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
