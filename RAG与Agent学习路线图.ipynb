{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸš€ RAGä¸Agentå­¦ä¹ è·¯çº¿å›¾\n",
        "\n",
        "## ğŸ“‹ ä½ çš„å­¦ä¹ ç›®æ ‡è¯„ä¼°\n",
        "\n",
        "### âœ… ä½ å·²ç»æŒæ¡çš„çŸ¥è¯†\n",
        "- âœ“ çŸ©é˜µè¿ç®—ï¼ˆçº¿æ€§ä»£æ•°åŸºç¡€ï¼‰\n",
        "- âœ“ å›å½’æ–¹ç¨‹ï¼ˆæœºå™¨å­¦ä¹ åŸºç¡€ï¼‰\n",
        "- âœ“ Pythonç¼–ç¨‹åŸºç¡€\n",
        "- âœ“ NumPyæ•°æ®å¤„ç†\n",
        "\n",
        "### ğŸ¯ RAGå’ŒAgentæ˜¯ä»€ä¹ˆï¼Ÿ\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¤– ä»€ä¹ˆæ˜¯RAGï¼Ÿ\n",
        "\n",
        "**RAG = Retrieval-Augmented Generationï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰**\n",
        "\n",
        "### é€šä¿—ç†è§£\n",
        "\n",
        "æƒ³è±¡ä½ åœ¨è€ƒè¯•ï¼š\n",
        "- **ä¸ç”¨RAG**ï¼šåªé è„‘å­é‡Œè®°ä½çš„çŸ¥è¯†ç­”é¢˜ï¼ˆå¯èƒ½ä¼šçç¼–ï¼‰\n",
        "- **ç”¨RAG**ï¼šå…è®¸ä½ ç¿»ä¹¦æ‰¾èµ„æ–™å†å›ç­”ï¼ˆæ›´å‡†ç¡®ã€æ›´é è°±ï¼‰\n",
        "\n",
        "### å·¥ä½œæµç¨‹\n",
        "\n",
        "```\n",
        "ç”¨æˆ·æé—® \n",
        "    â†“\n",
        "1. æ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼ˆä»çŸ¥è¯†åº“æ‰¾èµ„æ–™ï¼‰\n",
        "    â†“\n",
        "2. æŠŠèµ„æ–™+é—®é¢˜ä¸€èµ·ç»™LLM\n",
        "    â†“\n",
        "3. LLMåŸºäºèµ„æ–™ç”Ÿæˆç­”æ¡ˆ\n",
        "    â†“\n",
        "è¿”å›ç»™ç”¨æˆ·\n",
        "```\n",
        "\n",
        "### å®é™…åº”ç”¨åœºæ™¯\n",
        "\n",
        "- ğŸ“š **ä¼ä¸šçŸ¥è¯†åº“é—®ç­”**ï¼šå‘˜å·¥é—®\"è¯·å‡æµç¨‹æ˜¯ä»€ä¹ˆï¼Ÿ\"â†’ ä»å…¬å¸æ–‡æ¡£ä¸­æ£€ç´¢\n",
        "- ğŸ“„ **PDFæ–‡æ¡£åŠ©æ‰‹**ï¼šä¸Šä¼ è®ºæ–‡ï¼Œé—®\"è¿™ç¯‡æ–‡ç« çš„æ ¸å¿ƒè§‚ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ\"\n",
        "- ğŸ¥ **åŒ»ç–—å’¨è¯¢ç³»ç»Ÿ**ï¼šåŸºäºåŒ»å­¦æ–‡çŒ®å›ç­”é—®é¢˜\n",
        "- ğŸ’¼ **å®¢æœæœºå™¨äºº**ï¼šåŸºäºäº§å“æ‰‹å†Œå›ç­”ç”¨æˆ·é—®é¢˜\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¦¾ ä»€ä¹ˆæ˜¯Agentï¼Ÿ\n",
        "\n",
        "**Agent = èƒ½è‡ªä¸»æ€è€ƒã€è§„åˆ’ã€ä½¿ç”¨å·¥å…·çš„AIåŠ©æ‰‹**\n",
        "\n",
        "### é€šä¿—ç†è§£\n",
        "\n",
        "- **æ™®é€šLLM**ï¼šä½ é—®ä¸€å¥ï¼Œå®ƒç­”ä¸€å¥ï¼ˆè¢«åŠ¨ï¼‰\n",
        "- **Agent**ï¼šä¼šè‡ªå·±åˆ†è§£ä»»åŠ¡ã€è°ƒç”¨å·¥å…·ã€å¤šæ­¥éª¤å®Œæˆå¤æ‚ä»»åŠ¡ï¼ˆä¸»åŠ¨ï¼‰\n",
        "\n",
        "### å·¥ä½œæµç¨‹\n",
        "\n",
        "```\n",
        "ç”¨æˆ·ï¼šå¸®æˆ‘åˆ†æä¸€ä¸‹ç‰¹æ–¯æ‹‰è‚¡ç¥¨\n",
        "    â†“\n",
        "Agentæ€è€ƒï¼š\n",
        "1. æˆ‘éœ€è¦å…ˆè·å–è‚¡ç¥¨æ•°æ®ï¼ˆè°ƒç”¨è‚¡ç¥¨APIå·¥å…·ï¼‰\n",
        "2. ç„¶ååˆ†ææ•°æ®ï¼ˆè°ƒç”¨æ•°æ®åˆ†æå·¥å…·ï¼‰\n",
        "3. ç”ŸæˆæŠ¥å‘Šï¼ˆè°ƒç”¨æ–‡æ¡£ç”Ÿæˆå·¥å…·ï¼‰\n",
        "    â†“\n",
        "æ‰§è¡Œï¼šä¾æ¬¡è°ƒç”¨å„ä¸ªå·¥å…·\n",
        "    â†“\n",
        "è¿”å›å®Œæ•´åˆ†ææŠ¥å‘Š\n",
        "```\n",
        "\n",
        "### å®é™…åº”ç”¨åœºæ™¯\n",
        "\n",
        "- ğŸ” **è‡ªåŠ¨åŒ–ç ”ç©¶åŠ©æ‰‹**ï¼šè‡ªåŠ¨æœç´¢ã€æ€»ç»“ã€ç”ŸæˆæŠ¥å‘Š\n",
        "- ğŸ’» **ä»£ç åŠ©æ‰‹**ï¼šç†è§£éœ€æ±‚â†’å†™ä»£ç â†’è°ƒè¯•â†’æµ‹è¯•\n",
        "- ğŸ“Š **æ•°æ®åˆ†æå¸ˆ**ï¼šè·å–æ•°æ®â†’æ¸…æ´—â†’åˆ†æâ†’å¯è§†åŒ–\n",
        "- ğŸ¤– **ä¸ªäººåŠ©ç†**ï¼šå®‰æ’æ—¥ç¨‹ã€å‘é‚®ä»¶ã€è®¢ç¥¨ã€æé†’\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“š ä½ éœ€è¦è¡¥å……çš„å‰ç½®çŸ¥è¯†\n",
        "\n",
        "### ğŸ”´ å¿…é¡»æŒæ¡ï¼ˆæ ¸å¿ƒåŸºç¡€ï¼‰\n",
        "\n",
        "#### 1. **è¯å‘é‡/Embeddingï¼ˆä½ å·²ç»å­¦è¿‡çš„åº”ç”¨ï¼ï¼‰**\n",
        "\n",
        "ä½ å­¦è¿‡çš„çŸ©é˜µçŸ¥è¯†æ­£å¥½ç”¨å¾—ä¸Šï¼\n",
        "\n",
        "**æ ¸å¿ƒæ¦‚å¿µ**ï¼š\n",
        "- æŠŠæ–‡å­—è½¬æˆæ•°å­—å‘é‡ï¼ˆå°±åƒä½ å­¦è¿‡çš„å‘é‡ï¼‰\n",
        "- ç›¸ä¼¼çš„è¯ï¼Œå‘é‡è·ç¦»è¿‘\n",
        "\n",
        "```python\n",
        "# ç¤ºä¾‹\n",
        "\"å›½ç‹\" â†’ [0.2, 0.5, 0.8, ...]\n",
        "\"å¥³ç‹\" â†’ [0.21, 0.48, 0.79, ...]  # è·ç¦»å¾ˆè¿‘ï¼\n",
        "\"è‹¹æœ\" â†’ [0.7, 0.1, 0.2, ...]     # è·ç¦»å¾ˆè¿œ\n",
        "```\n",
        "\n",
        "**ä¸ºä»€ä¹ˆé‡è¦ï¼Ÿ**\n",
        "- RAGéœ€è¦ç”¨embeddingæ‰¾ç›¸ä¼¼æ–‡æ¡£\n",
        "- ä½ å­¦è¿‡çš„ä½™å¼¦ç›¸ä¼¼åº¦ã€ç‚¹ç§¯éƒ½ä¼šç”¨åˆ°ï¼\n",
        "\n",
        "---\n",
        "\n",
        "#### 2. **å‘é‡æ•°æ®åº“ï¼ˆå­˜å‚¨å’Œæ£€ç´¢embeddingï¼‰**\n",
        "\n",
        "å¸¸ç”¨çš„ï¼š\n",
        "- **Milvus**ï¼šæœ€æµè¡Œï¼Œæ€§èƒ½å¥½\n",
        "- **Chroma**ï¼šè½»é‡çº§ï¼Œé€‚åˆå…¥é—¨\n",
        "- **Pinecone**ï¼šäº‘æœåŠ¡ï¼Œæ˜“ç”¨\n",
        "\n",
        "**æ ¸å¿ƒæ“ä½œ**ï¼š\n",
        "```python\n",
        "# å­˜å‚¨æ–‡æ¡£\n",
        "db.add(\"åŒ—äº¬æ˜¯ä¸­å›½çš„é¦–éƒ½\", embedding=[0.1, 0.2, ...])\n",
        "\n",
        "# æ£€ç´¢ç›¸ä¼¼æ–‡æ¡£\n",
        "query = \"ä¸­å›½çš„é¦–éƒ½åœ¨å“ªï¼Ÿ\"\n",
        "results = db.search(query, top_k=3)  # æ‰¾æœ€ç›¸ä¼¼çš„3ä¸ª\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### 3. **LLM APIè°ƒç”¨ï¼ˆOpenAI/Claude/å›½äº§æ¨¡å‹ï¼‰**\n",
        "\n",
        "**åŸºæœ¬è°ƒç”¨**ï¼š\n",
        "```python\n",
        "import openai\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"ä½ å¥½\"}\n",
        "    ]\n",
        ")\n",
        "```\n",
        "\n",
        "**å›½äº§æ›¿ä»£**ï¼š\n",
        "- é€šä¹‰åƒé—®ï¼ˆé˜¿é‡Œï¼‰\n",
        "- æ–‡å¿ƒä¸€è¨€ï¼ˆç™¾åº¦ï¼‰\n",
        "- ChatGLMï¼ˆæ¸…åï¼‰\n",
        "\n",
        "---\n",
        "\n",
        "#### 4. **æç¤ºå·¥ç¨‹ï¼ˆPrompt Engineeringï¼‰**\n",
        "\n",
        "å¦‚ä½•è®©AIæ›´å¥½åœ°ç†è§£ä½ çš„éœ€æ±‚\n",
        "\n",
        "**å·®çš„æç¤º**ï¼š\n",
        "```\n",
        "å¸®æˆ‘æ€»ç»“è¿™ç¯‡æ–‡ç« \n",
        "```\n",
        "\n",
        "**å¥½çš„æç¤º**ï¼š\n",
        "```\n",
        "è¯·æ ¹æ®ä»¥ä¸‹æ–‡ç« å†…å®¹ï¼Œæå–3ä¸ªæ ¸å¿ƒè§‚ç‚¹ï¼Œæ¯ä¸ªè§‚ç‚¹ç”¨ä¸€å¥è¯æ¦‚æ‹¬ï¼š\n",
        "\n",
        "ã€æ–‡ç« å†…å®¹ã€‘\n",
        "...\n",
        "\n",
        "è¾“å‡ºæ ¼å¼ï¼š\n",
        "1. è§‚ç‚¹1\n",
        "2. è§‚ç‚¹2\n",
        "3. è§‚ç‚¹3\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸŸ¡ å»ºè®®æŒæ¡ï¼ˆæå‡èƒ½åŠ›ï¼‰\n",
        "\n",
        "#### 5. **LangChainæ¡†æ¶ï¼ˆå¿«é€Ÿæ­å»ºRAG/Agentï¼‰**\n",
        "\n",
        "**ä¸ºä»€ä¹ˆç”¨ï¼Ÿ**\n",
        "- ä¸ç”¨ä»é›¶å†™ä»£ç \n",
        "- æä¾›äº†å¾ˆå¤šç°æˆæ¨¡å—\n",
        "- ç¤¾åŒºæ´»è·ƒï¼Œèµ„æ–™å¤š\n",
        "\n",
        "**æ ¸å¿ƒç»„ä»¶**ï¼š\n",
        "- `Document Loaders`ï¼šåŠ è½½æ–‡æ¡£\n",
        "- `Text Splitters`ï¼šæ–‡æ¡£åˆ†å—\n",
        "- `Vector Stores`ï¼šå‘é‡å­˜å‚¨\n",
        "- `Chains`ï¼šè¿æ¥å„ä¸ªæ­¥éª¤\n",
        "- `Agents`ï¼šæ™ºèƒ½ä»£ç†\n",
        "\n",
        "---\n",
        "\n",
        "#### 6. **åŸºç¡€NLPæ¦‚å¿µ**\n",
        "\n",
        "- **åˆ†è¯ï¼ˆTokenizationï¼‰**ï¼šæŠŠå¥å­æ‹†æˆè¯\n",
        "- **å‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰**ï¼šè¯†åˆ«äººåã€åœ°å\n",
        "- **æ–‡æœ¬æ¸…æ´—**ï¼šå»é™¤æ— ç”¨å­—ç¬¦\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸŸ¢ å¯é€‰å­¦ä¹ ï¼ˆæ·±å…¥ç†è§£ï¼‰\n",
        "\n",
        "#### 7. **Transformeræ¶æ„ï¼ˆäº†è§£LLMåŸç†ï¼‰**\n",
        "\n",
        "å¦‚æœæƒ³æ·±å…¥ç†è§£ï¼Œå»ºè®®å­¦ä¹ ï¼š\n",
        "- æ³¨æ„åŠ›æœºåˆ¶ï¼ˆAttentionï¼‰\n",
        "- BERT/GPTæ¶æ„\n",
        "- å¾®è°ƒï¼ˆFine-tuningï¼‰\n",
        "\n",
        "**ä½†æ³¨æ„**ï¼šä¸å­¦è¿™ä¸ªä¹Ÿèƒ½åšRAG/Agenté¡¹ç›®ï¼\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ—ºï¸ æ¨èå­¦ä¹ è·¯çº¿ï¼ˆ4å‘¨è®¡åˆ’ï¼‰\n",
        "\n",
        "### ğŸ“… ç¬¬1å‘¨ï¼šAIåŸºç¡€æ¦‚å¿µ\n",
        "\n",
        "**ç›®æ ‡**ï¼šç†è§£è¯å‘é‡å’ŒLLMåŸºç¡€\n",
        "\n",
        "#### Day 1-2ï¼šè¯å‘é‡ï¼ˆEmbeddingï¼‰\n",
        "- [ ] å­¦ä¹ è¯å‘é‡æ¦‚å¿µ\n",
        "- [ ] ç†è§£ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆä½ å·²ç»ä¼šçŸ©é˜µä¹˜æ³•äº†ï¼ï¼‰\n",
        "- [ ] å®è·µï¼šç”¨OpenAI APIç”Ÿæˆembedding\n",
        "\n",
        "```python\n",
        "# ç®€å•ç¤ºä¾‹\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=\"your-key\")\n",
        "\n",
        "text = \"äººå·¥æ™ºèƒ½å¾ˆæœ‰è¶£\"\n",
        "response = client.embeddings.create(\n",
        "    model=\"text-embedding-ada-002\",\n",
        "    input=text\n",
        ")\n",
        "embedding = response.data[0].embedding  # 1536ç»´å‘é‡\n",
        "```\n",
        "\n",
        "#### Day 3-4ï¼šLLMåŸºç¡€\n",
        "- [ ] æ³¨å†ŒOpenAIè´¦å·ï¼ˆæˆ–ç”¨å›½äº§æ¨¡å‹ï¼‰\n",
        "- [ ] å­¦ä¹ APIè°ƒç”¨\n",
        "- [ ] å®è·µï¼šåšä¸€ä¸ªç®€å•èŠå¤©æœºå™¨äºº\n",
        "\n",
        "#### Day 5-7ï¼šæç¤ºå·¥ç¨‹\n",
        "- [ ] å­¦ä¹ æç¤ºè¯æŠ€å·§\n",
        "- [ ] å®è·µï¼šFew-shot learning\n",
        "- [ ] å®è·µï¼šChain of Thoughtï¼ˆæ€ç»´é“¾ï¼‰\n",
        "\n",
        "**å­¦ä¹ èµ„æº**ï¼š\n",
        "- å´æ©è¾¾ã€ŠChatGPT Prompt Engineeringã€‹è¯¾ç¨‹ï¼ˆå…è´¹ï¼‰\n",
        "- OpenAIå®˜æ–¹æ–‡æ¡£\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“… ç¬¬2å‘¨ï¼šRAGåŸºç¡€\n",
        "\n",
        "**ç›®æ ‡**ï¼šæ­å»ºç¬¬ä¸€ä¸ªRAGç³»ç»Ÿ\n",
        "\n",
        "#### Day 1-2ï¼šæ–‡æ¡£å¤„ç†\n",
        "- [ ] å­¦ä¹ æ–‡æ¡£åŠ è½½ï¼ˆPDFã€TXTã€Markdownï¼‰\n",
        "- [ ] å­¦ä¹ æ–‡æœ¬åˆ†å—ï¼ˆChunkingï¼‰ç­–ç•¥\n",
        "\n",
        "```python\n",
        "# æ–‡æœ¬åˆ†å—ç¤ºä¾‹\n",
        "text = \"å¾ˆé•¿çš„æ–‡æ¡£...\"\n",
        "chunks = []\n",
        "chunk_size = 500  # æ¯å—500å­—\n",
        "for i in range(0, len(text), chunk_size):\n",
        "    chunks.append(text[i:i+chunk_size])\n",
        "```\n",
        "\n",
        "#### Day 3-4ï¼šå‘é‡æ•°æ®åº“\n",
        "- [ ] å®‰è£…Chromaï¼ˆæœ€ç®€å•ï¼‰\n",
        "- [ ] å­˜å‚¨æ–‡æ¡£å‘é‡\n",
        "- [ ] æ£€ç´¢ç›¸ä¼¼æ–‡æ¡£\n",
        "\n",
        "```python\n",
        "# Chromaç¤ºä¾‹\n",
        "import chromadb\n",
        "client = chromadb.Client()\n",
        "collection = client.create_collection(\"my_docs\")\n",
        "\n",
        "# æ·»åŠ æ–‡æ¡£\n",
        "collection.add(\n",
        "    documents=[\"åŒ—äº¬æ˜¯é¦–éƒ½\", \"ä¸Šæµ·æ˜¯ç»æµä¸­å¿ƒ\"],\n",
        "    ids=[\"doc1\", \"doc2\"]\n",
        ")\n",
        "\n",
        "# æŸ¥è¯¢\n",
        "results = collection.query(\n",
        "    query_texts=[\"ä¸­å›½çš„é¦–éƒ½\"],\n",
        "    n_results=2\n",
        ")\n",
        "```\n",
        "\n",
        "#### Day 5-7ï¼šå®ç°ç®€å•RAG\n",
        "- [ ] æŠŠä¸Šé¢çš„ç»„ä»¶è¿èµ·æ¥\n",
        "- [ ] å®è·µï¼šPDFé—®ç­”ç³»ç»Ÿ\n",
        "\n",
        "**é¡¹ç›®**ï¼šåšä¸€ä¸ª\"é—®ç­”è‡ªå·±ç¬”è®°\"çš„å·¥å…·\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“… ç¬¬3å‘¨ï¼šLangChainå®æˆ˜\n",
        "\n",
        "**ç›®æ ‡**ï¼šç”¨æ¡†æ¶å¿«é€Ÿå¼€å‘\n",
        "\n",
        "#### Day 1-3ï¼šLangChainåŸºç¡€\n",
        "- [ ] å®‰è£…LangChain\n",
        "- [ ] å­¦ä¹ æ ¸å¿ƒæ¦‚å¿µï¼ˆChains, Memory, Toolsï¼‰\n",
        "- [ ] å®è·µï¼šç”¨LangChainé‡æ„ç¬¬2å‘¨çš„RAG\n",
        "\n",
        "```python\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "# 5è¡Œä»£ç æ­å»ºRAG\n",
        "loader = TextLoader(\"my_doc.txt\")\n",
        "documents = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "vectorstore = Chroma.from_documents(docs, OpenAIEmbeddings())\n",
        "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=vectorstore.as_retriever())\n",
        "\n",
        "# ä½¿ç”¨\n",
        "answer = qa.run(\"é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ\")\n",
        "```\n",
        "\n",
        "#### Day 4-7ï¼šRAGè¿›é˜¶\n",
        "- [ ] å¤šæ–‡æ¡£RAG\n",
        "- [ ] å¯¹è¯è®°å¿†ï¼ˆMemoryï¼‰\n",
        "- [ ] å¼•ç”¨æ¥æºï¼ˆSource trackingï¼‰\n",
        "\n",
        "**é¡¹ç›®**ï¼šåšä¸€ä¸ª\"ä¼ä¸šçŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ\"\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“… ç¬¬4å‘¨ï¼šAgentå…¥é—¨\n",
        "\n",
        "**ç›®æ ‡**ï¼šç†è§£Agentå¹¶å®ç°ç®€å•ç¤ºä¾‹\n",
        "\n",
        "#### Day 1-3ï¼šAgentæ¦‚å¿µ\n",
        "- [ ] å­¦ä¹ ReActæ¡†æ¶ï¼ˆReason + Actï¼‰\n",
        "- [ ] ç†è§£å·¥å…·è°ƒç”¨ï¼ˆFunction Callingï¼‰\n",
        "- [ ] å®è·µï¼šç»™LLMæ·»åŠ \"è®¡ç®—å™¨\"å·¥å…·\n",
        "\n",
        "```python\n",
        "# ç®€åŒ–çš„Agentç¤ºä¾‹\n",
        "tools = {\n",
        "    \"calculator\": lambda x: eval(x),\n",
        "    \"search\": lambda q: f\"æœç´¢ç»“æœ: {q}\"\n",
        "}\n",
        "\n",
        "# Agentæ€è€ƒ\n",
        "user_input = \"234 * 567ç­‰äºå¤šå°‘ï¼Ÿ\"\n",
        "# Agentå†³å®šè°ƒç”¨calculatorå·¥å…·\n",
        "result = tools[\"calculator\"](\"234 * 567\")\n",
        "```\n",
        "\n",
        "#### Day 4-7ï¼šLangChain Agent\n",
        "- [ ] å­¦ä¹ LangChainçš„Agent\n",
        "- [ ] æ·»åŠ è‡ªå®šä¹‰å·¥å…·\n",
        "- [ ] å®è·µï¼šå¤šæ­¥éª¤ä»»åŠ¡\n",
        "\n",
        "**é¡¹ç›®**ï¼šåšä¸€ä¸ª\"èƒ½æœç´¢+æ€»ç»“\"çš„Agent\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“… é¢å¤–èµ„æº\n",
        "\n",
        "#### å¼€æºé¡¹ç›®å‚è€ƒ\n",
        "1. **Dify**ï¼šå¼€æºRAG/Agentå¹³å°ï¼ˆæ¨èï¼ï¼‰\n",
        "2. **Quivr**ï¼šä¸ªäººçŸ¥è¯†åº“\n",
        "3. **AnythingLLM**ï¼šä¼ä¸šRAGæ–¹æ¡ˆ\n",
        "\n",
        "#### å­¦ä¹ èµ„æº\n",
        "- ğŸ¥ Bç«™ï¼šæå®æ¯…ã€Šç”Ÿæˆå¼AIã€‹\n",
        "- ğŸ“š å´æ©è¾¾ï¼šã€ŠLangChain for LLM Application Developmentã€‹\n",
        "- ğŸ“– GitHub Awesome-LLM-RAG\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ’¡ å¿«é€Ÿå…¥é—¨ç¤ºä¾‹\n",
        "\n",
        "è®©æˆ‘ç»™ä½ ä¸€ä¸ªæœ€ç®€å•çš„RAGç¤ºä¾‹ï¼Œä½ ç°åœ¨å°±å¯ä»¥è¯•è¯•ï¼\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### ç¤ºä¾‹1ï¼šç†è§£Embeddingï¼ˆè¯å‘é‡ï¼‰\n",
        "\n",
        "# ä½ å·²ç»å­¦è¿‡çš„çŸ¥è¯†ï¼šä¸¤ä¸ªå‘é‡çš„ç›¸ä¼¼åº¦\n",
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(v1, v2):\n",
        "    \"\"\"è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆä½ å­¦è¿‡çš„ï¼ï¼‰\"\"\"\n",
        "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
        "\n",
        "# æ¨¡æ‹Ÿè¯å‘é‡\n",
        "king = np.array([0.1, 0.9, 0.5])\n",
        "queen = np.array([0.15, 0.85, 0.52])\n",
        "apple = np.array([0.8, 0.1, 0.2])\n",
        "\n",
        "print(\"å›½ç‹ vs å¥³ç‹çš„ç›¸ä¼¼åº¦:\", cosine_similarity(king, queen))\n",
        "print(\"å›½ç‹ vs è‹¹æœçš„ç›¸ä¼¼åº¦:\", cosine_similarity(king, apple))\n",
        "\n",
        "# è¿™å°±æ˜¯RAGæ£€ç´¢çš„æ ¸å¿ƒï¼æ‰¾æœ€ç›¸ä¼¼çš„æ–‡æ¡£\n",
        "documents = {\n",
        "    \"doc1\": np.array([0.1, 0.9, 0.5]),\n",
        "    \"doc2\": np.array([0.8, 0.1, 0.2]),\n",
        "    \"doc3\": np.array([0.12, 0.88, 0.48])\n",
        "}\n",
        "\n",
        "query = np.array([0.1, 0.9, 0.5])  # ç”¨æˆ·çš„é—®é¢˜\n",
        "\n",
        "# æ‰¾æœ€ç›¸ä¼¼çš„æ–‡æ¡£\n",
        "similarities = {}\n",
        "for doc_name, doc_vector in documents.items():\n",
        "    sim = cosine_similarity(query, doc_vector)\n",
        "    similarities[doc_name] = sim\n",
        "\n",
        "print(\"\\næ£€ç´¢ç»“æœï¼ˆæŒ‰ç›¸ä¼¼åº¦æ’åºï¼‰:\")\n",
        "for doc, sim in sorted(similarities.items(), key=lambda x: x[1], reverse=True):\n",
        "    print(f\"{doc}: {sim:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### ç¤ºä¾‹2ï¼šç®€å•çš„RAGæµç¨‹ï¼ˆä¼ªä»£ç ï¼‰\n",
        "\n",
        "# è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„RAGæµç¨‹ï¼Œå¸®ä½ ç†è§£æ ¸å¿ƒæ¦‚å¿µ\n",
        "\n",
        "class SimpleRAG:\n",
        "    def __init__(self):\n",
        "        # çŸ¥è¯†åº“ï¼šæ–‡æ¡£å†…å®¹ â†’ å‘é‡\n",
        "        self.knowledge_base = {\n",
        "            \"åŒ—äº¬æ˜¯ä¸­å›½çš„é¦–éƒ½ï¼Œä½äºååŒ—åœ°åŒº\": [0.1, 0.9, 0.5, 0.3],\n",
        "            \"ä¸Šæµ·æ˜¯ä¸­å›½çš„ç»æµä¸­å¿ƒï¼Œäººå£ä¼—å¤š\": [0.2, 0.8, 0.6, 0.4],\n",
        "            \"æ·±åœ³æ˜¯ç§‘æŠ€åˆ›æ–°ä¹‹åŸï¼Œä¸´è¿‘é¦™æ¸¯\": [0.3, 0.7, 0.7, 0.5]\n",
        "        }\n",
        "    \n",
        "    def retrieve(self, query_vector, top_k=2):\n",
        "        \"\"\"æ£€ç´¢ï¼šæ‰¾æœ€ç›¸ä¼¼çš„æ–‡æ¡£\"\"\"\n",
        "        scores = {}\n",
        "        for doc, vec in self.knowledge_base.items():\n",
        "            # è®¡ç®—ç›¸ä¼¼åº¦ï¼ˆç”¨ä½ å­¦è¿‡çš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰\n",
        "            score = np.dot(query_vector, vec) / (np.linalg.norm(query_vector) * np.linalg.norm(vec))\n",
        "            scores[doc] = score\n",
        "        \n",
        "        # è¿”å›top_kä¸ªæœ€ç›¸ä¼¼çš„\n",
        "        sorted_docs = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "        return [doc for doc, score in sorted_docs[:top_k]]\n",
        "    \n",
        "    def generate(self, query, relevant_docs):\n",
        "        \"\"\"ç”Ÿæˆï¼šLLMåŸºäºæ£€ç´¢åˆ°çš„æ–‡æ¡£å›ç­”\"\"\"\n",
        "        # æ„é€ æç¤ºè¯\n",
        "        context = \"\\n\".join(relevant_docs)\n",
        "        prompt = f\"\"\"\n",
        "        æ ¹æ®ä»¥ä¸‹å‚è€ƒèµ„æ–™å›ç­”é—®é¢˜ï¼š\n",
        "        \n",
        "        ã€å‚è€ƒèµ„æ–™ã€‘\n",
        "        {context}\n",
        "        \n",
        "        ã€é—®é¢˜ã€‘\n",
        "        {query}\n",
        "        \n",
        "        ã€å›ç­”ã€‘\n",
        "        \"\"\"\n",
        "        \n",
        "        # å®é™…ä½¿ç”¨æ—¶è¿™é‡Œä¼šè°ƒç”¨LLM API\n",
        "        return f\"[æ¨¡æ‹ŸLLMå›ç­”] åŸºäºèµ„æ–™: {context[:50]}...\"\n",
        "    \n",
        "    def ask(self, query):\n",
        "        \"\"\"å®Œæ•´çš„RAGæµç¨‹\"\"\"\n",
        "        # 1. æŠŠé—®é¢˜è½¬æˆå‘é‡ï¼ˆå®é™…ä½¿ç”¨embedding APIï¼‰\n",
        "        query_vector = [0.15, 0.85, 0.52, 0.35]  # æ¨¡æ‹Ÿ\n",
        "        \n",
        "        # 2. æ£€ç´¢ç›¸å…³æ–‡æ¡£\n",
        "        relevant_docs = self.retrieve(query_vector, top_k=2)\n",
        "        print(\"æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£:\")\n",
        "        for i, doc in enumerate(relevant_docs, 1):\n",
        "            print(f\"{i}. {doc}\")\n",
        "        \n",
        "        # 3. åŸºäºæ–‡æ¡£ç”Ÿæˆç­”æ¡ˆ\n",
        "        answer = self.generate(query, relevant_docs)\n",
        "        return answer\n",
        "\n",
        "# ä½¿ç”¨\n",
        "rag = SimpleRAG()\n",
        "question = \"ä¸­å›½çš„é¦–éƒ½åœ¨å“ªé‡Œï¼Ÿ\"\n",
        "answer = rag.ask(question)\n",
        "print(f\"\\né—®é¢˜: {question}\")\n",
        "print(f\"ç­”æ¡ˆ: {answer}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### ç¤ºä¾‹3ï¼šAgentçš„æ€è€ƒè¿‡ç¨‹ï¼ˆä¼ªä»£ç ï¼‰\n",
        "\n",
        "class SimpleAgent:\n",
        "    def __init__(self):\n",
        "        # å¯ç”¨çš„å·¥å…·\n",
        "        self.tools = {\n",
        "            \"calculator\": self.calculator,\n",
        "            \"search\": self.search,\n",
        "            \"weather\": self.get_weather\n",
        "        }\n",
        "    \n",
        "    def calculator(self, expression):\n",
        "        \"\"\"è®¡ç®—å™¨å·¥å…·\"\"\"\n",
        "        try:\n",
        "            return eval(expression)\n",
        "        except:\n",
        "            return \"è®¡ç®—é”™è¯¯\"\n",
        "    \n",
        "    def search(self, query):\n",
        "        \"\"\"æœç´¢å·¥å…·ï¼ˆæ¨¡æ‹Ÿï¼‰\"\"\"\n",
        "        return f\"[æœç´¢ç»“æœ] å…³äº'{query}'çš„ä¿¡æ¯...\"\n",
        "    \n",
        "    def get_weather(self, city):\n",
        "        \"\"\"å¤©æ°”å·¥å…·ï¼ˆæ¨¡æ‹Ÿï¼‰\"\"\"\n",
        "        return f\"{city}ä»Šå¤©æ™´å¤©ï¼Œ25åº¦\"\n",
        "    \n",
        "    def think(self, task):\n",
        "        \"\"\"Agentçš„æ€è€ƒè¿‡ç¨‹ï¼ˆReActæ¡†æ¶ï¼‰\"\"\"\n",
        "        print(f\"\\nğŸ¤” ä»»åŠ¡: {task}\")\n",
        "        print(\"\\n--- Agentæ€è€ƒè¿‡ç¨‹ ---\")\n",
        "        \n",
        "        # å®é™…ä½¿ç”¨æ—¶ï¼Œè¿™éƒ¨åˆ†ç”±LLMç”Ÿæˆ\n",
        "        # è¿™é‡Œæˆ‘ä»¬æ¨¡æ‹ŸAgentçš„æ€è€ƒ\n",
        "        \n",
        "        if \"è®¡ç®—\" in task or \"å¤šå°‘\" in task:\n",
        "            print(\"æ€è€ƒ: è¿™æ˜¯ä¸€ä¸ªè®¡ç®—é—®é¢˜ï¼Œæˆ‘éœ€è¦ä½¿ç”¨è®¡ç®—å™¨å·¥å…·\")\n",
        "            action = \"calculator\"\n",
        "            action_input = \"123 * 456\"\n",
        "        elif \"å¤©æ°”\" in task:\n",
        "            print(\"æ€è€ƒ: è¿™æ˜¯è¯¢é—®å¤©æ°”ï¼Œæˆ‘éœ€è¦ä½¿ç”¨å¤©æ°”å·¥å…·\")\n",
        "            action = \"weather\"\n",
        "            action_input = \"åŒ—äº¬\"\n",
        "        else:\n",
        "            print(\"æ€è€ƒ: è¿™éœ€è¦æœç´¢ä¿¡æ¯\")\n",
        "            action = \"search\"\n",
        "            action_input = task\n",
        "        \n",
        "        # æ‰§è¡Œè¡ŒåŠ¨\n",
        "        print(f\"è¡ŒåŠ¨: ä½¿ç”¨å·¥å…· '{action}'\")\n",
        "        result = self.tools[action](action_input)\n",
        "        print(f\"è§‚å¯Ÿ: {result}\")\n",
        "        \n",
        "        # ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ\n",
        "        answer = f\"æ ¹æ®{action}å·¥å…·çš„ç»“æœï¼Œç­”æ¡ˆæ˜¯: {result}\"\n",
        "        print(f\"\\nâœ… æœ€ç»ˆç­”æ¡ˆ: {answer}\")\n",
        "        return answer\n",
        "\n",
        "# ä½¿ç”¨\n",
        "agent = SimpleAgent()\n",
        "\n",
        "# ä»»åŠ¡1ï¼šè®¡ç®—\n",
        "agent.think(\"123ä¹˜ä»¥456ç­‰äºå¤šå°‘ï¼Ÿ\")\n",
        "\n",
        "# ä»»åŠ¡2ï¼šæŸ¥å¤©æ°”\n",
        "agent.think(\"åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ æ€»ç»“\n",
        "\n",
        "### âœ… ç°åœ¨å°±å¯ä»¥å¼€å§‹ï¼\n",
        "\n",
        "ä½ çš„åŸºç¡€**å®Œå…¨è¶³å¤Ÿ**å¼€å§‹å­¦ä¹ RAGå’ŒAgentï¼\n",
        "\n",
        "### ğŸ“ æ ¸å¿ƒè¦ç‚¹\n",
        "\n",
        "1. **RAG = æ£€ç´¢ + ç”Ÿæˆ**\n",
        "   - æ£€ç´¢ç”¨åˆ°ä½ å­¦è¿‡çš„å‘é‡ç›¸ä¼¼åº¦\n",
        "   - ç”Ÿæˆé LLM API\n",
        "\n",
        "2. **Agent = æ€è€ƒ + è¡ŒåŠ¨**\n",
        "   - æ€è€ƒé LLMæ¨ç†\n",
        "   - è¡ŒåŠ¨é å·¥å…·è°ƒç”¨\n",
        "\n",
        "3. **ä¸éœ€è¦æ·±åšçš„æ•°å­¦/MLèƒŒæ™¯**\n",
        "   - ä¼šè°ƒAPIå°±èƒ½åš\n",
        "   - ä¼šPythonå°±èƒ½åš\n",
        "   - ä½ çš„çŸ©é˜µçŸ¥è¯†æ˜¯åŠ åˆ†é¡¹ï¼\n",
        "\n",
        "### ğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨\n",
        "\n",
        "1. **ä»Šå¤©**ï¼šæ³¨å†Œä¸€ä¸ªLLM APIè´¦å·\n",
        "2. **æœ¬å‘¨**ï¼šè·‘é€šä¸Šé¢3ä¸ªç¤ºä¾‹ä»£ç \n",
        "3. **ä¸‹å‘¨**ï¼šå®‰è£…LangChainï¼Œåšç¬¬ä¸€ä¸ªRAGé¡¹ç›®\n",
        "4. **æœ¬æœˆ**ï¼šå®Œæˆä¸€ä¸ªå®Œæ•´çš„åº”ç”¨\n",
        "\n",
        "### ğŸ’ª ç›¸ä¿¡è‡ªå·±\n",
        "\n",
        "ä½ å·²ç»æŒæ¡äº†ï¼š\n",
        "- âœ… çŸ©é˜µè¿ç®—ï¼ˆç†è§£embeddingçš„åŸºç¡€ï¼‰\n",
        "- âœ… Pythonç¼–ç¨‹ï¼ˆèƒ½å†™ä»£ç ï¼‰\n",
        "- âœ… å­¦ä¹ èƒ½åŠ›ï¼ˆç³»ç»Ÿå­¦è¿‡çº¿æ€§ä»£æ•°ï¼‰\n",
        "\n",
        "**RAG/Agentæ¯”ä½ æƒ³è±¡çš„æ›´å®¹æ˜“ä¸Šæ‰‹ï¼**\n",
        "\n",
        "æœ‰é—®é¢˜éšæ—¶é—®æˆ‘ï¼Œç¥ä½ å­¦ä¹ é¡ºåˆ©ï¼ğŸ‰\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
